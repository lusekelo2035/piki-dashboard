"""
Piki Weekly Business Intelligence Dashboard
============================================
Architecture:
  1. Global Filters (sidebar: city, business, date range, time period)
  2. Shared data prep ‚Äî one pass, all sections reuse filtered df
  3. Four tab sections selectable via pills/tabs:
       üìà Weekly Trends    ‚Äî orders, sales, KPI, failed & rejected orders
       ‚è∞ Delivery Times   ‚Äî stage breakdown, hourly, city charts, heatmap
       üö¥ Rider Attendance ‚Äî attendance pivot, deficiency alerts
       üì¶ Products         ‚Äî product mix, business rankings, geo area tool
  4. Every section has AI Insight + Q&A chat
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.ticker import FuncFormatter
from io import BytesIO
from math import radians, sin, cos, sqrt, atan2
import numpy as np
from datetime import datetime, timedelta
import io
import re
from collections import defaultdict
from rapidfuzz import fuzz, process
import folium
from folium.plugins import HeatMap, Draw
from streamlit_folium import st_folium
from shapely.geometry import Point, Polygon
import anthropic
import os
import json
import requests as _requests
from datetime import date as _date

# ‚îÄ‚îÄ Google API imports (Department KPI tab) ‚îÄ‚îÄ
try:
    from google.oauth2 import service_account as _sa
    from googleapiclient.discovery import build as _gbuild
    import gspread as _gspread
    _GOOGLE_LIBS_OK = True
except ImportError:
    _GOOGLE_LIBS_OK = False

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# PIKI LOGO (embedded base64)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
PIKI_LOGO_B64 = "/9j/4AAQSkZJRgABAgAAAQABAAD/wAARCANIBbADACIAAREBAhEB/9sAQwAIBgYHBgUIBwcHCQkICgwUDQwLCwwZEhMPFB0aHx4dGhwcICQuJyAiLCMcHCg3KSwwMTQ0NB8nOT04MjwuMzQy/9sAQwEJCQkMCwwYDQ0YMiEcITIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIy/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMAAAERAhEAPwD3+iiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAopN3tRmgBaKTdRuoAWim7qY08a/ekQfVqAJaKrG+tV63MI+rio21awXreQf99ik2luOzLtFZx17S1PN9AP+BUw+I9HHXUYB/wKlzx7lezn2NSisn/hJtG/6CVv/wB9UDxNox/5iMH/AH1Rzx7h7KfZmtRWWPEekMcDUID/AMCqRda05+l7Af8AgYo549w9nJdDQoqsuoWj/duYj9HFTLKjj5WU/Q1Sd9iLD6KbupQaAFopM0ZoAWikByaWgAooooAKKKKACiiigAooooAKKKTNAC0Umar3V/bWUZe5mSNR3Y4ovYFroizSE1yd78QNKtyVgElw3+yMD8zWJcfEe6ckW9lGg7F2yawniaUN5HZTwGJqfDB/kejUV5TJ481t+jQIPZP/AK9V28Z643/L3j6KKwePoo6Vk2Jfb7z17NFeP/8ACYa7/wA/zf8AfIqRPGmuof8Aj6DfVBR/aFLzH/YuJ8vvPXKB1ryyLx/rCEb1gkH+4R/WtW0+JAyBd2OB/ejbP6VccbRfUxnlWKh9m/oz0CisnS/Emm6sALa4XzO6Nw1aoORXTGSkrpnDOEoPlkrMWikpaokKKKKACkpaSgApM/WuJ8TeMbnStSFrZpEwAyxYZwaxf+Fg6t/zzt/++T/jXNPF0oS5W9TvpZbiKsFOK0Z6hn60Z+teX/8ACwdW/wCedv8A98n/ABo/4WDq3/PO3/75P+NR9eo9zT+yMV/L+KPUM/WjP1ry/wD4WDq3/PO3/wC+T/jR/wALB1b/AJ52/wD3yf8AGj69R7h/ZGK/l/FHqGaM15f/AMLB1b/nnb/98n/Gj/hYOrf887f/AL5P+NH16j3F/ZGK/l/E9QzSjrXmKfETUlPz20DD2yP61rad8Q4pp0ivLXydxxvVsgVccZRlomRPLMVBXcfyO5opkciyxrIhBVhkEU+uk4HoFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFBpM0ALRTc1n3+u6dpoJurqND/dzk/lSbS3GouTslc0qaetcXd/EayjJFrbSzejN8orHm+IuouT5NtBH/vZaueeLox0bOynl2JqaqH36HplGa8nk8c64/8Ay1iT/dSoD4x1w/8AL6R9FFZPH0ToWTYl9vvPX8ijNeQDxhrg/wCX0n/gIqVPG+uJ1nRv95KP7Qo+Y3kuJ8vvPWs0o6V5fB8Q9UjP72C3kHsCv9a27H4i2chC3ltJCT1ZfmFaxxlGTtcwqZZioK7jf0O2oqnZanaajCJbSdJV/wBk9Kt5roTT1RwtNOzFooopiCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKTNNeVUUsxCqOpJxQA+mk81gah4z0iwJXz/ADnH8MQz+tc3efEeZiRaWSqOzSt/QVjPEUofEzqpYKvW1hFnoeaK8ln8b63PnE6Rf7if41SfxLrMh+bUJvwOK53mFJbHbHJcS97L5ns+fej8a8U/t7Vs5/tCf/vqpE8Ta1H93UJfxwalZjT7Mp5JX6NHs+aUGvJoPHOtw43SxSj/AG0rYs/iOwwLyyyP70bf0rWOOoy62MKmU4qGyv6HoVFYWn+LtI1DaqXIjkP8EnBrbVwwypBB6EV0xnGWqZwTpyg7TVh1FJuozVEC0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVBdXC2tu8zkBUGTUx6VyXjvUha6P9nU4eY44qKk1CLk+hpRpurUUF1Mi4+I825hBYJwSMu/+FUJvH+ryf6tYI/8AgOa5QUteHLG1pdT62GV4WP2L/ebkvjHXZf8Al8Kf7qgVVk8Q6xL97Ubg/RsVm0Vm8RVe8mbxwWHjtBfcWH1G+f715cH/ALat/jUTXEzfemkP1cmmUVDnJ9TZUqa2ivuAsT1JP40lLRU3ZXKuwlFLRRcYnFGB7UtFIYlFLRRqIASpyCQfapUu7mM5S5mX/dkIqKiq5pLZkuEXujQi17VoP9XqFwPq+f51o2/jfW4CN1wsgHZ061z1FaRr1Y7SZjPB4ee8F9x3Ft8R5l4urFW943x/Ot6y8c6PdYV5GgY9pBgfnXlNFbxx9Vb6nFUyfDS+HQ92try3ul3wTxyKe6sDVivBre7ubR99vPJE3qpxXVaV4+vrYql+guI+m4DDV2UswhLSeh5lfJq0Nab5vzPT6KytK12w1iPdazAsOqHhhWoDXfGSkro8iUJQfLJWYtFFFMkKKKKACiiigAppp1Z+sXgsdMnn6FVOPrSbSV2NJt2Rz3ijxgNLJtLLa9z3bsn/ANevObu9ub6Uy3U7yuf7x4H4VHNM9zO80hy7nJNMrwcRiZ1ZNX0PscFgKeHgna8u4lLRRXKegFFFFABRRRQAUlLRQAsckkMgkico68qwOMGvWfB+tvq+mYmOZovlY+teS16J8OYGjsrmUj5Xbiu3AzkqqitmeVm9KEsO5vdbHcjrS00dadXuHyQUUUUAFV7y4FraSzsRhFJqxXIePNS+y6V9mRsSTH9KipNQi5M1o03VqKC6nm9/dG91Ce4Y53uSKgpBS183J8zbZ93CChFRXQKKKKkoKKKKACiiigBKMFsKASSeKWtTw5YHUdbgiHIRg7fSmlzOyJlNQi5PZHrWiIyaNaK/3hGM1oUyNAiKgGABgU8V9NBcsUj4KpLmm5LqwoooqiAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAA1FLIsMbSOwVVGST2qQ9K5Dx5qT2mlrBE215Tg/SoqTUIuTNKNJ1ZqC6mJ4j8a3FxK9rpzGKIHBlB5b6Vxru0jl3ZmY9WY5Jpo6UtfP1a86ru3ofaYbCUsPHlgte/USloorE6gooooAKKKKACkpaKALml6ncaVeJPbyFQD8y54Ir2bTrtb6whul6SKDXhmN3yjqeK9p8NxNBoFpG3URivSy6cuZx6Hg53ShyRqdbmsKKKK9c+bCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigApCcCg9K47xj4mOmx/Y7Vv8ASJByw/hFRUqRpxcpbGlGjOtNQgtWXdf8X2mjgxR4nuf7inhfrXnOqeINR1ZybidhHniJDhRWaztI5d2LMTkk96SvEr4ydTRaI+rwmWUqCvJXkJS0UVyHphRRSUALRSc+hooAWiiigBK2dJ8T6lpLjy5jJDnmKQ5H59qx6KuE5Qd4uxlUowqrlmk0evaH4pstaQKreVP3iY/yreFeCxTSW8yywuUdTkMK9V8JeIxrFr5UxAuo+G/2h616+FxntPdnufNZhlboL2lLWP5HT0UUV3njhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUANNeSeM9R+3a46I2YohtH1r0zWb0WGlzzk4KqcfWvFJJTPM8zfecljXnZhUtBQ7nt5LQ5qrqvZfmNooorxz6cKKKKACiiigAooooAKKKTIoAWikzRketAC0UZooAKKKKACiiigAooooAKTFLRQA+CeW2mWaCRo5F6Mpr0Pwz42W5K2molUm6LJ2b615zRk5BBII71tRxEqTujkxWDpYmNpb9z3wNkAjoadXDeCfErXSjTrtsyqPkYnqPSu4HSveo1Y1Y80T4/EYeeHqOExaKKK1MAooooAKwfFsMk3h+4WMFjjPHpW9TJEWRGRgCpGCDUzV4tF058klLseBilru9e8ByGV7nTCpDHJhPH5GuMutPvLJylzbSxkf3lOK+eq0J0naSPtsPi6VeKcH8ivRRketFYnSFFFFABRRRmgBKWrFtp17dttt7WaQn+6prptN8AX9yyteutvH3Ucsa0hSnP4Vcxq16VJXqSsc1p+n3Gp3iW1uhZmOD7CvZNG0xNK0yG1j/hHJ9TTNK0Sy0eDy7WIA93PVq0x0r18JhfZe9Lc+YzHMfrPuQ+EMUtFFdx5QUUUGgBpbAya8j8Z6l9v1x0BzHFwpr0zXL4afpM9weqqcV4pJIZpXkYkljnmvOzCraKh3PbyWhzVHVfQSiiivHPpwooooAKKKKACiiigBK9D+Hmm7YZr515Y4Q+1efxRtNMkSjJYgYr2vRbJdP0u3t1/hQZrtwFPnqXfQ8rOK/s6HKt5Ghiloor3D5IKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAQ9K8++I0Mha3mx8gGM+9ehGqOpadb6pZvbXCBlbv6H1rGvT9pTcF1OjCV1QrRqPoeHUtdPq3gfUbF2e1X7TB22/eH4VzcsMsLFZYpIyOzKRXz86c4O0kfaUq9OtG9N3GUUmfelqDYKKKKACiigAscKCT6AUAFJmtGy0HVL8gW9nKQf4mXaPzrrdI+H2HWTU5twHPlR/1Na06FSp8KOavi6NBXnIwfC3h+bV79JXQrbRtlm9TXrkaCNFQdAMCo7W1hs4VhgiWONeAFGKnr28Nh1Rj5nyuPxrxU9NEtgooorpOAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAIbqbyLWWX+4pNeH6hdvf381y5JLsTXtOrIX0q5Veuw14bggkHsTXmZlJ2S6Hv5FCLc5PfQBS0UV5J9GFHSikoA6Xw14Ul1sied2itQeo6t9K9AsvCukWKAJZxuw/icbjVHwVf29zokUMZUSRcMvcV1Fe3hMPTUFK12fJ5jja7qyp3sl0Kh02zK7TbQ49NgrNv8AwjpF8h3WqxuejR/KRW7SHpXU6VNqzR58cRWg7xk/vPH/ABF4am0KUMGMtsx+V8cj61hCvS/H9/bppP2MkGaQ5AzyK80HSvExdKNOpaJ9ZluIqV6HNU3/ADCiiiuU9AK0NCvn0/WbeZWIXdhh61n0+3RpLqJF+8XH86cW000ROKlFxezPd433xq/94A1IKr2oK2sIPUIP5VOK+mi20mz4KaSk0haKKKokKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKDTHkEaMzdFGTQBwvxD1LbDDYIcFjuOK89ArU8RX51HW55c5QNhazK+fxdTnqtn2eXUPY4dJ7vUKKKK5jvCiiigAooooAKSloCliFH3icCgDrvBGhQalJNc3UIliX5QrdM16BHo2mxjC2UA/wCACqvhfTxp+iQR7cOw3P8AWtnFe7haEY01danx+YYypUryUZNJaFP+zLH/AJ9IP++BTH0fTpBhrKAj/cFX8UYrp9nDscPtqn8z+8wp/CGiXAO6yVSe6Eg1gaj8O4iC2n3LKeyScj867zFBXNZSwtKe8Top5hiae0n8zw3UNMu9LuDDdxFG7HsfpVOvatd0iHVtOkhkUF9pKNjoa8YmiME8kJ6oxWvIxWG9i9Nj6XL8csVF3VpIbRRRXKeiFFFFABRRRQAUUUUATWd09leRXEZ+ZGBFe22Fyt3Ywzqc7lBP1rws1614JmM3hyEsckcV6OXTam49DxM7pJ0lUW6OkpaQUtewfMBRRRQAUUVG8yR/fdVz6nFADzTJIklUq6KwPYjNN+0w/wDPVP8AvoUfaYf+eqf99Ck7PcautjPn8O6Tc/62whY+u3H8qpv4L0N/+XPb/usRW59oh/56p/30KPtEP/PVP++hWToUnvFG8cXXj8M395zx8B6GT/qZf+/hoHgTQx/ywkP1kNdD9oh/56p/30KPtEP/AD1T/voVP1aj/Ki/r+K/nZix+DNCT/lyVv8AeYmrsOhaXbf6qxgX/gOau/aIT/y1T/voUoliPSRT+NUqNJbRREsVXlvN/eOSNY1CoiqPQCn00OD0INLnmtkrHO23uLRRRQAUUUUAFIelLTJXEcbOxwFGTQBwfxD1LCQ2MbYbO5h6iuAFaXiC+bUdZuJicqGKqfas2vn8VU9pVbPtMvoexw8V1eoUUUVzHcFFFFABRRRQAUUUhOBmgDo/BWnfbtdWUjKQfMa9aUAVyfgTTTaaQZ3XEkpzn2rrRXuYGnyU7vqfI5vX9riLLZaC0UUV2nlhRSE4pN1ADqKjaeNDhpEB9CaT7TD/AM9U/wC+hQBLRUX2mH/nqn/fQo+0w/8APVP++hQBLRUX2mH/AJ6p/wB9Cj7TD/z1T/voUAS0VF9ph/56p/30KPtMP/PVP++hQBLRUX2mH/nqn/fQoFzCTxKn/fVAEtFNDhumDS0ALRRRQAUUUUAFFITgVGbiJSQ0iAjsTQBJVeezt7gYmhjkH+0oNP8AtMP/AD1T/voUfaIf+eqf99Ck0mtRpuLujLl8LaLMSX0+LPqOKqt4H0N+fszL/uuRW99oh/56p/30KPtEP/PVP++hWToUnvFHRHGYiO0395zv/CB6H/zxl/7+Gnr4G0NT/wAe7n6yGt/7RD/z1T/voUfaIf8Anqn/AH0KX1aj/Ki/r+Kf22Y8fhHQ4zxYRk/7RJrQh0qxt8eTaQpjuFFWPtEJ/wCWqf8AfQpwljPR1P41UaNOOyRlPE1pfFNv5jwoHQUtNBz0p1amG4UUUUAFFFITgUALTScZzwBTJp44ImkkYKijJJ7V5p4m8ZTX8j2tgxjt84Ljq/8A9asq1aNKN5HRhsLUxE+WCPRze2oODcRZH+2KPttr/wA/MP8A32K8Ky394/nRlvU1wf2kv5T2P7Cf8/4Huv221/5+Yf8AvsUfbbX/AJ+Yf++xXhWW9TRlvU0f2kv5fxD+wn/z8/D/AIJ7r9ttf+fmH/vsUfbbX/n5h/77FeFZb1NGW9TR/aS/l/EP7Cf/AD8/D/gnuv221/5+Yf8AvsUfbbX/AJ+Yf++xXhWW9TRlvU0f2kv5fxD+wn/z8/D/AIJ7r9ttf+fmH/vsUfbbX/n5h/77FeFZb1NGW9TR/aS/l/EP7Cf/AD8/D/gnuv221/5+Yf8AvsUfbbX/AJ+Yv++xXhWW9TRlvU0f2kv5fxD+wn/z8/D/AIJ7st3bMcLPGT7MKlDA9DkV4KGdejsPocV0nhPXNQh1eC1ErywyNhlY5xV08wjKVmjKtktSEXKMr2PWB0paRelLXoniBRRRQA2RQ8ZVhkEYIrx7xTpEmlatJ8v7mQ7kI6D2r2M9KzdY0i31eya3uF/3W7qa5sVQ9rCy3R3ZfjPq1Xmez3PExRWprOgXmizlZULQk/LIBwfrWVmvBlFwdpH2FOpGpHmg7oWiiipNCa1vLmxnE1tM0Ug7g11dl8Q76FQt1bxzf7QODXHUYranXqU/hZzV8JRr/wASJ6AfiRFjjT5M/wC+Kzb74gahcIUtoY7cH+L7xrkaMVrLG1npc5o5VhYu/Lf5klxcTXUzTTyNJI3JZjUdJilrlbbd2ehGKikkrIKKKTNIoK6bwXor6jqq3TqfIgOcnoTVTQfDV5rUysEMdsPvSEdfpXq+nadb6ZaJbW6BUUfnXbhMM6kuZ7I8rMsfGhBwjrJ/gWwuBilFLRXuHyQUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAIawvFmo/2fokzKf3jjao9a3TXmfxA1IT38Vkh4iGTj1rDE1PZ0mzrwND21eMOhxxOST680UUV87e+59stFYKKKKBhRRRQAUUUUAFa3hrT/7S1uGIg7FO4n6Vk9q9E+HuneXayXzjPmHC57Vth6ftKiicuNrexoSmdvGoVQo6AYp9IOtLX0Z8P5sKKKKACiiigBr/AHT9K8R1og6zdFem817NqVytpp887HhEJrw+4k866mlz99i1ebmT91I93I4vnnLyI6KKK8g+lYUUUUAFFFFABRRRQAh716r4DUjw5GT3NeVdePWvZPC9obPQbaMjHy5/Ou7ARftTyM6lbDW7s2hS0gpa9s+UCiikNAATivKPG2ptd60YY3by4eAQe9ekateLYaZPcH+FeK8UmlM9xJMSSXYtzXn5hU5Yci6ns5Lh1Oq6ktl+Ynmyf89G/M0ebJ/z0f8AM02ivI5n3PpuSPYd5sn/AD0f8zR5sn/PR/zNNoo5n3HyR7DvNk/56P8AmaPNk/56P+ZptFHM+4ckew7zZP8Ano//AH0aUTSjpLIP+BGmUUc0u4uSHY09P8Q6np06vHdSMgPKO2VIr17S74ajYRXIBG8civDlUs6KBklgK9v0a2+yaXbw+iivSy+pOUmm7o8LOqNKMIyirSZfooor1T50KKKKAErA8Xal/Z+hzMD87/KB9a3jXmXj7UhcalHaI3ywj5h61hians6bZ14Gj7avGBx49+tLRRXzp9utNEFFFFABRRRQAUUUUAFWNPtTe38NuBnewBx6VXrsPh/p3n6hJesPljG0Z9a0pQ55qKMcRVVGk5voj0a1t1tbWOFRwi4qelor6SKsrHwkpOUnJ9QoopppiFPSsDxH4jg0S2IBDXLD5EH8zUXiTxRBo0JijIe7YfKvp7mvLLu7nvrl7i4cvIx5JrixWLVJcsdz1Mvy6WIfPPSP5jrq/uby5a4nmcuxz948VD5sn/PR/wDvo02ivGc5N3bPqo0oRVkh3myf89H/ADNHmyf89H/M02ilzPuVyR7DvNk/56P+Zo82T/no/wCZptFHM+4ckew7zZP+ej/maPNk/wCej/mabRRzPuHJHsO82T/no3/fRo82Qf8ALR/++jTaSlzPuHs4vobGj6/f6bexFJ5HiLAGNmyDXsUL+ZEjn+IA15x4S8Jy3MyX96hWFeUQ/wAXvXpIG0ACvYwCqcrctj5fOJUXUUaaV1vYfRRRXoHjhRRSGgCC8nW2tJJnOAqk5rxK+vpby/muGdgXYnG6vRvHmpfZdJFsp+aY4rzCvKzCq7qCZ9FkuHTjKrJb6DvNk/56N/30aPNk/wCejf8AfRptFebzPue9yR7DvNk/56N/30aPNk/56N/30abRRzMOSPYd5sn/AD0f8zR5sn/PR/zNNoo5n3Dkj2HebJ/z0f8A76NOW5nQ5SeRT6hzUdBo5n3F7OHY6nwz4pv7bUI7e5meeCQ4+c5I/GvVFO5QfWvGPDFqbvxBbx44B3H8K9nUYUD0r18BOcovmZ8znNKlTqLkVmxaKKK9A8YKa5CoSTwKCea5Lxrr39n2f2OFh58w59hUTmoR5maUaUqs1CO7Oe8ZeJmvp2sLVyIEOHYfxGuQFHJ5OSe5NWrS0S6Yq13DAf8AprkA18/VqyrTufaYahTwtJRXzK1FdBF4SknGYdUsH+klTf8ACC6m33JrV/pJR9Xq/wAofXcOtHNHM0V0jeBNbA+WKJvpIKgfwZrqdbMH6SA0nQqL7L+4pYug9pr7zCorWk8Ma1H10+U/7vNVpNG1KL79hOP+AGocJLoaKrB7SX3lKipGtrhD80Eq/VDUR+U88fWlYtO+wtFJmikMWikqzYafdalcrb2sZdyfwHuaaV3ZCbSV2QojyuqRqWdjgAd69L8IeFv7MT7ZdgG5ccL/AHRVvw54UttHRZpQJLsjlz2+ldJkKCTwK9XC4LlfPU3PnMxzTnTpUdurFXpTZJEiQvIwRR1JOAK4fxX8TNL0EvbWhF5egEbVPyofc149r3jDWvEUjG8umEJ6Qxnag/xr0zwT3LUviJ4Z0xzHJqSSSD+GEb/5cVHp/wASfDOoyiNdQELngCZSv6185gYpaAPrSGaOeMSRSK6HoynIqSvl3RvE+saBKH0+8kjUHmNjlD+Br1fwz8WrG/KW2sRi0nPAlH+rJ/pQB6JcW0N1C0U0ayIeoYVxWteAEfdNpbbG6+Ux4P0ruYZ4riJZYZFkjYZVlOQRUh6VjVoQqq0kdGHxVXDu9N/I8HurO4sZzDcxNG47EVDXtup6PZ6tAYrqEN6N3H0Neca74NvNLLS2wNxb+o+8o968mvgp09Y6o+lwea0q/uz92RzNFJ3pa4j1QooooAKKACxCqCSegHeus0HwPdX5We/zBAedg+8f8KunTlUdooyq1qdGPNUdkc5Yadd6lcCG1haRievYfU132jeAra2Czai3ny9dg4Uf411Wn6ba6bCIbWJUUenU1dr1qGAjHWerPnMXnFSpeNHRd+pFFEkMYjiRUReAAMAVJS0V3pJaI8Ztt3YUUUUxBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRSUAQXlwtrayTv0RSa8S1C6a91Ge4Y53OSD7V6P471P7JpHkI37yU4x7V5cOBxXk5jU1UD6PJKFoyqv0FooorzD3wooooAKKKKACiikNAEkETXFxHCgyzsAK9s0iyWx0yCBRjaoz9a808E6d9t1sSuPkhG7PvXrI6V6uXU95s+dzyvrGivUAKWiivUPnwooooAKQmjNct4l8W2+lRPb27CS7IwAOQv1qZzjBc0i6dOdWShBXZm+PdcWOAabA2Xf7+D0Hoa88AxUk88t1O80zl5HOSTTK+fxFb20+bofZ4HCrDUlHr1CiiisDsCiiigAooooAKKKQnFAGholidR1eCAKSu7Lewr2uKIRRIg6KoArjfAmhm1tTfzpiSUYX6V2w6V7WApcsOd9T5XOMSqlVU47RExS0UV3njhSGlpsjBELE8AZoA4b4hal5dtFYxth3+Zh7V54OlaviXUG1HXJpCcqh2qfasqvn8XU9pVbPs8toexw6T3eoUUUVzHeFFFFABRRRQAUUUUAbXhTTzqGuwjGUjO569iUBQAOg4rjPh/pvkWD3ki4kkOB9K7QV7eAp8tPmfU+Tziv7SvyLaItFFFdx5IUUUUAVr25S0tJZ3OFRSa8Rvrl7y/muHOWZjz7V6N491L7NpQtkPzTHBHtXmIGK8nMal2oI+jyShaMqz66C0UUV5h74UUUUAFFFFABRRRQAYyQo6ngV6/4S07+z9DhVlxI43NXmfh+wOo61bwlcpuBb2r2eNBGioOijFell1O8nNnhZ3X5YRpLqSDpSE4oHSobm5htYGmnkVEUZJY16580vIl3CuN8T+M47IPaWDCSc8M4PCVjeI/G0l5vtdOJjh6NL3b6VxuSSSSST1zXm4nGpe5T3PdwGUuTVSurLsPmmkuJmllcvIxyWPem4pKWvJbbd2fRxSS5UFFFFIoKKKKACiiigAopK39E8J3+sMHK+Rb/wB9hyfoKqEXN2SM6lSNOPNN2RiwQTXMyxQRtJI3RVFd/wCG/BAgZLvUwGkHKw9l+tdJo/h+x0aILbxAyfxSNyxrW7V6uHwPL71Q+exucOd4UNF3GqgUAKAAOgFOxRS16R4T11YCiiigAppODTqzdbvV0/S7icnDBTt+tJuyuOKcnZHmfjLUft+uOqNmOIbQPeueAp8kjTSvK/3nO402vm60/aTcj7rDUVRpRproFFFFZm4UUUUAFFFFABQaKVI2lkWNBlmIAFAHd/DzTj++vnHB4Q16COlZmhWKafpFvCox8oJ+taY6V9Dhafs6SR8VmFf22IlLpsLRRSGug4ive3KWdtJPIQFQZ5rxq9uZdc1eWZ5Y49zHb5rYAH1rsfH2tbIhpkLfM/MnsK89rycfWvJU1t1Po8mwrjF1nu9jcj8K38v+rmsm+lwKlPgvWcZEUTf7soNc+CVOQSD7VMl5dRnKXMy/RzXEnR6p/wBfI9VrE/ZlH7n/AJmq/g/XE/5cy3+6wNN/sHxDB92zu1A/uH/A1Wj17VovuahcL/wOrKeLNcj/AOX+Rv8AeANWnRWzaMpLFPeMX9/+QD/hJLX/AKCC/wDfRpw1/wAQwcm5ulx/fT/EVMvjfXFH/HxGfrGDT/8AhONVP30t3+sYq1OPSo/u/wCCZOlN/FRi/n/wCNfGuuRnBuVP+8gqZfH2tD7xgYe8dRt4vmkGJdOsnz6x1n3eqw3Skf2ZaRMf4owQabrTW1QSwtKTtKhb5o2h8QNQIxJaWz/Vaa3jUyf63RrJ/qv/ANauUpayeJqvdnQsBh18Kt83/mbs3iCxn+/oFpn1VyKyLqWGaXdDB5C/3Q5YVBXVeG/B82qMtzeAxWvUDu9SnOtLlS/AqUaWGjzybt5tszNE8PXetzgRKUgB+aUjivVNH0O00e1EVug3fxORy1XLW0gs4Fht41SNegFYfivxjYeFbMvOwe5Yfu4VPLH39BXr4bCRpK8tWfN47Mp4h8sdI/n6mtqWq2Wj2jXV9cJDEo6sevsK8S8X/E2+1wyWmmFrWx6FgcO/+ArmfEXibUfE181xeyny8/JCD8qCseuw8wOSSSck9SaKKKACiiigAo60UUAdJ4Z8bat4ZmAhlM1rkboJDkY9vSvcvDPjLS/E9sGtpQlwB88Dn5l/xr5pqazvLjT7pLq0meGZDkMpxQB9ZDmkZQwwcEe9eYeEvixa3aR2muHyLjgCcD5G+vpXpdvcw3cKzW8qSxtyGQ5BoA5rXvBVpqW6e2xBcew+VvrXnOpaVeaTOYruFk9G/hP417gRxVW8sbe/gaG5hWRCMYYVxV8FCprHRnq4PNalC0Z+9H8TwvNaWlaJfazMEtojs/ikI+UV3Mfw9sU1AzNM7W+ciH/69dbbWsFpCsUESxxr0VRXHSwE2/f0R6eIzmlGP7rV/kYOheELHSQJHAnuepdh0PtXRhcdKWlr1adKNNWij52viKleXNUdxAKWiitDEKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigApp4HNOrO1m+XTtKnuHPRTj60m0ldjSbdkeZ+NNR+3660an5IRtHvXPU6SRppnlc5ZiTmm183Wn7SbkfdYaiqNKNNdAooorM3CiiigAooooAKQnAzS0UAeoeBrKOz0fzWZd8x3cnnFdYGB6YrwZJ5ov8AVyyJ/usRVhdU1BPu31yv0lNenRx0KcFHlPAxWU1a9WVTnWp7jmgsB1IFeIf2xqmP+Qjdf9/TTH1K/k+/e3DfWQ1r/aUOxzrI638y/E9rmvrW3XM1xGg/2mArCv8AxtpFmCI5zcSD+GMf1ryhndzl3Zj6k5puKynmL+zE6KeRRX8Sd/Q6fVvG+o6gGit8W0J4+X7xH1rmSSzFmJJPJJOSaKK4aladR3mz16GFpUFamrBRRRWR0BRRRQAUUUUAFFFJmgArpPCfhyTV7sTzKRaxkEk/xGm+G/C0+szrLMrR2gOSxH3vpXqtpaQ2VukECBI0GAAK7cLhXUfNLY8nMcxjQXs4P3vyJI0WNFRAAoGABUlJilr20raI+Ubu7sKKKKYhKxPFOpDTtDmkB+ZhtA+tbR615t8QdR828jskbiPlh61jiKihTcjqwdH21eMOhxeSSSTkmloor5y9z7jToFFFFABRRRQAUUUUAFS2tu11dxQKMmRgvFRV1XgTTfterG5YZSEenerpw55qJlXqqlTlN9Eekadaiz0+C3XgIgFXKQDilr6WMeVJI+EnJzk5PqFFFFMkKaxA5NKazNdvl0/SZ5ycHaQPrSbsrjinJpI8z8Y6j9v12QKx2RfJjtWDSyO0srSOcsxyTSV83Vn7Sbl3PusNRVGlGC6BRRRWZuFFFFABRRRQAUlLSxxtNMkSfedsCgDv/h5pwWKa/Yff+Vc9q7zNYdpNZeHdDgS5lSLagLA9Scelchrnju4u90OnAwRdPMP3j9PSvcpyhhqK5j5LEU6uOxMnTWm3kddrfiiw0ZCrOJJ+0a9fxrzPWNfvdamLTvtiz8sS8AVmuzyOXdiznqxOSaSvPxGMlV0WiPZweWU8P70tZBRRRXGeoFFFFABRRRQAUlLU1rZ3N9MIraB5XPZR0oE3bcgq9pukX2rTCO0gL88seFH412OifD8ZWbVXyevkr/U13NtZwWcIit4kjQdAoxXdQwM56y0R5GKzelSvGn7z/A5fQ/A9pp+2e8/0i464P3V/CusRQgCqAAOwp2KWvWp0YU1aKPnK+Kq15c1RhRRRWpgFFFFABRRSHpQAZrgfiHqX7uKwQ/e+Y4ru5HCRs56KMmvF9fvzqOs3E+cpuwvtXHjavJTt3PTymh7XEJvZambRRRXhH14UUUUAFFFFABRRRQAVveD9O+367GSPkh+fNYBOK9P8A6Z9m0s3Lj55jkH2rowtPnqpHHj63scPKXXY60LgY9KeKTFLX0J8SFQXUy29tJM3RFJqc1T1O3a706eBDhnQgUntoOKTaueL6ndvfalPcO27cxx9Kq1ZvNPu7Gd4p7eRNp6lTg/jVXNfNTbcm5H3tKMYwSjsLRRRUGgUUUUAFFFFABRRmkzQAtKiPLIqRqWZjgKOSams7K41C5W3tomd2PYdPrXqPhzwnbaPGJpQJbojliPu/St6GHlVemxyYvGU8NG89+iMjwz4J8vZeamoL9Vi7D613KqEUKoAAp2QoySMCvKfiD8R/szSaTo8n777ss6n7vsPevco0IUo2ifI4rF1MTLmm/ka/jb4kWuhI9lpxW4vyME/wx/X3rw+/v7rVLt7u9maWZzksx6fSoGZncu7FnY5LMckmkrY5gooooAK09F8Pan4guRBp1s0n95zwq/jSeH9LGta7bWJcIsjDcfbPIr6X0nSbPRrCK0soUjjQY4GCfc0AedaL8GrSNFk1i8kmfvFD8q/n1rqYfhv4WhTaNLVvd2JNdWBiloA4XUPhP4avEPkwy2snZonP8jXmniX4Z6xoZaa2Q31oOd8Y+YD3FfQtIVzQB8jsCrFWBVgcEEYxRX0nr/gPQvEKs1xarFcH/lvCArfj615Zr3wm1jTS8umsL+EfwqNrgfTvQB58a0dM13VNHkD6fezQH0VuD+FVLi2uLOYxXUEkMg/hkUg1FQB6FYfGDX7YBbuC2ulH8RUq36cVvQfGuAgCfR5FPqkuf6V4/RQB7UPjRpeP+QddZ+oqtcfGuAf8e+kSN7vKBXj1FAHplx8aNVY/wCj6ZaJ6b2Y/wBazZ/i34nlz5bW0Of7sef51wtKoZzhFZj6KM0AdVL8SfFk33tT2/7kYFUpfG3iWX72sXQ/3WxWfFouqzLui027dfVYW/wqK406+tf+PiyuIh/txEUAaH/CW+Iv+g1e/wDf010vgbxf4guPFdlZzajNcQSth1kO7iuAzXr/AMKfCE0BOt30ZTcMQow5+tAHrQpaKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKQ0ALXBfELUtsMVjG33jlx7V3MjiNGZjgAZNeMeIr86jrk8p6Kdg+lceNq8lLzZ6WVUPa4hPojLFLRRXhH2AUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFSQW81zII4Inkc9lGa6rSfAN9dFZL9vs0R/hHLH/CrhTnN2irmVWvToq9SSRykUMtxKscMbO7cBVGTXdeH/AZylzquPVYQf511ulaFYaRHttYQGxy55Y1qCvUoYBRfNU18jwMXnMpJwoaLuRRRRwxqkaBVUYAA4FSClor0UklZHhNtu7CiiimIKKKKAILqdbe2kmc4CKTXiWp3j3+pz3DnJZjj6V6T451L7HoxgU/NP8v4V5WOABXk5jV1UEfRZJQspVn6IWiiivMPoAooooAKKKKACiikoADXrXgzThY6JGzLiWX5mrzTRbI6jq0FvglWbn2r2uKMRwpGOigCvRy+nebm+h4edV+WmqS6ktFA6UV7B8yFFFFACGuA+IepfLDYIchuXFd7K4jjZ2OAozXiuvX51HWbi4zxuKgfSuPG1eSlZbs9PKaHtcQm9o6mdRQKK8I+vCiiigAooooAKKKKACpLed7WdZo8eYhypIzg1HRTTsJq+jJ7y9ub+Yy3UzSOf7x6fSq9LRRJuTuxRhGEeWKsgooopFBRRRQAUUGp7Sxur6URWsDyueyimk3sJtLVkFSW9tPdzCK3iaVz2UZrtdI+H0j7ZNTl2Dr5UZ5/E12+n6XZ6ZGIrSBY19QOT+NdlHA1J6y0R5eJzajR0h7z8tvvOG0f4fyy7ZdTk8tP+eSHn8TXc2GmWemwiO1gSNR6Dk/jV6ivUo4anS2Wp8/icfWxD952XZbDQOadRRXQcQUUUUAFFFFABRRRQAUh6UtIelAGB4u1H+z9DlKtiRxtWvIc5yT1JzXX+P8AUvtGox2an5Yhnj1rkB0rxMdV5qnKuh9Zk9D2dDne8gooorhPWCiiigAooooAKKKKAJ7K2e8voYEGSzDivbrK2W0tIoEGFRcV5x4B077Rqb3jLxCMKfXNenivXy6laLm+p81ndfmmqS6C0UUV6R4QGm4p1FAETwxyqVkjVgeoIzWTc+FtFuiTJYRhj3XI/lW3RUSpwl8SNIVqkPgk0cnJ4A0aQ5UTJ7LJVZ/hzp5+5dTr9cGu1orF4Si/snTHMcVHaZwTfDaH+HUJB9UFRt8Nj/DqH5pXoGRTJp4bdC80qRoOrOcCp+o0Oxos2xf834I8/Pw3m7agn4pSf8K3uP8An/j/AO+DW5qPxC8MaaWWXVI3cfwwguf04rnLv4zaPHxa2V1P7kBP50vqFHsX/bGK7r7i0nw2Of3moY/3UrQtfh7pkRBnklmI7ZwP0rkJvjXJk+To647b5P8ACoP+F16hn/kEW2P+ujVUcFRXQznmmKl9q3oetWWl2WmoEtLaOIew5P41cwK8gi+Ncuf32jqf9yT/ABrVtPjNo8pH2qyuYPcAP/KumMVFWSOGc5Td5O7Nr4jarf6X4Ymawjcs42tIozsFfO5YuSzMSxOSTX0nYeOvDGsL5cepQ7m4Mcw2/wA+Kq6l8O/C+tgzi1ETvz5ls23P9KZJ870V6/e/BSI5Nhq0g/2ZkBH6Vg3Xwf8AEUJPkS2s4/39v86APPqK6m4+HHiu3OP7KeQesbqf61mz+Fdfts+dpF2uPSMn+VAGZBPLbTpPA7RyocqynkGu+0z4v65ZRLHdwQXgUY3H5GP1xXDyabfxf6yyuU/3omH9KrsjocMjL9RigD12D42RYH2jR5Pfy5Af51pW/wAZtCkP760vIfqob+Rrw7NGaAPoS3+KnhacgfbJI/8ArpERWtbeNPDt4wWHV7ViexfBr5lpCAeooA+sob22ueYbmKTP9xwanwK+SoppYG3QyvGfVGI/lW7p3jjxHpePs+pyso/gm+cfrQB9EanoemavEY7+yhnU/wB9efz61x958IfDlwzNAbm3J6BJMqPwNQ+BPiQ/iG7/ALN1KJI7wjKPGPlf/CvRhQB5TJ8FLYnMesTL7NEDUY+Cceedaf8A79D/ABr1uigDyqP4KWanMurzuPQRgVoQfB3w/H/rpbuU/wDXTAr0WjIoA5K0+G3hS1wRpSSMOjSOx/rW7a6HpVlj7Np1tFjoVjGasXN/aWUZe6uYoVHeRwK5fUPiZ4WsCR/aHnsOCsKFqAOuCKOigfhTJreGeMpLEjq3BDDNeZ3Pxp01CRa6bcyjsWIWs2X413GT5Wjx4/25DQB17fDPQG18ap5GFHP2cfcz612SRpGgRFCqBgADgV4yPjXqHfSLbHs7Vah+Nh/5b6OT/wBc5f8AGgD16ivObP4xaDMQLqC5tz6lNw/Sup03xj4f1bH2TVIHY/ws20/kaAN2ikDKRkEEeopc0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSGlpDQBheLNQGn6HM+cM42r9TXj/ACeSck9TXY/EDUvPv47NGykY+Ye9cdXiY+pzVOXsfV5PQ9nQ53vIKKKK4T1wooooAKKKKACiiigAorrPCPhm21mGWe8VtinauDjmt+T4d6YxJSe4X23Aj+VdMMJVnHmitDgrZlh6NR05vVHmlFehP8N4D/q7+QfVQagPw2f+HUR+MdDwddfZEs0wj+2cJRXcH4bz9r+P/vg0f8K3uP8An/j/AO+TS+q1v5S/7Rwv86OHoruR8N5u+oJ+CVIvw25+bUc/SOn9UrP7InmWEX2zgqTNekR/DiyH+su52+mBV6DwFokWN8Ukp/2nP9KtYGs+hlLN8Ktnf5HlOasQWV3dHEFtLIf9lCa9ht/DukW2PK0+EEdCRk/rWisMcYwiKo9hito5bL7UjkqZ5BfBBs8qsvBGsXeDJGtuh7yHn8q6XTvh5YwkNeTvcEfwgbRXZ4pR1rrp4GlHfU8+tm+IqaR91eRVs9Ms7BAlrbxxD/ZXmrO2nUV1RjGKtFHmznKbvJ3YgFLRRVEhRRRQAUUUUAFITig1Q1e8Wx0ye4Y4wvB96TdlcaTbsjzXxtqX27W2iVvkgyuPeuap80zTzyTPyzsSabXzlafPUcj7nC0fY0Yw7BRRRWR0BRRRQAUUUUAFJS0KhkdY1+8xwPrQB3Xw703c81+44+6uR3r0PFZXh2wXTtHghAwxXLfWtavoMLT5KSR8XmNf22Ib6LQKKKK6ThCkzzS0lAHP+MNSFhoUoBxJJ8q815Dknk9Tya67x7qX2jU0tEbMcQyfrXJV4mPq81Sy6H1mT0PZ0OZ7sKKKK4T1gooooAKKKKACiiigAorofC/h5dcNx5uVRV+Rge9ZOp6dPpV89tOuCp4PYir9nLk57aGKr03UdK+qKlFFFQbBRRRQAUUUUABrb8P+JJ9DmxtElux+Ze49waxKSqhJwfMjOrSjVg4SV0z2/TNVtdVtVntpAwPUZ5FXh1rxDS9Wu9IuhPayEc/MnZhXq+geILXW7cNG22ZR86HqDXt4bFxq6PRnyePy6WGfNHWJtUUUV2HmhRRRQAUUUUAFFFFABRRRQAmar3t0tpZyzt0RSasVyHjzUja6ULaNsSSnp7VFSahFyfQ1oU3VqRprqecX1y17fzXBYne5I+lQUgGBilr5qUnJts+7hFQioroFFFFIoKKKKACiiigApCTxSmtLQLBtR1q3hAyocF/pTSu7ClJRXNLZHpnhHTf7P0OIMPncbifrW+BTYkWOJUUYCjAp9fSUockFE+ExFV1aspvqFFFFaGIUUUUAFFFBOBmgBCcVla14k0vw/bmbULpI+OEzlm+grjPG/wATYdIZ9P0krNe9Gk6rH/ia8Xvb+71O6a5vZ3mmY5LMf5UAej698Yry4ZotFthbx9BNL8zH6DoK8/1HW9U1aQvf39xOT2dzj8ulUKKAExS0VLb2tzduEt4JJWPQIhNAEVFb0HgrxLcDKaPcjP8AfXb/ADqR/AXiiNdzaRMR7YNAHO0VevNF1TT/APj70+5hHq8ZFUc0AGK1tJ8T6zokgax1CZFH/LMsWU/gayaKAPZvDPxft7p0ttchFvIePPQ/IfqO1enQXEN1Cs0EiSRuMqytkGvkvFdZ4N8c3vhe8SN3abT2IDxHnb7igD6MxxRiqmm6jb6rYxXlrIHikGQRVygBjRI/3kU/UZqFrC0f71rA31jBqzRQBmTeHtHuAfN0y0bPrCv+FZN78OvC96pDaXFEx/ih+Q/pXU0UAeMeJ/hG9nbvdaLcvKqDJgl649jXlzAqxVlKsOCCORX1df3UNlYzXE7BY0Uk5NfLerXUd7rF3cxDEckhKj2oAqUUVJb28t3cx20Cl5ZDhVHegDsfhbp0t54vinVT5UIO9h2NfQY6VzHgjwtF4Z0VIyoN1KA0r9yfSuooAKQnFNklSGNpJGCooySewryDxr8U5HeTT9Bfaoyr3OOT/u0Ad/4h8b6L4bQi7uA8/aCM5c/4V5Vrvxb1nUGaPTY1sIezA7n/AD7VwEssk8rSzO0kjHLMxyTTaALF3f3moSmS8uprhz1Mjlqr0UZHegAoqza6bfXzbbS0nnP/AEzjJrYh8C+J5lyukXA/3higDnqK6GXwL4mhGW0i4I/2Rmse706+sGK3dpPAR2kQigCrSjKnIJB9R1oooA6HRfG+v6Eyi3vpJIR/yxmYsv8A9avV/C3xT0zWSltqCiyujwCzfIx9j2rwek6c96APrhXDAFSCD0Ip1eF+AviLcaVPHpuqymWzY7UkPVP/AK1e4RSpNGskbBkYZVh0IoAkooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqC7nW2tZJmIAVSeamzXJ+PNT+yaP9nU4eY44qKkuSLkaUabq1FBdTzbUbtr7UZ7luruar0g6UtfNylzO7Pu4QUIqK6BRRRUlhRRRQAUUUUAFCqZHVF6uQooNbXhTTv7Q12FWXMaHc3tiqjFyaSIqTUIOT6Hpvh2w/s/RreEjD7ct9a1hSKu1QB0FOr6SnBQioo+Eq1HUqOb6hRRRVmYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAhrhPiHqW22isUOfMOW9q7qRgqFj0AzXjHiPUP7S1ueYH5QdoH0rkxtXkpPuz0sroe1xCb2RldqKKK8E+wYUUUUAFFFFABRRRQAVt+E9OOo67EGXKR/OT71idq9K+H+nfZ9Oe7YfNMcjPpW+Gp+0qJHHjq/saEpdTslGMCnU0dadX0R8SFFFFABVW9uVtLOWdsDYpPNWc1x/j7U/s2mLaI2JJj+lRUmoQcma0KTq1FBdTzi9uWvL6a5brIxNQ0gpa+abcndn3cIqMVFbIKKKKRQUUUUAFFFFABSH260taOg2LahrVvABkBgzfSnGLk7ImUlFNvY9M8Iab/AGfoUQI+aT5j+NHinQU1nT2KjFxGMowH6VuRoI41RRhVGAKfivoo0Y+yVNnxFTFTeIddb3PBZI3hlaKRdrocMKbXb+OtB8qX+0rdPlP+sAHT3rh814Nak6U+Vn2GFxEcRSU4i0UUVkdIUUUUAFFFFABU9le3Gn3KXFs5WRf1+tQUU02ndCcVJWZ6/wCHPEcGt2oyQlyo+dP6it4dK8Js72fT7tLm3crIp7d69c8PeIIdbsg64WZBh0z0Ne1hMUqi5ZbnymZZc8O/aU/h/I26KQHNLXceSFFFFABRRRQAUUUUANJAyfSvI/GWo/b9ddQcpD8qmvTNcvl07Sbi4PZTivFHkaWRnYkljnJrzswqWioLqe5klDmqOq+glFFFeOfTBRRRQAUUUUAFFFFAAeld/wDDzTcLNfuuCflX6VwMaGaVIgOXIWva9DsRp+k28A6qgzXbgafNVu+h5Wb1/Z4flW8jSHSigUV7h8kFFFFABRRRQAZrzT4meODpMB0nT3/0qUYkcfwD0+td7q98mnaXcXTnAjQkfWvl7U9Qm1TVLi9nYmSVyTzQBVJZmLMSzHkk96KKKACtXQfDmpeI7wQafCWA+/IeFX6motD0mbXNYt9PgB3SH5j6L3r6U0DQrPQNMjsrSIKFHzNjlj6mgDkNA+EukacqS6kWvrjqQ3CD8O9d3a2NrZRiO1tooUHZEAqzRQAUUUUANdFdCrKGB6gjNcnr3w60HXEZvswtbg9JYBt59x0NddRQB8zeKvB+o+FbvZcr5lu/+rnUcH6+lc/X1H4j0i31vRLm0uIwwZCVyOh7V8w3ds1nezWz/eicqaAIqPaiigD0r4S+JXtNTbRp3zBKN0eTwpr2+vlPRbh7XXLKWM4PnKD9M19UwtviRvVQaAH0UUUAFIzqilmIAAySaGYKMnge9eQfEj4g7jJouky+qzzKf0FAGZ8S/HB1a5bSNPk/0SJv3jqfvmvOaPr1ooAM4r1/4WeDDEo1y/j+dh+4Rh0HrXI/D7wfJ4k1VbidSLG3IZiR94+lfQkMKQRLFEoRFGFUDgUAPFBIAyelLXNeOdaOh+GrmdG2zOuyM+9AHnHxO8cSXly+i6dKRbp/rnU/ePpmvMQMU5naV2lc5dzuY+5pKACkpa6TwR4YbxPrqwPkW0Xzyn1HpQAeF/BOq+KJgYE8m1B+adxx+A717BoXwy0DR0V5YTe3A6yT8jPsK6yysoLC0jtraJY4owAqqMCrNAEUMEcEYSKNI0HQKMCpaKKACoZ7aG5jMc0SSIequoINTUUAcD4k+Fmj6sjy2C/YbrqDH9xj7ivFdb0O+8P37Wd/EUcfdYdGHqK+qK434j6BBrHhqaUoPtFuN8bAc0AfPFFGCDtPUHBooAQjIr234S+Jn1Cwk0m5fdLbgbCf7vpXiddZ8Nrx7XxrZxqcCZtpoA+jaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAQ9K8j8Z6l9u1to1bMcXAHvXp2r3YstMnnJwVQ4+teJSymed5j1dt1edmFS0FFdT2sloc1R1H0GUtFFeOfUBRRRQAUUUUAFFFFAAa9I+H2nCGwkvGGGmPGa87toGu7qKBPvSMAK9t021Wz0+CBRjYgBrvwFPmqcz6HkZxX5KHIt5F2iiivaPlAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooppoAxfFWojT9Emfdh3G1frXjhJYksck8mu0+IOpefeR2KHKINzfWuMrxMfU5qnKuh9Xk9D2dHne8vyCiiiuE9cKKKKACiiigAoopD0oAns7dru8ht0GWdgK9t0+1SzsYYFGAqgV5v4D037TqrXTr8sPKn3r1IdK9bLqdk6nc+bzuveaoroApaKK9M8EKDRSGgBGbaMnpXkPi/UTqGuyBWzFHwtel69fDTtIuJ8/MFIA9TXi7uZJGkPVjmvNzCpaKgup7mSUOao6r2Q2looryD6YKKKKACiiigAooooASu/wDh5pvE19IvOdqH2rgkjaSRY1GSxxxXtWg2I07SLe3A6Lk124Gnz1b9jy82r+yoOK3kaIpaWivcPkSte2kd7Zy28qgo6kHNeLatp0ml6lNauPunKn1Fe4npXGeO9G+12YvYUzLF1x3FcWNoe0hzLdHq5Vi/Y1eSW0jzWikB4pa8M+tCiiigAooooAKKKKACrml6nPpN8lzAxGD8y+oqnSU03F3RM4xlFqSuj27SNUh1ayjuYWByPmHofStGvHPDGuyaLqA3Em3k4dfSvXYZkniWWNgyMMgivewuIVaPmfHZhgnhall8L2JqKB0orqOAKKKKACikNMldYomdjgKMk0AcJ8Q9SwIrGNuTy49q8/FaWvX7ajrU8xPAYqv0rOr57FVPaVWz7TLqHscOl1eoUUUVzncFFFFABRRRQAUlLSZoA6LwZp32/XUdhmKLlq9bUAAAdK5LwFpv2XSjcuuJJjz9K6+vdwNLkp37nyOb1/aYhxWyCiiiuw8sKKKKACiiigDjvidK8Pga+ZCQTtGR9a+dl6Cvpnxtpzar4UvbVBliu7H05r5nKlWZTwVJFABRRRQB6D8IUibxHIz43hfkzXu9fLnhvWpPD+uW+oR8hDhx/s96+lNH1ez1rT47yzlV43GeDyD70AaFFGaKACiiigAoozTJZUijLyOqooyWY4AoAhv50trKeaQgKiEkn6V8tatdLe6zd3KfdkkJH516L8R/iBHqEb6PpMm6DOJph39hXl9ABRRRnFAF/QrR73XrKGMZbzVJ+ma+p4l2xqvoMV4x8I/DL3F82tXEZEUY2xEjhq9pFAC0hIAJPAFLXkXxG+IbxPNommbo3U7ZpiCPwH+NAB8RPiNjzNH0aX5sbZp17ewryPkkkkknqT3pM5JJOSepJ60ZFAC9q6Twl4MvvFd0PKHl2aN+8mbp9BXN9q7Dwp8Q7/wraG0S1huLctuwx2sPxoA950bR7TRNMisrSMLHGMfU+taFeTW3xsgJ/wBJ0eRB6pKG/pW3ZfFvwzckCZ57Yn/npHkfpQB31eW/GqVxo9lEDhTLk16Pp+pWeqWq3NlOk0LdGWuI+LumPfeGUmjUn7O+9selAHhA6UUgIIBpaACvZPgwkX9m3T8ebvwfpXjddb8P/FI8Na3/AKQf9En+Vz/d96APoyioba5huoEngkWSJxlWU5BFTUAFFFFABRRSZFAC1geM76PT/C17NIQP3ZCj1Na19fWun2r3F3OkMSDJZjivA/H/AI3bxPefZrTK6fEfl7Fz60AcWW3sz/3jmiiigArrvhnZPd+M7aVRkQHca5A17l8J/DL6ZpbancxlZ7kDbn+72oA9HFLRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFITjNAHEfELURFZRWSth5DuP0rzit7xhem91+Vc5WH5VrBrwMZU56r8j7LK6PssNHz1FooorlPQCiiigAooooAKKKQ5xx1oA6nwNpou9Z+0OuY4eQfevVAK5nwRpostFWRhhpjvNdP2r3cFS5KWvU+PzWv7XENLZaCiiiiuw80KKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKr3Mwt7aWZjwik1YrmPG98bTQnRGw8nAqZz5IuRpSpupNQXU8y1K7N/qVxckk+Y5IqrSClr5qUuaTl3Pu4QUIqK2QUUUVJYUUUUAFFFFABSH260taGh2LajrNvAoz8wY/Smk27ImUlFNs9L8HaaNP0OM/wAUvzmujHSooo1ijVEGAowBUtfSUoKEFFHwuIrOtVlUfUKKKK0MQpDS1HM4jiZz0UZoA4H4h6lnybBGIP3mxXB1o67etf6zcSscqGIX6VnV89iqntKrZ9rl9D2OHjHq9QooornO0KKKKACiiigAoopCcUAdB4O043+uxsRlIfmYV66oxXIeA9NNtpZuXXEkp4PtXYDrXuYCny0+Z9T5LN6/tMRyraItFFFdp5QVFPCs8TxOMqwwRUtFAeZ4p4g0ttJ1eWAjCH5k+lZleqeNdF/tHTTPEuZoeRjuK8q5BIPUcH618/i6PsqlujPssuxXt6KvutxaKKK5j0AooooAKKKKACiiigBK7zwL4gIP9mXL+8ZP8q4SnRSyQTJNGcOhyprWjVdOakjmxWHjiKTpy/4Y97HSjNY/h3WE1fS45QcuoCv9a2BX0UJKcVJHxNSnKnNwluhaKKKogD0rnvF+o/2foUp/ik+QfjXQHpXmvxCvjLfw2qt8qDLD3rDE1PZ02zrwNH21eMTix6nqaWiivnT7e1gooooAKKKKACiiigAqxYWhvtQhtgD+8YA4qvXYfD/TftGoSXrjMcYwPrWlKDnNRRjiKqpUpTfRHo1nAtraxQKOEUCrFNHWnV9IlZWR8JKTk22FFFFMQUUUUAFFFFADXQOpVhlSMEV8+/EfwnLoOsvewRk2Nw2QQOEPpX0JVPU9MtdWsZLS8iEkTjBB7fSgD5SortfGHw61Dw9K9zZo1zp+chl5ZB7iuKFABWtoXiXVPDlz52n3BRT96JuUb6ismigD2nRvjHp06rHqtrLbSd3j+df8a6+08c+Gr1QYtXtgT/C77T+tfM9JgUAfVH/CQ6Ptz/adpj/rqKo3Xjfw3ZqTLq9tkfwq+4/kK+ZcClwKAPb9W+MWj2ysunW813J2YjYv+Nea+IfHmt+IyY57gwWx/wCWEPA/E965qigAFFFOiiknkWKKNnkbgKoyTQA2un8G+DbvxTqCnY0djGw82UjGfYe9dJ4T+FF3fNHd65m3t+ogB+dvr6V7JY2Frp1oltaQrFCgwqqKAE07TrfS7GK0tUCRRjAAFW6KKACs+80PS9QYtd6fbTsf4pIgT+daFFAHOSeA/DEhJbR7f8AR/KoT8OvCh66PD/303+NdTRQByw+HPhMf8weL/vpv8acPh54VHTR4PzP+NdPRQBzqeBPDKHI0e2/Fc1ai8KaDD/q9Ish/2xBrYooAjhgit0EcMaRoOiouBUN/ZxahZTWk6ho5VKsDVqigD5h8VeHbjw1rUtrMp8ondE+OCPasSvp7xJ4asfE2nta3ic/8s5B95TXgXifwZqnhi4YXETSWpPyToMgj39KAOeoPNAOaKAOk8N+OdY8MEJbzeda5yYJDkfh6V6jpHxf0K7RUvo5rOXHORuXP1FeFUYoA+nbbxj4euwDDq9oc9jIAast4h0dV3NqdoB6+aK+WMUYFAH0peeP/AAxZKS+rQOR/DEdx/SuQ1f4zWcYZNJspJn7STfKv5da8bxRQBsa74o1fxFNv1C7Z0z8sS8IPwrHoooAKKsWVhd6lcrb2VvJPKxwFQZr1nwh8J1gZL7X8PIMMtsp+UfX1oA5/4feAZtZuY9T1GNo7GM5RWGDIf8K91jiWKNURQqqMAAdBRFEkUYjjQKijAAGABT6ACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooASmyKWRlHUin0UAeKeILGey1i4E6MAzZViOGrLr3W60+1vk2XMEcq+jDNZMvgrQpTk2YH+65H8jXk1sBNycos+kw2c0401GpF3R5DRXrP/AAgmg/8APq//AH9b/Gj/AIQTQf8An1f/AL+t/jWX9n1vL7zo/trDef3Hk1Fes/8ACCaD/wA+r/8Af1v8aP8AhBNB/wCfV/8Av63+NH9n1vL7w/tnDef3Hk1Fes/8IJoP/Pq//f1v8aP+EE0H/n1f/v63+NH9n1vL7w/tnDef3Hk1W9Jsm1DVILdByWyfpXp3/CCaD/z6v/39b/GreneFdK0u5Fxa25WUDAYuT/M1Ucvq3V7ETzmhyvlvc1LeJYIUiQYVRgVNSAYpa9hKysj5dtyd3uFFFFMQUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVxXxAsri4sYpolLJESWA5rtaYyB1KsAQeoNZ1Ye0g49zahW9jUVRK9jwOlr2S48KaNdMWksY9x6leM/lVU+BdBP/AC6t/wB/G/xryXl9VaJo+kjneHe6aPJfxor1n/hBNB/59X/7+t/jR/wgmg/8+r/9/W/xpf2fW8vvK/tnDef3Hk1Fes/8IJoP/Pq//f1v8aP+EE0H/n1f/v63+NH9n1vL7w/tnDef3Hk1Fes/8IJoP/Pq/wD39b/Gj/hBNB/59X/7+t/jR/Z9by+8P7Zw3n9x5LXe/DzTSTLfOv8Asoa3f+EE0HH/AB6v/wB/W/xra0/TrfTLVba1TZEvQZzW2HwU4VFKdtDkxubUqlFwpXuy0KWkxS16p88FFFFABVe9jaWzmjX7zKQKsUhGaGCdjwi9t5bS8lhmVldWPUdagr3K70mxvv8Aj5topfdlrLk8FaFISTZ4/wB1iK8epl87+4z6alndLlSmmmeRUV6z/wAIJoP/AD6v/wB/W/xo/wCEE0H/AJ9X/wC/rf41H9n1vL7zb+2cN5/ceTUV6z/wgmg/8+r/APf1v8aP+EE0H/n1f/v63+NH9n1vL7w/tnDef3Hk1Fes/wDCCaD/AM+r/wDf1v8AGj/hBNB/59X/AO/rf40f2fW8vvD+2cN5/ceS1PZWrXt9DbqCfMYA/SvU/wDhBNB/59X/AO/rf41ZsvCWkaddLcW1uVkHQlyf5mmsvq31JlnOHs+W9/Q07K2FpZxQL0RQKs0DgUV7MUoqyPl5Sc5OT6hRRRTJCiiigBrKGUqRkHivMPFXhO4tbp7yziMkDkllUcrXqOKaVBGDgisa9CNaPKzqwmLnhp88TwMgg4IwfQ0V7Xd+H9LvWLT2ULMf4tuDWe3gbQmOfshH0kb/ABrzJZdUWzR78M7oNe8mjySivWf+EE0H/n1f/v63+NH/AAgmg/8APq//AH9b/Gp/s+t5feX/AG1hvP7jyaivWf8AhBNB/wCfV/8Av63+NH/CCaD/AM+r/wDf1v8AGj+z63l94f2zhvP7jyaivWf+EE0H/n1f/v63+NH/AAgmg/8APq//AH9b/Gj+z63l94f2zhvP7jyaivWf+EE0H/n1f/v63+NL/wAIJoP/AD6v/wB/W/xo/s+t/TF/bOG8/uOF8IaydL1ZY3bEEx2tk8CvW1YNgjpXPDwLoKkEWrgg5H71v8a6CGFYI1jTO1RgZOa78JSqUo8szxsyxFDETVSnv1JKKKK7DzRD0ryfxvY3EGtNcSI3lSDKt2Fes1BcWkF3GY54lkQ9mGawxFH20OW514LFfVqyqNXPB8iivYJfBmhzNk2Sqf8AZYiof+EE0H/n1f8A7+t/jXl/2fW/pn0CzrDPdM8mor1n/hBNB/59X/7+t/jR/wAIJoP/AD6v/wB/W/xo/s+t5feP+2cN5/ceTUV6z/wgmg/8+r/9/W/xo/4QTQf+fV/+/rf40f2fW8vvD+2cN5/ceTUletf8IJoP/Pq//f1v8aP+EE0H/n1f/v63+NH9n1vL7xf2zhvP7jyXBYgL1PAr2DwnposNEhBXDyDc31qNPA2hJIrratlSCMyMf610KIsaBVGAOldWEwkqUnKZ5+ZZlTr01Cl8xRS0UV6J4gUUUUAFFFFABRRRQAUUUUANdQ6lWAIPUEVxPiL4YaJrbNNAhsbk874R8pPuK7iigD591f4VeIdNLNbRpfRDoYjhvyNcjdadfWLFbuzngI/56RkV9X4qOW2inGJYkkHoyg0AfJWR60uR619O3Pg/w9dkmbSLRie/lgGs6T4aeFJDzpaj/ddh/WgD5zyKTI9a+il+GHhNTkabn6ysf61cg8A+F7f7mj25P+2C386APmxEeRgsaM7HoFGTW1p3g3xDqrD7NpVxtP8AHIuwfrX0fbaPp1moW2sreID+5GBV3bjjtQB43o3wYuZCsmr36xr3igGT9M16TofhHRvD6AWNkiyY5lYbnP41uUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABUVxbw3ULRTxJJGwwVYZBqWigDzjX/hFpeos82mSNYzHnZjKH8O1ec6r8N/EulFj9iN1EP44Du/TrX0bSYoA+TJ7W5tX2XFvLC3pIhU/rUWa+sZ7G1ulInt4pQeu9Aax7jwR4auSTLo9rk91Taf0oA+Zs0ZHrX0U/wy8JucnTMf7sjD+tCfDHwmhyNMz9ZWP9aAPnTI9alhgmuH2QQySt/dRSx/SvpS38D+GrbBj0e1yO7JuP61rwadaWqgQW0MQHTYgGKAPnXTPAHiXVSpi02SKM/xz/IP15ru9F+DEKFZdYvjKe8UAwPxNesYpRQBm6ToWm6LAIdPs4oFHdV5P1NaVFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/9k="

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# CONFIG
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.set_page_config(
    page_title="Piki Weekly Report",
    page_icon="üõµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for clean look
st.markdown("""
<style>
    .metric-card {
        background: #f8f9fa; border-radius: 10px;
        padding: 16px; text-align: center; border-left: 4px solid #FF6B00;
    }
    .metric-value { font-size: 28px; font-weight: 700; color: #FF6B00; }
    .metric-label { font-size: 13px; color: #666; margin-top: 4px; }
    .section-header {
        background: linear-gradient(90deg, #FF6B00 0%, #CC5500 100%);
        color: white; padding: 10px 18px; border-radius: 8px;
        font-size: 16px; font-weight: 600; margin-bottom: 16px;
    }
    .kpi-ok  { color: #28a745; font-weight: 700; }
    .kpi-bad { color: #dc3545; font-weight: 700; }
    div[data-testid="stTabs"] button { font-size: 15px; font-weight: 600; }
    /* AI Insight card */
    .ai-insight-card {
        background: #FFF9F5;
        border: 1px solid #e0e6f0;
        border-left: 3px solid #FF6B00;
        border-radius: 8px;
        padding: 14px 18px;
        margin: 8px 0;
        font-size: 13.5px;
        line-height: 1.6;
        color: #2c3e50;
    }
    .ai-insight-card h1, .ai-insight-card h2, .ai-insight-card h3 {
        font-size: 14px !important;
        font-weight: 600 !important;
        color: #8B3000 !important;
        margin: 8px 0 4px 0 !important;
    }
    .ai-insight-card p { margin: 4px 0 !important; }
    .ai-insight-card ul, .ai-insight-card ol { 
        margin: 4px 0 !important; padding-left: 18px !important; 
    }
    .ai-insight-card li { margin: 2px 0 !important; font-size: 13px !important; }
    .ai-insight-label {
        font-size: 11px;
        font-weight: 600;
        color: #FF6B00;
        text-transform: uppercase;
        letter-spacing: 0.5px;
        margin-bottom: 6px;
    }
</style>
""", unsafe_allow_html=True)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# CONSTANTS
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FAILED_KPI       = 10          # max failed orders / week
GROWTH_RATE      = 0.012       # 1.2% weekly KPI
KPI_START_YEAR   = 2026
TARGET_RIDERS    = pd.DataFrame({
    'Business City':        ['Masaki','City Centre','Mlimani','Mikocheni','Mbezi',
                             'Kigamboni','Kinondoni','Arusha','Dodoma','Zanzibar','Mwanza'],
    'Weekday Active Riders':[40, 35, 9, 10, 8, 1, 3, 8, 3, 2, 2],
    'Weekend Active Riders':[50, 40, 10, 13, 10, 1, 4, 10, 4, 3, 3]
})
REGIONAL_CITIES  = ['Arusha','Dodoma','Mwanza','Zanzibar']
DAR_CITIES       = ['Mlimani','Mbezi','Masaki','Mikocheni','City Centre','Kinondoni']
OPERATING_HOURS  = list(range(7, 24)) + [0, 1, 2]
DAY_NAMES        = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']

PRODUCT_MAPPING  = {
    'chapatti':'chapati','chapati - per piece':'chapati',
    'chickenshawarma':'chicken shawarma','tradional wings':'traditional wings',
    'burger':'beef burger','1 pc chicken':'chicken piece (1)','1pc chicken':'chicken piece (1)',
    'plain chips':'regular chips','chips':'regular chips','fries':'regular chips',
    'french fries':'regular chips','french fries - regular':'regular chips',
    'chips (salted crisps)':'regular chips','chips kavu':'regular chips',
    'reg coleslaw':'coleslaw','regular coleslaw':'coleslaw',
    'soda':'soft drinks','soda - 600ml':'soft drinks (600ml)','coke':'coca cola',
    '600ml coke':'coke - 600ml','1.25ltr coke':'coke - 1.25l',
    'dasani water still - 500ml':'water - 500ml','dew drop - 600ml (12 pack)':'water - 600ml',
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# HELPERS ‚Äî pure functions, no Streamlit calls
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def millions(x, pos):
    return f'{x/1_000_000:.1f}M'

fmt_millions = FuncFormatter(millions)

def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    a = sin((lat2-lat1)/2)**2 + cos(lat1)*cos(lat2)*sin((lon2-lon1)/2)**2
    return R * 2 * atan2(sqrt(a), sqrt(1-a))

def extract_products(text):
    results = []
    for qty, name in re.findall(r"(\d+)\s*x\s*([^:\n\r]+)", str(text)):
        results.append((name.lower().strip(), int(qty)))
    return results

def standardize_product(name):
    if name in PRODUCT_MAPPING:
        return PRODUCT_MAPPING[name]
    m = process.extractOne(name, PRODUCT_MAPPING.keys(), scorer=fuzz.token_sort_ratio)
    return PRODUCT_MAPPING[m[0]] if m and m[1] >= 80 else name


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# DELIVERY STAGE TARGETS (from Piki operations standard)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Stage targets (minutes):
#   Accept by Business   = 2 min   (restaurant accepts the order)
#   Assign Time          = 2 min   (system assigns a driver)
#   Accept by Driver     = 1.5 min (driver accepts the assignment)
#   Driver to Business   = 8 min   (driver rides to restaurant; distance-based for individual orders)
#   Driver in Business   = 12 min  (restaurant prep + handover time)
#   Pickup to Customer   = CUSTOM  (distance-based, see below)
#
# Pickup-to-Customer breakdown (per order):
#   Driving time         = (distance_km √ó 1.6) / 30 km/h √ó 60  (road dist at 30 km/h)
#   Check address/direction = 1 min
#   Park/walk/security   = 2 min
#   Take payment         = 3 min
#   Total overhead       = 6 min + driving time
#
# Total target = AcceptB + Assign + AcceptD + D2B + AtB + P2C
# For a 3 km straight-line order:  road dist = 3√ó1.4 = 4.2 km
#   driving = 4.2/40√ó60 = 6.3 min  ‚Üí P2C target = 6.3+6 = 12.3 min  ‚Üí Total ‚âà 37.8 min
#
# The "custom Total Target" per order is therefore distance-dependent.
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

STAGE_TARGETS_FIXED = {
    "Accepted by Business": 2,
    "Assigned Time":        2,
    "Accepted by Driver":   1.5,
    "Driver to Business":   8,
    "Driver in Business":   12,
}
STAGE_DRIVING_SPEED_KMH = 30   # city driving speed (Dar es Salaam realistic avg)
STAGE_P2C_OVERHEAD_MIN  = 6    # 1 check address + 2 park/walk + 3 payment
DIST_ROAD_FACTOR        = 1.6  # straight-line ‚Üí road distance (city roads)

def round1(x):
    """Round numeric value to 1 decimal place; pass through non-numeric."""
    try: return round(float(x), 1)
    except: return x

def p2c_target(dist_straight_km: float) -> float:
    """Compute Pickup-to-Customer target in minutes for a given straight-line distance."""
    road_km = dist_straight_km * DIST_ROAD_FACTOR
    drive_min = (road_km / STAGE_DRIVING_SPEED_KMH) * 60
    return round(drive_min + STAGE_P2C_OVERHEAD_MIN, 1)

def total_target(dist_straight_km: float) -> float:
    """Full order target = sum of fixed stages + P2C target."""
    fixed = sum(STAGE_TARGETS_FIXED.values())   # 2+2+1.5+8+12 = 25.5
    return round(fixed + p2c_target(dist_straight_km), 1)


def compute_delivery_stages(df):
    """
    Add all delivery stage columns to df (in-place-safe via copy).
    Also adds distance-based targets per order.
    """
    df = df.copy()
    for col in ['DELIVERY TIME','ACCEPTED BUSINESS HOUR','ASSIGNED HOUR',
                'ACCEPTED DRIVER HOUR','IN BUSINESS HOUR','PICKUP HOUR','DELIVERY HOUR']:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')

    def stage(a, b, default):
        s = (df[b] - df[a]).dt.total_seconds() / 60
        return s.mask(s < 0, default)

    # Measured stages
    df['Accepted by Business'] = stage('DELIVERY TIME',         'ACCEPTED BUSINESS HOUR', 0).clip(lower=0)
    df['Assigned Time']        = stage('ACCEPTED BUSINESS HOUR','ASSIGNED HOUR',           2)
    df['Accepted by Driver']   = stage('ASSIGNED HOUR',         'ACCEPTED DRIVER HOUR',    1.5)
    df['Driver to Business']   = stage('ACCEPTED DRIVER HOUR',  'IN BUSINESS HOUR',        8)
    df['Driver in Business']   = stage('IN BUSINESS HOUR',      'PICKUP HOUR',            12)
    df['Pickup to Customer']   = stage('PICKUP HOUR',           'DELIVERY HOUR',          10)

    # Average Delivery Time: prefer full window; fall back to acceptance‚Üídelivery
    adt  = (df['DELIVERY HOUR'] - df['DELIVERY TIME']).dt.total_seconds() / 60
    adt2 = (df['DELIVERY HOUR'] - df['ACCEPTED BUSINESS HOUR']).dt.total_seconds() / 60
    df['Average Delivery Time'] = adt.mask(adt < 0, adt2).mask(adt2 < 0, 40)

    # ‚îÄ‚îÄ Distance-based P2C target per order ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Requires DISTANCE (km) already present; if not, we add straight-line now
    _has_dist = 'DISTANCE (km)' in df.columns and df['DISTANCE (km)'].notna().any()
    if not _has_dist:
        if all(c in df.columns for c in ['CUSTOMER LATITUDE','CUSTOMER LONGITUDE',
                                          'BUSINESS LATITUDE','BUSINESS LONGITUDE']):
            df['DISTANCE (km)'] = df.apply(
                lambda r: round(haversine(r['CUSTOMER LATITUDE'],r['CUSTOMER LONGITUDE'],
                                          r['BUSINESS LATITUDE'],r['BUSINESS LONGITUDE']) * DIST_ROAD_FACTOR, 2), axis=1)
        else:
            df['DISTANCE (km)'] = np.nan

    if 'DISTANCE (km)' in df.columns:
        _road_km = pd.to_numeric(df['DISTANCE (km)'], errors='coerce')
        # For orders that already have road factor applied (from add_distance), use directly
        # add_distance already applies √ó1.4, so we use the stored value as road_km
        _drive_min = (_road_km / STAGE_DRIVING_SPEED_KMH) * 60
        df['P2C Target (min)']    = (_drive_min + STAGE_P2C_OVERHEAD_MIN).round(1)
        df['Total Target (min)']  = (sum(STAGE_TARGETS_FIXED.values()) + df['P2C Target (min)']).round(1)
        # Performance vs target per order  (positive = faster than target = good)
        df['vs Target (min)']     = (df['Total Target (min)'] - df['Average Delivery Time']).round(1)
        df['vs Target (%)']       = ((df['vs Target (min)'] / df['Total Target (min)'].replace(0,np.nan)) * 100).round(1)
    return df



def categorize_delay(row):
    if row.get('Average Delivery Time', 0) <= 100:
        return ""
    issues = []
    checks = [
        ('Accepted by Business',  5),   # target 2 min, alert at 5
        ('Assigned Time',         5),   # target 2 min, alert at 5
        ('Accepted by Driver',    5),   # target 1.5 min, alert at 5
        ('Driver to Business',   20),   # target 8 min, alert at 20
        ('Driver in Business',   25),   # target 12 min, alert at 25
        ('Pickup to Customer',   30),   # target varies; alert at 30
    ]
    for col, limit in checks:
        v = row.get(col, 0)
        if v < 0 or v > limit:
            issues.append(f"{col} Delay")
    return ", ".join(issues) if issues else "Unclassified Delay"

def week_label(period_or_date):
    """Return readable week label from a Period or datetime."""
    try:
        p = pd.Period(period_or_date, freq='W')
        return f"W{p.week} ({p.start_time.strftime('%d %b')})"
    except Exception:
        return str(period_or_date)

def apply_growth_kpi(weekly):
    weekly = weekly.copy()
    weekly['Year'] = weekly['Week'].dt.year
    base = weekly[weekly['Year'] == KPI_START_YEAR].head(1)
    if base.empty:
        weekly['Growth KPI Orders'] = None
        return weekly
    idx = base.index[0]
    weekly['Growth KPI Orders'] = None
    weekly.loc[idx, 'Growth KPI Orders'] = base['Total_Orders'].values[0]
    for i in range(idx+1, len(weekly)):
        weekly.loc[i, 'Growth KPI Orders'] = weekly.loc[i-1, 'Growth KPI Orders'] * (1 + GROWTH_RATE)
    return weekly

def add_distance(df):
    if not all(c in df.columns for c in ['CUSTOMER LATITUDE','CUSTOMER LONGITUDE',
                                          'BUSINESS LATITUDE','BUSINESS LONGITUDE']):
        return df
    df = df.copy()
    # Haversine gives straight-line distance; multiply by DIST_ROAD_FACTOR (1.6) for real road distance
    df['DISTANCE (km)'] = df.apply(
        lambda r: round(haversine(r['CUSTOMER LATITUDE'],r['CUSTOMER LONGITUDE'],
                                  r['BUSINESS LATITUDE'],r['BUSINESS LONGITUDE']) * DIST_ROAD_FACTOR, 2), axis=1)
    bins   = [0, 2, 3, 4, 5, 7, float('inf')]
    labels = ['0-2 km','2-3 km','3-4 km','4-5 km','5-7 km','7+ km']
    df['Distance Category'] = pd.cut(df['DISTANCE (km)'], bins=bins, labels=labels)
    return df

def excel_bytes(df, sheet='Sheet1'):
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine='xlsxwriter') as w:
        df.to_excel(w, index=False, sheet_name=sheet)
    buf.seek(0)
    return buf.read()

def format_products_clean(products_text):
    extracted = extract_products(str(products_text))
    if not extracted:
        return ""
    return ", ".join(f"{qty} x {name.title()}" for name, qty in extracted)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# CLAUDE AI HELPERS
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def claude_insight(prompt: str, max_tokens: int = 700) -> str:
    try:
        key = os.getenv("CLAUDE_API_KEY")
        if not key:
            return "‚ö†Ô∏è Set CLAUDE_API_KEY environment variable to enable AI insights."
        client = anthropic.Anthropic(api_key=key)
        r = client.messages.create(
            model="claude-sonnet-4-6",
            max_tokens=max_tokens,
            messages=[{"role": "user", "content": prompt}]
        )
        return r.content[0].text
    except Exception as e:
        return f"‚ö†Ô∏è AI insight unavailable: {e}"

def claude_chat_answer(context: str, history: list, question: str) -> str:
    try:
        key = os.getenv("CLAUDE_API_KEY")
        if not key:
            return "‚ö†Ô∏è Set CLAUDE_API_KEY environment variable."
        client = anthropic.Anthropic(api_key=key)
        system = f"""You are a senior BI analyst for a food delivery company in Tanzania.
Answer questions about the dashboard section using this data context:
{context}
Be concise, specific, and use real numbers. If data doesn't support an answer, say so."""
        r = client.messages.create(
            model="claude-sonnet-4-6", max_tokens=600,
            system=system,
            messages=history + [{"role": "user", "content": question}]
        )
        return r.content[0].text
    except Exception as e:
        return f"‚ö†Ô∏è Could not get answer: {e}"

def ai_block(section_key: str, context: str, insight_text: str):
    """Renders insight card + Q&A chat for any section."""
    html_text = insight_text
    st.markdown(
        f'''<div class="ai-insight-card">
<span class="ai-insight-label">ü§ñ AI Insight</span>
{html_text}
</div>''',
        unsafe_allow_html=True
    )

    with st.expander("üí¨ Ask a follow-up question", expanded=False):
        hkey = f"chat_{section_key}"
        if hkey not in st.session_state:
            st.session_state[hkey] = []
        for m in st.session_state[hkey]:
            st.chat_message(m["role"]).markdown(m["content"])
        q = st.chat_input("Ask anything about this section‚Ä¶", key=f"inp_{section_key}")
        if q:
            st.chat_message("user").markdown(q)
            with st.spinner("Thinking‚Ä¶"):
                ans = claude_chat_answer(context, st.session_state[hkey], q)
            st.chat_message("assistant").markdown(ans)
            st.session_state[hkey] += [{"role":"user","content":q},
                                        {"role":"assistant","content":ans}]
        if st.session_state[hkey]:
            if st.button("üóëÔ∏è Clear chat", key=f"clr_{section_key}"):
                st.session_state[hkey] = []
                st.rerun()


def ai_insight_button(section_key: str, label: str, build_fn, *args, **kwargs):
    """On-demand AI insight: shows a styled button, runs insight only when clicked."""
    _sk = f"ai_ins_{section_key}"
    _ctx_sk = f"ai_ctx_{section_key}"
    if _sk not in st.session_state:
        st.session_state[_sk] = None
        st.session_state[_ctx_sk] = None
    st.markdown(f"""
    <div style="margin:14px 0 6px 0;padding:10px 14px;background:linear-gradient(90deg,#f0f4ff,#e8f0fe);
         border-radius:8px;border:1px solid #c5d3f0;display:flex;align-items:center;gap:10px;">
      <span style="font-size:18px;">ü§ñ</span>
      <span style="font-size:13px;color:#3a5280;font-weight:500;">
        AI Insight available ‚Äî click to analyze <b>{label}</b>
      </span>
    </div>""", unsafe_allow_html=True)
    col_btn, col_rst = st.columns([3,1])
    with col_btn:
        if st.button(f"‚ö° Generate AI Insight", key=f"btn_{section_key}",
                     type="primary", use_container_width=True):
            with st.spinner(f"Claude is analyzing {label}‚Ä¶"):
                result = build_fn(*args, **kwargs)
                if isinstance(result, tuple):
                    ins_text, ctx_text = result
                else:
                    ins_text, ctx_text = result, ""
            st.session_state[_sk] = ins_text
            st.session_state[_ctx_sk] = ctx_text
    with col_rst:
        if st.session_state[_sk] and st.button("‚Ü∫ Refresh", key=f"ref_{section_key}"):
            st.session_state[_sk] = None
            st.rerun()
    if st.session_state[_sk]:
        ai_block(section_key, st.session_state[_ctx_sk] or "", st.session_state[_sk])

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# INSIGHT BUILDERS ‚Äî return (text, context)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def build_trend_insight(weekly, full_df):
    ws = weekly[['Week_Label','Total_Orders','Growth KPI Orders','Total_Sales']].to_string(index=False)
    wow = ""
    prev_lbl = None
    if len(weekly) >= 2:
        l, p = weekly.iloc[-1], weekly.iloc[-2]
        do = l['Total_Orders'] - p['Total_Orders']
        ds = l['Total_Sales']  - p['Total_Sales']
        prev_lbl = p['Week_Label']
        wow = (f"WoW Orders: {do:+.0f} ({do/max(p['Total_Orders'],1)*100:+.1f}%)\n"
               f"WoW Sales:  {ds:+,.0f} TZS ({ds/max(p['Total_Sales'],1)*100:+.1f}%)")

    # ‚îÄ‚îÄ 7-week rolling average comparison ‚îÄ‚îÄ
    avg7_ctx = ""
    if len(weekly) >= 2:
        _cur_orders = int(weekly.iloc[-1]['Total_Orders'])
        _cur_sales  = weekly.iloc[-1]['Total_Sales']
        _prev_n = weekly.iloc[:-1].tail(7)   # up to 7 preceding weeks
        _avg7_orders = _prev_n['Total_Orders'].mean()
        _avg7_sales  = _prev_n['Total_Sales'].mean()
        _n_weeks = len(_prev_n)
        _diff_orders = _cur_orders - _avg7_orders
        _diff_pct    = _diff_orders / max(_avg7_orders, 1) * 100
        avg7_ctx = (
            f"\n\n7-WEEK ROLLING AVERAGE COMPARISON (vs last {_n_weeks} weeks):\n"
            f"  This week orders:        {_cur_orders:,}\n"
            f"  Avg of last {_n_weeks} weeks:    {_avg7_orders:,.0f}\n"
            f"  Difference:              {_diff_orders:+,.0f} ({_diff_pct:+.1f}%)\n"
            f"  This week sales:         {_cur_sales/1e6:.2f}M TZS\n"
            f"  Avg sales last {_n_weeks} weeks: {_avg7_sales/1e6:.2f}M TZS"
        )

    # ‚îÄ‚îÄ Business-level movers ‚îÄ‚îÄ
    contrib = ""
    _df = full_df.copy()
    _df['_yw'] = (_df['DELIVERY DATE'].dt.isocalendar().year.astype(str)
                  + "-W" + _df['DELIVERY DATE'].dt.isocalendar().week.astype(str).str.zfill(2))
    _yw_pairs = (_df[['DELIVERY DATE']].assign(
        _iso_yr=_df['DELIVERY DATE'].dt.isocalendar().year,
        _iso_wk=_df['DELIVERY DATE'].dt.isocalendar().week
    )[['_iso_yr','_iso_wk']].drop_duplicates().sort_values(['_iso_yr','_iso_wk']))
    _yw_cur  = (_yw_pairs.iloc[-1]['_iso_yr'].astype(str)
                + "-W" + str(_yw_pairs.iloc[-1]['_iso_wk']).zfill(2))
    _yw_prev = (_yw_pairs.iloc[-2]['_iso_yr'].astype(str)
                + "-W" + str(_yw_pairs.iloc[-2]['_iso_wk']).zfill(2)) if len(_yw_pairs) >= 2 else _yw_cur

    if 'BUSINESS NAME' in full_df.columns and len(_yw_pairs) >= 2:
        lb = _df[_df['_yw']==_yw_cur].groupby('BUSINESS NAME').agg(
            Latest=('ID','count'), Sales_L=('SUBTOTAL','sum')).reset_index()
        pb = _df[_df['_yw']==_yw_prev].groupby('BUSINESS NAME').agg(
            Prev=('ID','count'), Sales_P=('SUBTOTAL','sum')).reset_index()
        bz = pd.merge(lb, pb, on='BUSINESS NAME', how='outer').fillna(0)
        bz['Order_Œî'] = bz['Latest'] - bz['Prev']
        bz['Sales_Œî'] = bz['Sales_L'] - bz['Sales_P']
        bz = bz.sort_values('Order_Œî', ascending=False)
        contrib = (f"\nBUSINESS MOVERS (latest vs prev week):"
                   f"\nTop Growers:\n{bz.head(6)[['BUSINESS NAME','Latest','Prev','Order_Œî','Sales_Œî']].to_string(index=False)}"
                   f"\nTop Decliners:\n{bz.tail(6)[['BUSINESS NAME','Latest','Prev','Order_Œî','Sales_Œî']].to_string(index=False)}")

    # ‚îÄ‚îÄ City performance vs KPI + 7-week avg per city ‚îÄ‚îÄ
    city_ctx = ""
    if 'BUSINESS CITY' in full_df.columns and len(_yw_pairs) >= 2:
        kpi_rate = GROWTH_RATE
        _city_now  = (_df[_df['_yw']==_yw_cur].groupby('BUSINESS CITY')
                      .agg(Orders_Now=('ID','count'), Sales_Now=('SUBTOTAL','sum')).reset_index())
        _city_prev = (_df[_df['_yw']==_yw_prev].groupby('BUSINESS CITY')
                      .agg(Orders_Prev=('ID','count')).reset_index())

        # 7-week rolling avg per city
        _prev7_yws = _yw_pairs.iloc[:-1].tail(7)
        _prev7_yw_list = (_prev7_yws['_iso_yr'].astype(str)
                          + "-W" + _prev7_yws['_iso_wk'].astype(str).str.zfill(2)).tolist()
        _city_7wk = (_df[_df['_yw'].isin(_prev7_yw_list)]
                     .groupby(['BUSINESS CITY','_yw'])
                     .agg(Wk_Orders=('ID','count')).reset_index()
                     .groupby('BUSINESS CITY')['Wk_Orders'].mean()
                     .reset_index().rename(columns={'Wk_Orders':'Avg7Wk_Orders'}))
        _city_m = pd.merge(_city_now, _city_prev, on='BUSINESS CITY', how='outer').fillna(0)
        _city_m = pd.merge(_city_m, _city_7wk, on='BUSINESS CITY', how='left').fillna(0)
        _city_m['WoW_%']      = ((_city_m['Orders_Now'] - _city_m['Orders_Prev']) /
                                  _city_m['Orders_Prev'].replace(0,1) * 100).round(1)
        _city_m['KPI_Target'] = (_city_m['Orders_Prev'] * (1 + kpi_rate)).round(0)
        _city_m['vs_KPI']     = (_city_m['Orders_Now'] - _city_m['KPI_Target']).round(0)
        _city_m['vs_7wk_avg'] = (_city_m['Orders_Now'] - _city_m['Avg7Wk_Orders']).round(0)
        _city_m['vs_7wk_%']   = ((_city_m['Orders_Now'] - _city_m['Avg7Wk_Orders']) /
                                   _city_m['Avg7Wk_Orders'].replace(0,1) * 100).round(1)
        _city_m['KPI_Status'] = _city_m['vs_KPI'].apply(
            lambda x: '‚úÖ Beat' if x >= 0 else f'‚ùå Miss {abs(int(x))}')
        _city_m = _city_m.sort_values('WoW_%', ascending=False)
        city_ctx = (
            f"\n\nCITY PERFORMANCE vs 1.2% KPI + 7-WEEK AVERAGE:\n"
            f"{_city_m[['BUSINESS CITY','Orders_Prev','Orders_Now','WoW_%','vs_KPI','KPI_Status','Avg7Wk_Orders','vs_7wk_avg','vs_7wk_%']].to_string(index=False)}"
        )

    context = (f"WEEKLY TREND (all weeks):\n{ws}\n\n"
               f"CURRENT WEEK: {weekly.iloc[-1]['Week_Label']} | "
               f"Orders: {int(weekly.iloc[-1]['Total_Orders'])} | "
               f"Sales: {weekly.iloc[-1]['Total_Sales']/1e6:.2f}M TZS\n\n"
               f"WEEK-OVER-WEEK:\n{wow}"
               f"{avg7_ctx}"
               f"{contrib}"
               f"{city_ctx}")

    prompt = f"""You are a senior business analyst writing a narrative intelligence report for Piki's leadership team. You have full access to the numbers ‚Äî your job is NOT to list them again. Instead, write the story BEHIND the numbers.

Raw data for your analysis:
{context}

Write a narrative executive report. The leadership team has already seen the charts and tables. They want to understand WHY things happened, WHAT changed, and WHAT to do about it. Do NOT repeat numbers they already see. Instead:

**1. The Story This Week**
What is the single most important thing that happened this week? Was there an unusual event ‚Äî a promotion, a competitor move, a supply issue, a city that suddenly dropped or spiked? What pattern breaks from the previous trend and why might that be? Hypothesize based on the data.

**2. Who Drove the Change?**
Name the specific restaurants or cities that moved the needle most ‚Äî but explain WHY they likely moved. Did a big restaurant drop off? Did a new restaurant gain traction? Is a city growing because of expansion or losing because of a service issue? Look at the business movers data and tell the story of what changed in the restaurant mix.

**3. Where Is the Business Healthy vs At Risk?**
Don't list cities ‚Äî instead group them: which cities are genuinely gaining momentum (consecutive growth weeks), which are stagnating, and which are in decline? What is the pattern ‚Äî is it one city dragging the whole company, or is the issue widespread? Is the overall business trajectory improving or deteriorating based on the multi-week trend?

**4. The Revenue Quality Story**
Is Piki making more money per order or just doing more orders? If sales grew faster than orders, that is positive ‚Äî customers are spending more. If orders grew but sales didn't keep up, that suggests cheaper orders or more discounts. Tell this story.

**5. Three Things Leadership Should Do NOW**
Be direct and operational. Each action must be tied to a specific observation from the data ‚Äî not generic advice. For example: "Reach out to [restaurant type] in [city] because they dropped X orders and that is unusual for them" or "Investigate why [city] has been below its 7-week average for 3 consecutive weeks."

Write in clear, flowing paragraphs. Be direct. Be a trusted advisor, not a data reporter."""
    return claude_insight(prompt, 1400), context


def build_failed_insight(failed_weekly, pivot_df=None, week_label_str=None):
    ws = failed_weekly[['Week_Label','Failed Orders']].to_string(index=False)
    context = f"FAILED ORDERS TREND (KPI‚â§{FAILED_KPI}/week):\n{ws}"
    if pivot_df is not None:
        context += f"\n\nWEEKLY BREAKDOWN ‚Äî {week_label_str}:\n{pivot_df.to_string()}"
    prompt = f"""Senior operations analyst for a Tanzanian food delivery company.
{context}
Provide:
1. **Trend** ‚Äì Improving, worsening or stable?
2. **KPI Breaches** ‚Äì Which weeks & by how much?
3. **City / Day Patterns** ‚Äì Where do failures concentrate?
4. **Root Cause Hypotheses** ‚Äì What operational factors likely cause these?
5. **Actions** ‚Äì 3 specific fixes for the highest-risk areas.
Use real numbers."""
    return claude_insight(prompt, 750), context


def build_delivery_insight(stage_df, city):
    summary = stage_df[['BUSINESS CITY','Average Delivery Time','Driver in Business',
                         'Pickup to Customer','Accepted by Business']].head(30).to_string(index=False)
    context = f"DELIVERY STAGE DATA ‚Äî {city}:\n{summary}"
    prompt = f"""Senior BI analyst for a Tanzanian food delivery company.
{context}
Provide:
1. **Overall Speed** ‚Äì Is avg delivery time acceptable (<45 min target)?
2. **Bottleneck Stage** ‚Äì Which stage contributes most to delays?
3. **City Comparison** ‚Äì Best vs worst performing areas.
4. **Vendor Prep Risk** ‚Äì Is Driver-in-Business time too high?
5. **Actions** ‚Äì 2 specific fixes for the biggest delay source.
Use real numbers."""
    return claude_insight(prompt, 700), context


def build_attendance_insight(pivot_df, week_sel, df_week):
    deficiency_cities = pivot_df[pivot_df['Avg Deficiency'] > 0][
        ['WORKING ZONE','Avg Deficiency','Status']].to_string(index=False)
    ok_cities = pivot_df[pivot_df['Avg Deficiency'] == 0]['WORKING ZONE'].tolist()
    total_drivers = df_week['DRIVER NAME'].nunique() if not df_week.empty else 0
    context = (f"DRIVER ATTENDANCE ‚Äî Week {week_sel}\n"
               f"Total unique drivers active: {total_drivers}\n"
               f"Cities with deficiency:\n{deficiency_cities}\n"
               f"Cities at target: {', '.join(ok_cities)}")
    prompt = f"""Senior operations analyst for a Tanzanian food delivery company.
{context}
Provide:
1. **Attendance Summary** ‚Äì How many cities are understaffed vs sufficient?
2. **Highest Risk Zones** ‚Äì Which areas need urgent rider recruitment?
3. **Day Patterns** ‚Äì Are deficiencies on weekdays, weekends or both?
4. **Impact on Delivery** ‚Äì Link understaffing to potential delivery delays.
5. **Actions** ‚Äì Specific staffing recommendations per city.
Use real numbers."""
    return claude_insight(prompt, 700), context


def build_product_insight(total_df, biz_df, weekly_prod_df):
    top10 = total_df.head(10).to_string(index=False)
    top_biz = biz_df.head(10).to_string(index=False)
    total_qty = int(total_df['Total Quantity'].sum())
    top3_share = round(total_df.head(3)['Total Quantity'].sum() / total_qty * 100, 1) if total_qty else 0
    context = (f"PRODUCT MIX ‚Äî Total items sold: {total_qty:,}\n"
               f"Top-3 share: {top3_share}% of volume\n\n"
               f"Top 10 Products:\n{top10}\n\n"
               f"Top 10 Businesses:\n{top_biz}")
    prompt = f"""Senior BI analyst for a Tanzanian food delivery company.
{context}
Provide:
1. **Best Sellers** ‚Äì What dominates and what does it reveal about customer preferences?
2. **Concentration Risk** ‚Äì Over-reliance on few products or businesses?
3. **Business Performance** ‚Äì Revenue vs volume outliers in top businesses.
4. **Menu Opportunity** ‚Äì Underperforming categories worth promoting.
5. **Actions** ‚Äì One for the product team, one for the commercial team.
Use real numbers. Be concise."""
    return claude_insight(prompt, 750), context


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# SIDEBAR ‚Äî Upload & Global Filters
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
with st.sidebar:
    st.markdown(f'<img src="data:image/jpeg;base64,{PIKI_LOGO_B64}" style="width:100%;border-radius:8px;margin-bottom:8px;" />', unsafe_allow_html=True)
    st.title("üìä Piki Dashboard Report")
    st.divider()

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # DATA SOURCE ‚Äî Supabase PostgreSQL (primary)
    # Falls back to CSV upload if DB not configured
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # Read secrets (works both locally and on Streamlit Cloud)
    def _get_secret(key, default=None):
        """Read from st.secrets first, then env vars."""
        try:
            return st.secrets[key]
        except Exception:
            return os.getenv(key, default)

    SUPABASE_URL = _get_secret("SUPABASE_URL", "")
    SUPABASE_KEY = _get_secret("SUPABASE_KEY", "")
    DB_TABLE     = _get_secret("DB_TABLE", "orders")

    def _parse_dates(df):
        df['DELIVERY DATE'] = pd.to_datetime(df['DELIVERY DATE'], errors='coerce')
        df['DELIVERY TIME'] = pd.to_datetime(df['DELIVERY TIME'], errors='coerce')
        return df

    # ‚îÄ‚îÄ Try Supabase (load ALL data, no date restriction) ‚îÄ‚îÄ
    def _load_from_supabase(url, key, table):
        """Load ALL orders from Supabase in paginated batches."""
        try:
            from supabase import create_client
            client = create_client(url, key)
            all_rows, page = [], 0
            PAGE = 1000
            while True:
                resp = (client.table(table)
                        .select("*")
                        .order("DELIVERY DATE", desc=True)
                        .range(page * PAGE, (page + 1) * PAGE - 1)
                        .execute())
                rows = resp.data
                all_rows.extend(rows)
                if len(rows) < PAGE:
                    break
                page += 1
            if not all_rows:
                return None, "No data found in database table."
            return pd.DataFrame(all_rows), None
        except ImportError:
            return None, "supabase package not installed."
        except Exception as e:
            return None, str(e)

    # ‚îÄ‚îÄ Default data file ‚Äî auto-loads when app opens ‚îÄ‚îÄ
    DEFAULT_CSV = "February Week 3.csv"   # keep this file in the same folder as Weekly_Report.py

    def _try_load_default():
        """Load the default CSV from the same directory as this script."""
        _try_paths = [
            DEFAULT_CSV,
            os.path.join(os.path.dirname(os.path.abspath(__file__)), DEFAULT_CSV),
        ]
        for _p in _try_paths:
            if os.path.exists(_p):
                try:
                    return pd.read_csv(_p, encoding='utf-8', on_bad_lines='skip'), _p
                except Exception:
                    try:
                        return pd.read_csv(_p, encoding='latin-1', on_bad_lines='skip'), _p
                    except Exception:
                        pass
        return None, None

    # ‚îÄ‚îÄ Optional file override (always visible in sidebar) ‚îÄ‚îÄ
    with st.expander("üìÇ Upload different file (optional)", expanded=False):
        _uploaded = st.file_uploader(
            "CSV or Excel ‚Äî replaces the default dataset",
            type=["csv", "xlsx"],
            key="override_upload",
            label_visibility="collapsed"
        )
        st.caption(f"Default: **{DEFAULT_CSV}** (auto-loaded)")

    _load_btn = st.button("üîÑ Refresh Data", type="secondary", use_container_width=True)

    # ‚îÄ‚îÄ Load logic: DB ‚Üí Upload ‚Üí Default CSV ‚îÄ‚îÄ
    if _load_btn or "raw_df" not in st.session_state:
        if SUPABASE_URL and SUPABASE_KEY:
            with st.spinner("Loading from database‚Ä¶"):
                _df_raw, _err = _load_from_supabase(SUPABASE_URL, SUPABASE_KEY, DB_TABLE)
            if _df_raw is not None:
                raw = _parse_dates(_df_raw)
                st.session_state.raw_df  = raw
                st.session_state["_src"] = "database"
                st.success(f"‚úÖ {len(raw):,} rows from database")
            else:
                st.error(f"‚ùå DB error: {_err}")
                st.stop()
        elif _uploaded:
            with st.spinner(f"Reading {_uploaded.name}‚Ä¶"):
                try:
                    raw = (pd.read_csv(_uploaded, encoding='utf-8', on_bad_lines='skip')
                           if _uploaded.name.endswith(".csv") else pd.read_excel(_uploaded))
                    raw = _parse_dates(raw)
                    st.session_state.raw_df  = raw
                    st.session_state["_src"] = _uploaded.name
                    st.success(f"‚úÖ {len(raw):,} rows from **{_uploaded.name}**")
                except Exception as _ue:
                    st.error(f"‚ùå Cannot read file: {_ue}")
                    st.stop()
        else:
            # Auto-load default CSV ‚Äî silent on success (no spinner needed for local file)
            _def_df, _def_path = _try_load_default()
            if _def_df is not None:
                raw = _parse_dates(_def_df)
                st.session_state.raw_df  = raw
                st.session_state["_src"] = DEFAULT_CSV
            elif "raw_df" not in st.session_state:
                st.error(f"‚ö†Ô∏è **{DEFAULT_CSV}** not found in app folder.")
                st.info("Place the file next to Weekly_Report.py, or expand 'üìÇ Upload' above.")
                st.stop()

    raw = st.session_state.raw_df
    _src_lbl = st.session_state.get("_src", DEFAULT_CSV)
    st.markdown(f"üìä **{len(raw):,} rows** ‚Äî `{_src_lbl}`")

    st.divider()
    st.subheader("üîç Global Filters")

    # ‚îÄ‚îÄ Date range ‚Äî default last 8 weeks (clamped to actual data range) ‚îÄ‚îÄ
    max_date = raw['DELIVERY DATE'].max()
    min_date = raw['DELIVERY DATE'].min()
    _8w_ago = (max_date - pd.Timedelta(weeks=8)).date()
    # Clamp: default_from must be >= min_date
    default_from_8w = max(_8w_ago, min_date.date())
    default_to_8w   = max_date.date()

    date_range = st.date_input(
        "Date Range",
        value=[default_from_8w, default_to_8w],
        min_value=min_date.date(),
        max_value=max_date.date(),
        help="Defaults to last 8 weeks for trend analysis. Narrow down as needed."
    )

    cities = sorted(raw['BUSINESS CITY'].dropna().unique())
    city_sel = st.multiselect("Business City", cities, placeholder="All cities")

    businesses = sorted(raw['BUSINESS NAME'].dropna().unique())
    biz_sel = st.multiselect("Business Name", businesses, placeholder="All businesses")

    hour_opt = st.selectbox("Time Period",
        ["All Day","Morning (7‚Äì11)","Afternoon (12‚Äì16)","Evening (17‚Äì22)",
         "Late Night (23‚Äì2)","Custom"])
    custom_hours = []
    if hour_opt == "Custom":
        custom_hours = st.multiselect("Hours", OPERATING_HOURS)

    st.divider()
    st.caption(f"Data spans {min_date.date()} ‚Üí {max_date.date()}")

    st.divider()
    st.markdown("#### üå§Ô∏è Weather Forecast")
    st.caption("AI weather outlook for Tanzania cities")
    if st.button("Generate Forecast", key="btn_weather_sidebar", use_container_width=True):
        st.session_state["show_weather_sidebar"] = True
    if st.session_state.get("show_weather_sidebar"):
        from datetime import date as _dt2, timedelta as _td2
        _today2 = _dt2.today()
        _days_ahead2 = [(_today2 + _td2(days=i)).strftime("%a %d %b") for i in range(1, 8)]
        _days_str2 = ", ".join(_days_ahead2)
        _wp2 = f"""Generate a 7-day weather summary for Tanzania food delivery operations ({_days_str2}).
Cities: Dar es Salaam, Arusha, Dodoma, Zanzibar, Mwanza.
Return ONLY a JSON array like:
[{{"Date":"Mon 03 Mar","City":"Dar es Salaam","Condition":"Partly Cloudy","Temp_C":31,"Rain_Risk_Pct":25,"Delivery_Impact":"Normal"}}]
Rules: Rain_Risk_Pct 0-100, Delivery_Impact: Normal/Moderate/High Impact."""
        with st.spinner("Generating forecast‚Ä¶"):
            try:
                _cl2 = anthropic.Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY",""))
                _wr2 = _cl2.messages.create(model="claude-opus-4-6", max_tokens=1200,
                    messages=[{"role":"user","content":_wp2}])
                _wt2 = _wr2.content[0].text.strip()
                import json as _json2
                _wj2 = _json2.loads(_wt2.replace("```json","").replace("```","").strip())
                _wdf2 = pd.DataFrame(_wj2)
                for _wd_row in _wdf2.itertuples():
                    _rain = getattr(_wd_row,"Rain_Risk_Pct",0)
                    _color = "üî¥" if _rain >= 70 else ("üü°" if _rain >= 40 else "üü¢")
                    st.markdown(f"**{getattr(_wd_row,'Date','')} ‚Äî {getattr(_wd_row,'City','')}**  \n"
                                f"{_color} {getattr(_wd_row,'Condition','')} ¬∑ {getattr(_wd_row,'Temp_C','')}¬∞C ¬∑ "
                                f"Rain {_rain}% ¬∑ {getattr(_wd_row,'Delivery_Impact','')}")
            except Exception as _we2:
                st.error(f"Forecast error: {_we2}")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# APPLY GLOBAL FILTERS ‚Üí produce `df`
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
df = raw.copy()

if len(date_range) == 2:
    df = df[(df['DELIVERY DATE'] >= pd.to_datetime(date_range[0])) &
            (df['DELIVERY DATE'] <= pd.to_datetime(date_range[1]))]
if city_sel:
    df = df[df['BUSINESS CITY'].isin(city_sel)]
if biz_sel:
    df = df[df['BUSINESS NAME'].isin(biz_sel)]

df['HOUR'] = df['DELIVERY TIME'].dt.hour
df = df[df['HOUR'].isin(OPERATING_HOURS)]

if hour_opt == "Morning (7‚Äì11)":
    df = df[df['HOUR'].between(7, 11)]
elif hour_opt == "Afternoon (12‚Äì16)":
    df = df[df['HOUR'].between(12, 16)]
elif hour_opt == "Evening (17‚Äì22)":
    df = df[df['HOUR'].between(17, 22)]
elif hour_opt == "Late Night (23‚Äì2)":
    df = df[(df['HOUR'] >= 23) | (df['HOUR'] <= 2)]
elif hour_opt == "Custom" and custom_hours:
    df = df[df['HOUR'].isin(custom_hours)]

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# HEADER
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.title("üìä Piki Weekly Business Intelligence")

city_label = ", ".join(city_sel) if city_sel else "All Cities"
biz_label  = f"{len(biz_sel)} businesses" if biz_sel else "All Businesses"
st.markdown(
    f"**Active filters:** üìÖ `{date_range[0]} ‚Üí {date_range[1]}` &nbsp;|&nbsp; "
    f"üèôÔ∏è `{city_label}` &nbsp;|&nbsp; üè™ `{biz_label}` &nbsp;|&nbsp; ‚è∞ `{hour_opt}`"
)

if df.empty:
    st.error("No data matches the current filters. Adjust the filters in the sidebar.")
    st.stop()

# ‚îÄ‚îÄ Quick KPI bar ‚Äî CURRENT WEEK ONLY with WoW direction ‚îÄ‚îÄ
_kpi_df = df.copy()
_kpi_df['DELIVERY DATE'] = pd.to_datetime(_kpi_df['DELIVERY DATE'], errors='coerce')
_kpi_df['_kpi_wk'] = _kpi_df['DELIVERY DATE'].dt.to_period('W-SUN')
_kpi_wks_sorted = sorted(_kpi_df['_kpi_wk'].dropna().unique(), reverse=True)
_kpi_cur_wk  = _kpi_wks_sorted[0]  if len(_kpi_wks_sorted) >= 1 else None
_kpi_prev_wk = _kpi_wks_sorted[1]  if len(_kpi_wks_sorted) >= 2 else None

def _kpi_subset(wk):
    if wk is None: return pd.DataFrame()
    return _kpi_df[_kpi_df['_kpi_wk'] == wk]

_cur  = _kpi_subset(_kpi_cur_wk)
_prev = _kpi_subset(_kpi_prev_wk)

def _delta_str(cur_val, prev_val, pct=True, invert=False):
    """Return delta string with direction arrow and % or absolute."""
    if prev_val == 0 or pd.isna(prev_val): return None
    diff = cur_val - prev_val
    pct_val = diff / prev_val * 100
    arrow = "‚ñ≤" if diff > 0 else "‚ñº"
    if invert:  # for failed orders, up is bad
        arrow = "‚ñº" if diff > 0 else "‚ñ≤"
    if pct:
        return f"{arrow} {abs(pct_val):.1f}%  WoW"
    return f"{arrow} {abs(diff):,.0f}  WoW"

def _delta_col(cur_val, prev_val, invert=False):
    if prev_val == 0: return "off"
    return ("inverse" if invert else "normal") if cur_val >= prev_val else ("normal" if invert else "inverse")

# Current week values
total_orders   = len(_cur)
total_sales    = _cur['SUBTOTAL'].sum()    if 'SUBTOTAL'     in _cur.columns else 0
total_failed   = len(_cur[_cur['STATE'] == 'Delivery Failed By Driver']) if 'STATE' in _cur.columns else 0
unique_biz     = _cur['BUSINESS NAME'].nunique()
unique_drivers = _cur['DRIVER NAME'].nunique() if 'DRIVER NAME' in _cur.columns else 0

# Previous week values
prev_orders   = len(_prev) if not _prev.empty else 0
prev_sales    = _prev['SUBTOTAL'].sum()    if (not _prev.empty and 'SUBTOTAL' in _prev.columns) else 0
prev_failed   = len(_prev[_prev['STATE'] == 'Delivery Failed By Driver']) if (not _prev.empty and 'STATE' in _prev.columns) else 0
prev_biz      = _prev['BUSINESS NAME'].nunique() if not _prev.empty else 0
prev_drivers  = _prev['DRIVER NAME'].nunique()   if (not _prev.empty and 'DRIVER NAME' in _prev.columns) else 0

_wk_lbl = f"Wk {_kpi_cur_wk.week} ({_kpi_cur_wk.start_time.strftime('%d %b')})" if _kpi_cur_wk else "Current"

col1, col2, col3, col4, col5 = st.columns(5)
col1.metric(f"üì¶ Orders ‚Äî {_wk_lbl}", f"{total_orders:,}",
            delta=_delta_str(total_orders, prev_orders),
            delta_color=_delta_col(total_orders, prev_orders))
col2.metric(f"üí∞ Sales ‚Äî {_wk_lbl}", f"{total_sales/1_000_000:.1f}M TZS",
            delta=_delta_str(total_sales, prev_sales),
            delta_color=_delta_col(total_sales, prev_sales))
col3.metric(f"‚ùå Failed ‚Äî {_wk_lbl}", f"{total_failed}",
            delta=_delta_str(total_failed, prev_failed, pct=False, invert=True),
            delta_color=_delta_col(total_failed, prev_failed, invert=True))
col4.metric(f"üè™ Businesses ‚Äî {_wk_lbl}", f"{unique_biz}",
            delta=_delta_str(unique_biz, prev_biz, pct=False),
            delta_color=_delta_col(unique_biz, prev_biz))
col5.metric(f"üö¥ Riders ‚Äî {_wk_lbl}", f"{unique_drivers}",
            delta=_delta_str(unique_drivers, prev_drivers, pct=False),
            delta_color=_delta_col(unique_drivers, prev_drivers))

st.divider()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# MAIN TABS
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìà Weekly Trends",
    "‚è∞ Delivery Times",
    "üö¥ Rider Attendance",
    "üì¶ Products & Geo",
    "üéâ Piki Party Store",
    "üîó Quick Access & Tools",
])

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# TAB 1 ‚Äî WEEKLY TRENDS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
with tab1:
    st.markdown('<div class="section-header">üìà Orders & Sales KPI Trend</div>', unsafe_allow_html=True)

    # ‚îÄ‚îÄ Per-chart city filter ‚îÄ‚îÄ
    _t1_cities_all = sorted(df['BUSINESS CITY'].dropna().unique().tolist())
    _t1_city_f = st.multiselect(
        "üèôÔ∏è Filter by City", _t1_cities_all,
        placeholder="All cities (or select one/more)",
        key="t1_orders_city"
    )
    _df_t1 = df[df['BUSINESS CITY'].isin(_t1_city_f)] if _t1_city_f else df.copy()
    if _t1_city_f:
        st.caption(f"Showing: **{', '.join(_t1_city_f)}**")

    # ‚îÄ‚îÄ Weekly aggregation ‚îÄ‚îÄ
    weekly = (
        _df_t1.groupby(_df_t1['DELIVERY DATE'].dt.to_period('W-SUN'))
        .agg(Total_Orders=('ID','count'), Total_Sales=('SUBTOTAL','sum'))
        .reset_index()
    )
    weekly['Week']       = weekly['DELIVERY DATE'].dt.start_time
    weekly['Week_Label'] = weekly['DELIVERY DATE'].apply(
        lambda p: f"W{p.week} ({p.start_time.strftime('%d %b')})"
    )
    weekly = apply_growth_kpi(weekly)

    # ‚îÄ‚îÄ Chart ‚îÄ‚îÄ
    fig, ax1 = plt.subplots(figsize=(13, 5))
    ax1.plot(weekly['Week_Label'], weekly['Total_Orders'],
             color='#FF6B00', marker='o', lw=2, label='Total Orders')
    if 'Growth KPI Orders' in weekly.columns:
        ax1.plot(weekly['Week_Label'], weekly['Growth KPI Orders'],
                 color='green', lw=2, linestyle='--', label='1.2% Growth KPI')
    ax1.set_ylabel("Orders"); ax1.grid(True, alpha=0.3)
    ax2 = ax1.twinx()
    ax2.bar(weekly['Week_Label'], weekly['Total_Sales'],
            alpha=0.25, color='#ff7f0e', label='Sales (TZS)')
    ax2.set_ylabel("Sales (TZS)"); ax2.yaxis.set_major_formatter(fmt_millions)
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1+lines2, labels1+labels2, loc='upper left', fontsize=9)
    _city_title = f" ‚Äî {', '.join(_t1_city_f)}" if _t1_city_f else " ‚Äî All Cities"
    plt.title(f"Weekly Orders vs Sales vs KPI{_city_title}"); plt.xticks(rotation=30, ha='right')
    plt.tight_layout(); st.pyplot(fig); plt.close()

    st.dataframe(
        weekly[['Week_Label','Total_Orders','Growth KPI Orders','Total_Sales']].rename(
            columns={'Week_Label':'Week','Total_Orders':'Orders',
                     'Growth KPI Orders':'KPI Target','Total_Sales':'Sales (TZS)'}
        ), use_container_width=True
    )

    # ‚îÄ‚îÄ Regional Manager Excel Download ‚îÄ‚îÄ
    st.markdown('<div class="section-header">üì• Regional Manager Report ‚Äî Download by City</div>', unsafe_allow_html=True)
    st.caption("One Excel sheet per city: weekly summary, operations KPIs with issue filtering, top vendors, top drivers.")

    _reg_btn_key = "reg_report_ready"
    if _reg_btn_key not in st.session_state:
        st.session_state[_reg_btn_key] = None

    if st.button("‚öôÔ∏è Generate Regional Report", key="btn_regional_excel", type="secondary", use_container_width=False):
        from openpyxl import Workbook as _OXLWorkbook
        from openpyxl.styles import Font as _OXLFont, PatternFill as _OXLFill
        from openpyxl.utils.dataframe import dataframe_to_rows as _df2rows

        _reg_wb = _OXLWorkbook()
        _reg_wb.remove(_reg_wb.active)

        # ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        def _categorize_issues(row):
            issues = []
            if row['Accepted by Business'] < 0 or row['Accepted by Business'] > 30:
                issues.append("Accepted by Business Out of Range")
            if row['Assigned Time'] < 0 or row['Assigned Time'] > 30:
                issues.append("Assigned Time Out of Range")
            if row['Accepted by Driver'] < 0 or row['Accepted by Driver'] > 45:
                issues.append("Accepted by Driver Out of Range")
            if row['Driver to Business'] < 0 or row['Driver to Business'] > 45:
                issues.append("Driver to Business Out of Range")
            if row['Driver in Business'] < 0 or row['Driver in Business'] > 90:
                issues.append("Driver in Business Out of Range")
            if row['Pickup to Customer'] < 0 or row['Pickup to Customer'] > 45:
                issues.append("Pickup to Customer Out of Range")
            if row['Average Delivery Time'] < 0 or row['Average Delivery Time'] > 100:
                issues.append("Average Delivery Time Out of Range")
            return ", ".join(issues)

        def _reg_write_section(_ws, title, dataframe, start_row):
            if dataframe is None or dataframe.empty:
                return start_row + 2
            _ws.merge_cells(start_row=start_row, start_column=1,
                            end_row=start_row, end_column=max(len(dataframe.columns), 1))
            _tc = _ws.cell(row=start_row, column=1, value=title)
            _tc.font = _OXLFont(bold=True, color="FFFFFF")
            _tc.fill = _OXLFill(start_color="4F81BD", end_color="4F81BD", fill_type="solid")
            for _r_i, _row in enumerate(_df2rows(dataframe, index=False, header=True), start=start_row+1):
                for _c_i, _val in enumerate(_row, start=1):
                    _cell = _ws.cell(row=_r_i, column=_c_i, value=_val)
                    if _r_i == start_row + 1:  # header row
                        _cell.font = _OXLFont(bold=True)
                        _cell.fill = _OXLFill(start_color="FFC000", end_color="FFC000", fill_type="solid")
            return start_row + len(dataframe) + 3

        # ‚îÄ‚îÄ Build per-city sheets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _reg_cities = sorted(df['BUSINESS CITY'].dropna().unique())
        _df_completed_all = df[df['STATE'].isin(['Delivery Completed By Driver','Completed'])].copy()

        # Ensure datetime columns parsed on the full dataframe
        for _tc_col in ['DELIVERY TIME','ACCEPTED BUSINESS HOUR','ASSIGNED HOUR',
                         'ACCEPTED DRIVER HOUR','IN BUSINESS HOUR','PICKUP HOUR','DELIVERY HOUR']:
            if _tc_col in _df_completed_all.columns:
                _df_completed_all[_tc_col] = pd.to_datetime(_df_completed_all[_tc_col], errors='coerce')

        _prog = st.progress(0, text="Building city reports‚Ä¶")
        for _ci, _rcity in enumerate(_reg_cities):
            _prog.progress(int((_ci / max(len(_reg_cities), 1)) * 100),
                           text=f"Building: {_rcity}‚Ä¶")

            _df_c   = df[df['BUSINESS CITY'] == _rcity].copy()
            _df_c_c = _df_completed_all[_df_completed_all['BUSINESS CITY'] == _rcity].copy()
            if _df_c.empty:
                continue

            # Week label using period (matches the main dashboard format)
            _df_c['Week']   = _df_c['DELIVERY DATE'].dt.to_period('W-SUN').apply(
                lambda p: f"Week {p.week} ({p.start_time.strftime('%d %b')})")
            if not _df_c_c.empty:
                _df_c_c['Week'] = _df_c_c['DELIVERY DATE'].dt.to_period('W-SUN').apply(
                    lambda p: f"Week {p.week} ({p.start_time.strftime('%d %b')})")

            # ‚îÄ‚îÄ Weekly summary ‚îÄ‚îÄ
            _wk_sum = (_df_c.groupby('Week', sort=False)
                       .agg(**{'Total Orders': ('ID','count')})
                       .reset_index())
            if not _df_c_c.empty:
                _wk_sum['Completed Orders'] = (_df_c_c.groupby('Week')['ID'].count()
                                               .reindex(_wk_sum['Week'], fill_value=0).values)
                _wk_sum['Total Sales (TZS)'] = (_df_c_c.groupby('Week')['SUBTOTAL'].sum()
                                                .reindex(_wk_sum['Week'], fill_value=0).values)
            else:
                _wk_sum['Completed Orders']  = 0
                _wk_sum['Total Sales (TZS)'] = 0

            # ‚îÄ‚îÄ Operations KPIs ‚Äî exact logic from reference code ‚îÄ‚îÄ
            _df_ops = _df_c_c.copy() if not _df_c_c.empty else pd.DataFrame()
            _ops_kpi = pd.DataFrame()
            if not _df_ops.empty:
                # Calculate each stage
                _df_ops['Accepted by Business'] = (
                    (_df_ops['ACCEPTED BUSINESS HOUR'] - _df_ops['DELIVERY TIME'])
                    .dt.total_seconds() / 60)
                _df_ops['Accepted by Business'] = _df_ops['Accepted by Business'].mask(
                    _df_ops['Accepted by Business'] < 0, 0)

                _df_ops['Assigned Time'] = (
                    (_df_ops['ASSIGNED HOUR'] - _df_ops['ACCEPTED BUSINESS HOUR'])
                    .dt.total_seconds() / 60)
                _df_ops['Assigned Time'] = _df_ops['Assigned Time'].mask(
                    _df_ops['Assigned Time'] < 0, 3)

                _df_ops['Accepted by Driver'] = (
                    (_df_ops['ACCEPTED DRIVER HOUR'] - _df_ops['ASSIGNED HOUR'])
                    .dt.total_seconds() / 60)
                _df_ops['Accepted by Driver'] = _df_ops['Accepted by Driver'].mask(
                    _df_ops['Accepted by Driver'] < 0, 3)

                _df_ops['Driver to Business'] = (
                    (_df_ops['IN BUSINESS HOUR'] - _df_ops['ACCEPTED DRIVER HOUR'])
                    .dt.total_seconds() / 60)
                _df_ops['Driver to Business'] = _df_ops['Driver to Business'].mask(
                    _df_ops['Driver to Business'] < 0, 7)

                _df_ops['Driver in Business'] = (
                    (_df_ops['PICKUP HOUR'] - _df_ops['IN BUSINESS HOUR'])
                    .dt.total_seconds() / 60)
                _df_ops['Driver in Business'] = _df_ops['Driver in Business'].mask(
                    _df_ops['Driver in Business'] < 0, 15)

                _df_ops['Pickup to Customer'] = (
                    (_df_ops['DELIVERY HOUR'] - _df_ops['PICKUP HOUR'])
                    .dt.total_seconds() / 60)
                _df_ops['Pickup to Customer'] = _df_ops['Pickup to Customer'].mask(
                    _df_ops['Pickup to Customer'] < 0, 15)

                _df_ops['Average Delivery Time'] = (
                    (_df_ops['DELIVERY HOUR'] - _df_ops['DELIVERY TIME'])
                    .dt.total_seconds() / 60)
                _df_ops['Average Delivery Time'] = _df_ops['Average Delivery Time'].mask(
                    _df_ops['Average Delivery Time'] < 0,
                    (_df_ops['DELIVERY HOUR'] - _df_ops['ACCEPTED BUSINESS HOUR'])
                    .dt.total_seconds() / 60)
                _df_ops['Average Delivery Time'] = _df_ops['Average Delivery Time'].mask(
                    _df_ops['Average Delivery Time'] < 0, 40)

                # Filter out rows with out-of-range values (exact logic from reference)
                _df_ops['_Issues'] = _df_ops.apply(_categorize_issues, axis=1)
                _df_ops = _df_ops[_df_ops['_Issues'] == '']

                if not _df_ops.empty and 'Week' in _df_ops.columns:
                    _kpi_metric_cols = ['Accepted by Business','Assigned Time','Accepted by Driver',
                                        'Driver to Business','Driver in Business','Pickup to Customer',
                                        'Average Delivery Time']
                    _ops_kpi = (_df_ops.groupby('Week', sort=False)[_kpi_metric_cols]
                                .mean().round(1).reset_index())
                    _ops_kpi['Average Delivery Time % Change'] = (
                        _ops_kpi['Average Delivery Time'].pct_change() * 100).round(1)

            # ‚îÄ‚îÄ Latest week top lists ‚îÄ‚îÄ
            _latest_wk = _df_c['Week'].max() if not _df_c.empty else None
            _recent    = _df_c[_df_c['Week'] == _latest_wk] if _latest_wk else pd.DataFrame()

            _top_vendors = (
                _recent.groupby('BUSINESS NAME')
                .agg(**{'Total Orders': ('ID','count'), 'Total Sales': ('SUBTOTAL','sum')})
                .reset_index().sort_values('Total Orders', ascending=False).head(10)
            ) if not _recent.empty else pd.DataFrame()

            _top_drivers = (
                _recent.groupby('DRIVER NAME')
                .agg(**{'Total Deliveries': ('ID','count')})
                .reset_index().sort_values('Total Deliveries', ascending=False).head(10)
            ) if not _recent.empty else pd.DataFrame()

            # ‚îÄ‚îÄ Create worksheet ‚îÄ‚îÄ
            _ws = _reg_wb.create_sheet(title=_rcity[:31])
            _cur_row = 1
            _cur_row = _reg_write_section(
                _ws, f"Weekly Summary ‚Äî {_rcity}", _wk_sum, _cur_row)
            _cur_row = _reg_write_section(
                _ws, "Operations KPIs (Completed, outliers filtered)", _ops_kpi, _cur_row)
            _cur_row = _reg_write_section(
                _ws, f"Top 10 Vendors ‚Äî {_latest_wk}", _top_vendors, _cur_row)
            _cur_row = _reg_write_section(
                _ws, f"Top 10 Drivers ‚Äî {_latest_wk}", _top_drivers, _cur_row)

        _prog.progress(100, text="‚úÖ Done!")

        # ‚îÄ‚îÄ Save & store in session ‚îÄ‚îÄ
        _reg_buf = io.BytesIO()
        _reg_wb.save(_reg_buf)
        _reg_buf.seek(0)
        st.session_state[_reg_btn_key] = _reg_buf.getvalue()

    # Show download button once generated
    if st.session_state.get(_reg_btn_key):
        st.download_button(
            "üì• Download Regional Report (Excel)",
            data=st.session_state[_reg_btn_key],
            file_name=f"Weekly_Report_By_City_{pd.Timestamp.today().strftime('%b_%d_%Y')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="dl_regional_excel"
        )
        st.success("‚úÖ Regional report ready ‚Äî one sheet per city with summary, KPIs, vendors and drivers.")
    # ‚îÄ‚îÄ City KPI Summary Table (always visible, no AI needed) ‚îÄ‚îÄ
    if 'BUSINESS CITY' in df.columns and len(weekly) >= 2:
        st.markdown("#### üìä City Performance vs 1.2% Weekly Growth KPI")
        # Build ISO year+week key directly from df so it matches regardless of Week_Label format
        _df_tr = df.copy()
        _df_tr['_iso_yr'] = _df_tr['DELIVERY DATE'].dt.isocalendar().year
        _df_tr['_iso_wk'] = _df_tr['DELIVERY DATE'].dt.isocalendar().week
        _df_tr['_yw']     = (_df_tr['_iso_yr'].astype(str)
                             + "-W" + _df_tr['_iso_wk'].astype(str).str.zfill(2))
        # Get 2 most recent distinct year-week combinations from data
        _yw_pairs = (_df_tr[['_iso_yr','_iso_wk','_yw']]
                     .drop_duplicates()
                     .sort_values(['_iso_yr','_iso_wk']))
        if len(_yw_pairs) >= 2:
            _yw_cur  = _yw_pairs.iloc[-1]['_yw']
            _yw_prev = _yw_pairs.iloc[-2]['_yw']
            _city_now  = (_df_tr[_df_tr['_yw']==_yw_cur]
                          .groupby('BUSINESS CITY')
                          .agg(Orders_Now=('ID','count'), Sales_Now=('SUBTOTAL','sum'))
                          .reset_index())
            _city_prev = (_df_tr[_df_tr['_yw']==_yw_prev]
                          .groupby('BUSINESS CITY')
                          .agg(Orders_Prev=('ID','count'))
                          .reset_index())

            # ‚îÄ‚îÄ 7-week rolling average per city ‚îÄ‚îÄ
            _prev7_pairs = (_df_tr[['_iso_yr','_iso_wk','_yw']]
                            .drop_duplicates()
                            .sort_values(['_iso_yr','_iso_wk'])
                            .iloc[:-1].tail(7))
            _prev7_yw_list = _prev7_pairs['_yw'].tolist()
            _city_7wk = (_df_tr[_df_tr['_yw'].isin(_prev7_yw_list)]
                         .groupby(['BUSINESS CITY','_yw'])
                         .agg(Wk_Orders=('ID','count')).reset_index()
                         .groupby('BUSINESS CITY')['Wk_Orders'].mean()
                         .reset_index().rename(columns={'Wk_Orders':'Avg_7Wk'}))

            _city_tbl = pd.merge(_city_now, _city_prev, on='BUSINESS CITY', how='outer').fillna(0)
            _city_tbl = pd.merge(_city_tbl, _city_7wk, on='BUSINESS CITY', how='left').fillna(0)
            _city_tbl['Orders_Now']  = _city_tbl['Orders_Now'].astype(int)
            _city_tbl['Orders_Prev'] = _city_tbl['Orders_Prev'].astype(int)
            _city_tbl['Delta']       = _city_tbl['Orders_Now'] - _city_tbl['Orders_Prev']
            _city_tbl['Orders vs Last Week'] = (
                _city_tbl['Orders_Now'].astype(str)
                + " (" + _city_tbl['Delta'].apply(lambda x: f"{x:+d}") + ")")
            _city_tbl['WoW %'] = (
                _city_tbl['Delta'] / _city_tbl['Orders_Prev'].replace(0, 1) * 100).round(1)
            _city_tbl['KPI Target (+1.2%)'] = (_city_tbl['Orders_Prev'] * 1.012).round(0).astype(int)
            _city_tbl['vs KPI']    = (_city_tbl['Orders_Now'] - _city_tbl['KPI Target (+1.2%)']).astype(int)
            _city_tbl['KPI Status'] = _city_tbl['vs KPI'].apply(
                lambda x: '‚úÖ Beat KPI' if x >= 0 else f'‚ùå -{abs(x)} short')
            _city_tbl['7-Wk Avg'] = _city_tbl['Avg_7Wk'].round(0).astype(int)
            _city_tbl['vs 7-Wk Avg'] = (_city_tbl['Orders_Now'] - _city_tbl['Avg_7Wk']).round(0).astype(int)
            _city_tbl['vs 7-Wk %'] = (
                (_city_tbl['Orders_Now'] - _city_tbl['Avg_7Wk']) /
                _city_tbl['Avg_7Wk'].replace(0, 1) * 100).round(1)
            _city_tbl['Recommendation'] = _city_tbl.apply(lambda r: (
                f"üî¥ Urgent ‚Äî {abs(int(r['vs KPI']))} below KPI & below 7wk avg"
                if (r['vs KPI'] < -10 and r['vs 7-Wk Avg'] < 0) else (
                "üî¥ KPI miss ‚Äî investigate drop" if r['vs KPI'] < -10 else (
                "üü° Close ‚Äî small push to hit KPI" if r['vs KPI'] < 0 else (
                "üü¢ Strong ‚Äî sustain" if r['WoW %'] > 5
                else "‚úÖ On track")))), axis=1)
            _city_tbl['Sales (TZS)'] = _city_tbl['Sales_Now'].apply(lambda x: f"{int(x):,}")
            _kpi_tbl_disp = (_city_tbl[['BUSINESS CITY','Orders vs Last Week','WoW %',
                                        'KPI Target (+1.2%)','KPI Status',
                                        '7-Wk Avg','vs 7-Wk Avg','vs 7-Wk %',
                                        'Sales (TZS)','Recommendation']]
                             .sort_values('WoW %', ascending=False)
                             .reset_index(drop=True))
            _kpi_tbl_disp.index = range(1, len(_kpi_tbl_disp)+1)
            st.dataframe(_kpi_tbl_disp, use_container_width=True)
            st.download_button("‚¨áÔ∏è City KPI Table (Excel)",
                data=excel_bytes(_kpi_tbl_disp.reset_index(drop=True), "City KPI"),
                file_name=f"City_KPI_{_yw_cur}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="dl_city_kpi")
        else:
            st.info("Need at least 2 weeks of data to show city KPI comparison.")

    # ‚îÄ‚îÄ Auto-running AI insight ‚îÄ‚îÄ
    _tr_ins_key = "trend_auto_insight"
    if _tr_ins_key not in st.session_state:
        st.session_state[_tr_ins_key] = None
    _tr_ctx_hash = str(hash(weekly['Week_Label'].iloc[-1] + str(weekly['Total_Orders'].iloc[-1])))
    if (st.session_state[_tr_ins_key] is None or
            st.session_state.get(_tr_ins_key + "_hash") != _tr_ctx_hash):
        with st.spinner("ü§ñ Analyzing trend‚Ä¶"):
            _tr_ins, _tr_ctx = build_trend_insight(weekly, df)
            st.session_state[_tr_ins_key] = (_tr_ins, _tr_ctx)
            st.session_state[_tr_ins_key + "_hash"] = _tr_ctx_hash
    if st.session_state[_tr_ins_key]:
        _tr_ins, _tr_ctx = st.session_state[_tr_ins_key]
        ai_block("trend_orders", _tr_ctx, _tr_ins)
    # Refresh button
    _tr_c1, _ = st.columns([2, 3])
    if _tr_c1.button("‚Ü∫ Refresh Trend Insight", key="btn_trend_refresh"):
        st.session_state[_tr_ins_key] = None
        st.rerun()


    # ‚îÄ‚îÄ Failed & Rejected Orders ‚îÄ‚îÄ
    st.markdown('<div class="section-header">‚ùå Failed & Rejected Orders Analysis</div>', unsafe_allow_html=True)

    if 'STATE' not in df.columns:
        st.info("STATE column not found.")
    else:
        failed_df   = df[df['STATE'] == 'Delivery Failed By Driver'].copy()
        rejected_df = df[df['STATE'].str.contains('Rejected|rejected', na=False)].copy()

        c1, c2 = st.columns(2)
        c1.metric("Total Failed (period)", len(failed_df),
                  delta=f"KPI ‚â§ {FAILED_KPI}/week",
                  delta_color="off")
        c2.metric("Total Rejected (period)", len(rejected_df))

        # Weekly trend chart
        def _weekly_state_trend(state_df, label, color, kpi_line=None):
            if state_df.empty:
                return None
            state_df = state_df.copy()
            state_df['ISO_Y'] = state_df['DELIVERY DATE'].dt.isocalendar().year
            state_df['ISO_W'] = state_df['DELIVERY DATE'].dt.isocalendar().week
            wk = (state_df.groupby(['ISO_Y','ISO_W']).size()
                  .reset_index(name=label))
            wk['Week_Label'] = (wk['ISO_Y'].astype(str)+"-W"+
                                wk['ISO_W'].astype(str).str.zfill(2))
            fig, ax = plt.subplots(figsize=(12, 4))
            ax.plot(wk['Week_Label'], wk[label], marker='o', color=color, lw=2, label=label)
            if kpi_line:
                ax.axhline(kpi_line, linestyle='--', color='orange', lw=2,
                           label=f'KPI ({kpi_line})')
            ax.set_xlabel("Week"); ax.set_ylabel("Count"); ax.grid(True, alpha=0.3)
            ax.legend(); plt.xticks(rotation=45, ha='right'); plt.tight_layout()
            return fig, wk

        if not failed_df.empty:
            result = _weekly_state_trend(failed_df, "Failed Orders", "#d62728", FAILED_KPI)
            if result:
                fig_f, failed_weekly = result
                st.pyplot(fig_f); plt.close()

                # Day √ó City pivot for selected week
                failed_weekly_wl = failed_weekly.copy()
                week_opts = failed_weekly_wl['Week_Label'].tolist()
                sel_week = st.selectbox("Select Week for Breakdown", week_opts,
                                        index=len(week_opts)-1, key="failed_week_sel")
                yr, wn = int(sel_week.split("-W")[0]), int(sel_week.split("-W")[1])
                w_start = pd.to_datetime(f"{yr}-W{wn}-1", format='%G-W%V-%u')
                w_end   = w_start + pd.Timedelta(days=6)
                wf      = failed_df[(failed_df['DELIVERY DATE'] >= w_start) &
                                    (failed_df['DELIVERY DATE'] <= w_end)].copy()
                wf['Day'] = wf['DELIVERY DATE'].dt.day_name()

                pivot = pd.pivot_table(wf, index='BUSINESS CITY', columns='Day',
                                       values='ID', aggfunc='count', fill_value=0)
                pivot = pivot.reindex(columns=DAY_NAMES, fill_value=0)
                pivot['Total'] = pivot.sum(axis=1)
                total_row = pivot.sum().to_frame().T; total_row.index = ['TOTAL']
                pivot = pd.concat([pivot, total_row])
                tot = int(pivot.loc['TOTAL','Total'])
                pivot['Status'] = ""
                pivot.loc['TOTAL','Status'] = (
                    "‚úÖ Within KPI" if tot <= FAILED_KPI
                    else f"‚ùå Over by {tot - FAILED_KPI}"
                )
                st.dataframe(pivot.style.set_properties(**{'text-align':'center'}),
                             use_container_width=True)
                st.download_button("‚¨áÔ∏è Download Failed Orders",
                                   data=excel_bytes(wf),
                                   file_name=f"failed_{sel_week}.xlsx",
                                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

                ai_insight_button("failed_orders", "Failed Orders", build_failed_insight, failed_weekly_wl, pivot, sel_week)

        if not rejected_df.empty:
            st.markdown("#### üö´ Rejected Orders Analysis")
            result_r = _weekly_state_trend(rejected_df, "Rejected Orders", "#9467bd")
            if result_r:
                fig_r, rej_weekly = result_r
                st.pyplot(fig_r); plt.close()

                # ‚îÄ‚îÄ Total orders per city (for % calculation) ‚îÄ‚îÄ
                _total_orders_by_city = df.groupby('BUSINESS CITY')['ID'].count()
                _total_orders_by_biz  = df.groupby('BUSINESS NAME')['ID'].count()
                _grand_total_orders   = len(df)

                # ‚îÄ‚îÄ City breakdown with % of total orders ‚îÄ‚îÄ
                _rej_city = (rejected_df.groupby('BUSINESS CITY')
                             .agg(Rejections=('ID','count'), Revenue_Lost=('SUBTOTAL','sum'))
                             .reset_index())
                _rej_city['Total Orders'] = _rej_city['BUSINESS CITY'].map(_total_orders_by_city).fillna(0).astype(int)
                _rej_city['% of City Orders'] = (
                    _rej_city['Rejections'] / _rej_city['Total Orders'].replace(0, 1) * 100
                ).round(1)
                _rej_city['% of All Rejected'] = (
                    _rej_city['Rejections'] / max(len(rejected_df), 1) * 100
                ).round(1)
                _rej_city = _rej_city.sort_values('Rejections', ascending=False)
                # Total row
                _rej_city_total = pd.DataFrame([{
                    'BUSINESS CITY': 'TOTAL',
                    'Rejections': _rej_city['Rejections'].sum(),
                    'Revenue_Lost': _rej_city['Revenue_Lost'].sum(),
                    'Total Orders': _grand_total_orders,
                    '% of City Orders': round(_rej_city['Rejections'].sum() / max(_grand_total_orders,1) * 100, 1),
                    '% of All Rejected': 100.0,
                }])
                _rej_city_disp = pd.concat([_rej_city, _rej_city_total], ignore_index=True)
                _rej_city_disp['Revenue_Lost'] = _rej_city_disp['Revenue_Lost'].apply(lambda x: f"{int(x):,} TZS")
                _rej_city_disp = _rej_city_disp.rename(columns={'BUSINESS CITY': 'City', 'Revenue_Lost': 'Revenue Lost'})

                # ‚îÄ‚îÄ Restaurant breakdown with % of restaurant's total orders ‚îÄ‚îÄ
                _rej_biz = (rejected_df.groupby('BUSINESS NAME')
                            .agg(Rejections=('ID','count'), Revenue_Lost=('SUBTOTAL','sum'))
                            .reset_index())
                _rej_biz['Total Orders'] = _rej_biz['BUSINESS NAME'].map(_total_orders_by_biz).fillna(0).astype(int)
                _rej_biz['Rejection %'] = (
                    _rej_biz['Rejections'] / _rej_biz['Total Orders'].replace(0, 1) * 100
                ).round(1)
                # Total row for restaurants
                _rej_biz_total = pd.DataFrame([{
                    'BUSINESS NAME': 'TOTAL',
                    'Rejections': _rej_biz['Rejections'].sum(),
                    'Revenue_Lost': _rej_biz['Revenue_Lost'].sum(),
                    'Total Orders': _grand_total_orders,
                    'Rejection %': round(_rej_biz['Rejections'].sum() / max(_grand_total_orders,1) * 100, 1),
                }])
                _total_lost = rejected_df['SUBTOTAL'].sum()

                # ‚îÄ‚îÄ Sort control ‚îÄ‚îÄ
                _sort_col, _sort_info = st.columns([2, 3])
                with _sort_col:
                    _rej_sort = st.radio(
                        "Sort restaurants by",
                        ["# Rejections (most first)", "Rejection % (highest first)"],
                        horizontal=True, key="rej_sort"
                    )
                with _sort_info:
                    st.caption("**Rejection %** = rejections √∑ restaurant's total completed orders. "
                               "High % on a restaurant with many orders = serious operational issue.")

                if _rej_sort == "Rejection % (highest first)":
                    _rej_biz = _rej_biz.sort_values('Rejection %', ascending=False).head(15)
                else:
                    _rej_biz = _rej_biz.sort_values('Rejections', ascending=False).head(15)

                _rej_biz_disp = pd.concat([_rej_biz, _rej_biz_total], ignore_index=True)
                _rej_biz_disp['Revenue_Lost'] = _rej_biz_disp['Revenue_Lost'].apply(lambda x: f"{int(x):,} TZS")
                _rej_biz_disp = _rej_biz_disp.rename(columns={
                    'BUSINESS NAME': 'Restaurant', 'Revenue_Lost': 'Revenue Lost'})

                _rj1, _rj2 = st.columns(2)
                with _rj1:
                    st.markdown("##### üèôÔ∏è Rejected Orders by City")
                    st.dataframe(_rej_city_disp, use_container_width=True)
                with _rj2:
                    st.markdown("##### üçΩÔ∏è Top Restaurants with Rejections")
                    st.dataframe(_rej_biz_disp, use_container_width=True)

                st.metric("üí∏ Total Revenue Lost to Rejections",
                          f"{_total_lost/1e6:.2f}M TZS",
                          delta=f"{len(rejected_df)} orders lost", delta_color="inverse")

                # ‚îÄ‚îÄ Rejected by Hour ‚Äî with city filter ‚îÄ‚îÄ
                st.markdown("##### üïê Rejected Orders by Hour of Day")
                _rh_cities = sorted(rejected_df['BUSINESS CITY'].dropna().unique().tolist())
                _rh_city_f = st.multiselect(
                    "üèôÔ∏è Filter by City (Hour chart)", _rh_cities,
                    placeholder="All cities", key="rej_hour_city"
                )
                _rej_hour_df = (rejected_df[rejected_df['BUSINESS CITY'].isin(_rh_city_f)]
                                if _rh_city_f else rejected_df.copy())
                _rej_hour = (pd.DataFrame() if 'HOUR' not in _rej_hour_df.columns
                             else _rej_hour_df.groupby('HOUR').size().reset_index(name='Rejections'))

                if not _rej_hour.empty:
                    fig_rh, ax_rh = plt.subplots(figsize=(12,4))
                    _rh_title = f"Rejected Orders by Hour{' ‚Äî ' + ', '.join(_rh_city_f) if _rh_city_f else ' ‚Äî All Cities'}"
                    ax_rh.bar(_rej_hour['HOUR'].astype(str).apply(lambda h: f"{int(h):02d}:00"),
                              _rej_hour['Rejections'], color='#9467bd', alpha=0.8)
                    ax_rh.set_title(_rh_title)
                    ax_rh.set_xlabel("Hour"); ax_rh.set_ylabel("Rejections")
                    ax_rh.grid(True, alpha=0.3, axis='y')
                    plt.xticks(rotation=45); plt.tight_layout()
                    st.pyplot(fig_rh); plt.close()

                # ‚îÄ‚îÄ AI insight ‚Äî auto-runs ‚îÄ‚îÄ
                _rej_ctx = (
                    f"REJECTED ORDERS ANALYSIS\n"
                    f"Total rejected: {len(rejected_df):,} | Revenue lost: {_total_lost/1e6:.2f}M TZS\n"
                    f"Rejection rate: {len(rejected_df)/max(len(df),1)*100:.1f}% of all orders\n\n"
                    f"BY CITY (with % of that city's total orders):\n{_rej_city_disp.to_string(index=False)}\n\n"
                    f"TOP BUSINESSES BY REJECTIONS (with rejection % of their orders):\n{_rej_biz_disp.head(10).to_string(index=False)}\n\n"
                    f"WEEKLY TREND:\n{rej_weekly[['Week_Label','Rejected Orders']].to_string(index=False)}"
                )
                _rej_prompt = (
                    "You are a senior operations analyst for Piki, a Tanzanian food delivery company.\n\n"
                    + _rej_ctx + "\n\n"
                    "Provide a deep rejected orders analysis:\n"
                    "1. **Rejection Trend** ‚Äî Is it improving or worsening week over week? Key inflection points.\n"
                    "2. **Worst Offenders** ‚Äî Which restaurants have the highest rejections? What might cause this (capacity, hours, system)?\n"
                    "3. **City Concentration** ‚Äî Which cities drive the most rejections? Is it proportional to their order volume?\n"
                    "4. **Revenue Impact** ‚Äî Quantify the financial loss. If this rate continues, what is the monthly revenue at risk?\n"
                    "5. **Time Pattern** ‚Äî Based on the hour data, when do rejections peak? What operational change does this suggest?\n"
                    "6. **Recommendations** ‚Äî 3 specific, actionable steps to reduce rejections by 30% within 2 weeks.\n"
                    "Use exact numbers. Be direct and operational."
                )
                _rej_ins_key = "rej_auto_insight"
                _rej_ctx_hash = str(hash(_rej_ctx[:200]))
                if _rej_ins_key not in st.session_state:
                    st.session_state[_rej_ins_key] = None
                    st.session_state[_rej_ins_key + "_h"] = None
                if (st.session_state[_rej_ins_key] is None or
                        st.session_state.get(_rej_ins_key + "_h") != _rej_ctx_hash):
                    with st.spinner("ü§ñ Analyzing rejected orders‚Ä¶"):
                        try:
                            st.session_state[_rej_ins_key] = claude_insight(_rej_prompt, 900)
                            st.session_state[_rej_ins_key + "_h"] = _rej_ctx_hash
                        except Exception as _re2:
                            st.session_state[_rej_ins_key] = f"Error: {_re2}"
                if st.session_state[_rej_ins_key]:
                    ai_block("rejected_orders", _rej_ctx, st.session_state[_rej_ins_key])
                _rj_rc1, _ = st.columns([2,4])
                if _rj_rc1.button("‚Ü∫ Refresh Rejection Insight", key="btn_rej_refresh"):
                    st.session_state[_rej_ins_key] = None
                    st.rerun()

        # PDF download
        st.divider()
        pdf_data = BytesIO()
        with PdfPages(pdf_data) as pdf:
            for city in sorted(df['BUSINESS CITY'].dropna().unique()):
                cdf = df[df['BUSINESS CITY'] == city]
                cw = (cdf.groupby(cdf['DELIVERY DATE'].dt.to_period('W-SUN'))
                      .agg(Total_Orders=('ID','count'), Total_Sales=('SUBTOTAL','sum'))
                      .reset_index())
                cw['Week'] = cw['DELIVERY DATE'].dt.start_time
                cw['Week_Label'] = cw['DELIVERY DATE'].apply(
                    lambda p: f"W{p.week}")
                cw = apply_growth_kpi(cw)
                fig_p, ax_p1 = plt.subplots(figsize=(10, 5))
                ax_p1.plot(cw['Week_Label'], cw['Total_Orders'], marker='o', label='Orders')
                if 'Growth KPI Orders' in cw.columns:
                    ax_p1.plot(cw['Week_Label'], cw['Growth KPI Orders'],
                               linestyle='--', color='green', label='KPI')
                ax_p1.set_ylabel("Orders"); ax_p1.grid(True)
                ax_p2 = ax_p1.twinx()
                ax_p2.plot(cw['Week_Label'], cw['Total_Sales'],
                           color='orange', marker='o', label='Sales')
                ax_p2.yaxis.set_major_formatter(fmt_millions)
                ax_p2.set_ylabel("Sales (TZS)")
                plt.title(f"KPI Trend ‚Äî {city}"); fig_p.legend(loc='upper left')
                plt.tight_layout(); pdf.savefig(fig_p); plt.close()

        st.download_button("üì• Download All Cities KPI PDF",
                           data=pdf_data.getvalue(),
                           file_name="Weekly_KPI_All_Cities.pdf",
                           mime="application/pdf")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# RESTAURANT WEEKLY TREND MONITOR  (still inside tab1)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    st.divider()
    st.markdown('<div class="section-header">üçΩÔ∏è Restaurant Weekly Trend Monitor</div>', unsafe_allow_html=True)
    st.caption("Track each restaurant's order volume over 8 weeks ‚Äî spot closures, system errors, growth & decline")

    # ‚îÄ‚îÄ Filters ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    _rv_col1, _rv_col2, _rv_col3 = st.columns([2, 2, 1])
    _rv_all_cities = sorted(df['BUSINESS CITY'].dropna().unique())
    with _rv_col1:
        _rv_city_sel = st.multiselect(
            "üèôÔ∏è Filter by City", _rv_all_cities,
            placeholder="All cities", key="rv_city_filter")
    with _rv_col2:
        _rv_sort_map = {
            "üî¥ Zero orders in latest week (closures first)": "zero_latest",
            "üìâ Biggest week-on-week decline": "wow_decline",
            "üìà Biggest week-on-week growth": "wow_growth",
            "üìä Highest total orders": "total_desc",
            "üî§ Restaurant name A‚ÄìZ": "name_az",
        }
        _rv_sort_lbl = st.selectbox(
            "üîΩ Sort by", list(_rv_sort_map.keys()), index=0, key="rv_sort_mode")
        _rv_sort_key = _rv_sort_map[_rv_sort_lbl]
    with _rv_col3:
        _rv_top_n = st.slider("Show top N", 10, 100, 40, step=10, key="rv_top_n")

    # ‚îÄ‚îÄ Build weekly pivot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    _rv_df = df.copy()
    if _rv_city_sel:
        _rv_df = _rv_df[_rv_df['BUSINESS CITY'].isin(_rv_city_sel)]

    _rv_df = _rv_df.copy()
    _rv_df['DELIVERY DATE'] = pd.to_datetime(_rv_df['DELIVERY DATE'], errors='coerce')
    _rv_df['_rv_wk'] = _rv_df['DELIVERY DATE'].dt.to_period('W-SUN')
    _rv_all_wks = sorted(_rv_df['_rv_wk'].dropna().unique(), reverse=True)
    _rv_weeks = _rv_all_wks[:8]
    _rv_weeks_chron = list(sorted(_rv_weeks))  # chronological

    _rv_pivot = (
        _rv_df[_rv_df['_rv_wk'].isin(_rv_weeks)]
        .groupby(['BUSINESS NAME', '_rv_wk'])['ID']
        .count()
        .unstack(fill_value=0)
    )
    for _w in _rv_weeks_chron:
        if _w not in _rv_pivot.columns:
            _rv_pivot[_w] = 0
    _rv_pivot = _rv_pivot[_rv_weeks_chron]
    _rv_wk_labels = [f"W{p.week} {p.start_time.strftime('%d %b')}" for p in _rv_weeks_chron]
    _rv_pivot.columns = _rv_wk_labels
    _rv_pivot = _rv_pivot.reset_index()

    _rv_wk_cols = _rv_wk_labels   # column names in order
    _rv_latest  = _rv_wk_cols[-1] if _rv_wk_cols else None
    _rv_prev    = _rv_wk_cols[-2] if len(_rv_wk_cols) >= 2 else None

    _rv_pivot['Total'] = _rv_pivot[_rv_wk_cols].sum(axis=1)
    _rv_pivot['WoW Change'] = (
        _rv_pivot[_rv_latest] - _rv_pivot[_rv_prev]
        if _rv_latest and _rv_prev else 0
    )

    # Trend label
    def _rv_trend(row):
        vals = [row[c] for c in _rv_wk_cols if c in row.index]
        if not vals: return '‚Äî'
        last = vals[-1]
        prev_avg = sum(vals[:-1]) / max(len(vals)-1, 1) if len(vals) > 1 else last
        if last == 0 and prev_avg > 2:  return 'üî¥ Inactive'
        if last == 0 and prev_avg <= 2: return '‚ö™ No history'
        if last >= prev_avg * 1.2:      return 'üìà Growing'
        if last <= prev_avg * 0.8:      return 'üìâ Declining'
        return '‚Üí Stable'

    _rv_pivot['Trend'] = _rv_pivot.apply(_rv_trend, axis=1)

    # City mapping
    _rv_city_map = df.groupby('BUSINESS NAME')['BUSINESS CITY'].agg(
        lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown')
    _rv_pivot['City'] = _rv_pivot['BUSINESS NAME'].map(_rv_city_map).fillna('Unknown')

    # ‚îÄ‚îÄ Sort ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if   _rv_sort_key == 'zero_latest' and _rv_latest:
        _rv_pivot = _rv_pivot.sort_values([_rv_latest, 'Total'], ascending=[True, False])
    elif _rv_sort_key == 'wow_decline':
        _rv_pivot = _rv_pivot.sort_values('WoW Change', ascending=True)
    elif _rv_sort_key == 'wow_growth':
        _rv_pivot = _rv_pivot.sort_values('WoW Change', ascending=False)
    elif _rv_sort_key == 'total_desc':
        _rv_pivot = _rv_pivot.sort_values('Total', ascending=False)
    elif _rv_sort_key == 'name_az':
        _rv_pivot = _rv_pivot.sort_values('BUSINESS NAME')

    # ‚îÄ‚îÄ Summary metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    _rv_total_biz  = len(_rv_pivot)
    _rv_inactive_n = int((_rv_pivot[_rv_latest] == 0).sum()) if _rv_latest else 0
    _rv_growing_n  = int((_rv_pivot['Trend'] == 'üìà Growing').sum())
    _rv_declining_n= int((_rv_pivot['Trend'] == 'üìâ Declining').sum())
    _rv_stable_n   = int((_rv_pivot['Trend'] == '‚Üí Stable').sum())

    _rvm1, _rvm2, _rvm3, _rvm4, _rvm5 = st.columns(5)
    _rvm1.metric("üçΩÔ∏è Restaurants", _rv_total_biz)
    _rvm2.metric("üî¥ Inactive (latest wk)", _rv_inactive_n)
    _rvm3.metric("üìà Growing", _rv_growing_n)
    _rvm4.metric("üìâ Declining", _rv_declining_n)
    _rvm5.metric("‚Üí Stable", _rv_stable_n)

    # ‚îÄ‚îÄ Table ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    _rv_disp = _rv_pivot.head(_rv_top_n).copy()
    _rv_col_order = ['City', 'BUSINESS NAME'] + _rv_wk_cols + ['Total', 'WoW Change', 'Trend']
    _rv_show = _rv_disp[[c for c in _rv_col_order if c in _rv_disp.columns]]

    def _style_rv(df_in):
        sty = pd.DataFrame('', index=df_in.index, columns=df_in.columns)
        for idx, row in df_in.iterrows():
            if _rv_latest and _rv_latest in df_in.columns:
                _all = [float(row.get(c, 0) or 0) for c in _rv_wk_cols if c in df_in.columns]
                _lv  = float(row.get(_rv_latest, 0) or 0)
                _pavg = sum(_all[:-1]) / max(len(_all)-1, 1) if len(_all) > 1 else _lv
                if _lv == 0 and _pavg > 2:
                    sty.at[idx, _rv_latest] = 'background-color:#ffcdd2;color:#b71c1c;font-weight:700'
                elif _lv >= _pavg * 1.2 and _lv > 0:
                    sty.at[idx, _rv_latest] = 'background-color:#c8e6c9;color:#1b5e20;font-weight:700'
                elif _lv <= _pavg * 0.8 and _pavg > 2:
                    sty.at[idx, _rv_latest] = 'background-color:#fff9c4;color:#f57f17'
            if 'WoW Change' in df_in.columns:
                try:
                    _dv = float(row.get('WoW Change', 0) or 0)
                    if   _dv > 0: sty.at[idx,'WoW Change'] = 'background-color:#c8e6c9;color:#1b5e20;font-weight:700'
                    elif _dv < 0: sty.at[idx,'WoW Change'] = 'background-color:#ffcdd2;color:#b71c1c;font-weight:700'
                except: pass
            if 'Trend' in df_in.columns:
                tv = str(row.get('Trend',''))
                if   'üî¥' in tv: sty.at[idx,'Trend'] = 'background-color:#ffcdd2;color:#b71c1c;font-weight:700'
                elif 'üìà' in tv: sty.at[idx,'Trend'] = 'background-color:#c8e6c9;color:#1b5e20'
                elif 'üìâ' in tv: sty.at[idx,'Trend'] = 'background-color:#fff9c4;color:#f57f17'
        return sty

    _rv_sort_name = _rv_sort_lbl.split(' ', 1)[1] if ' ' in _rv_sort_lbl else _rv_sort_lbl
    st.markdown(f"**üìã Top {min(_rv_top_n, _rv_total_biz)} restaurants ‚Äî sorted by: {_rv_sort_name}**")
    st.dataframe(
        _rv_show.style.apply(_style_rv, axis=None),
        use_container_width=True,
        height=min(80 + len(_rv_show) * 36, 720)
    )
    st.caption("üî¥ Latest week = 0 (possible closure or system error) ¬∑ üìà Growing >20% above avg ¬∑ "
               "üìâ Declining >20% below avg ¬∑ ‚Üí Stable  |  WoW Change = latest minus previous week")

    # ‚îÄ‚îÄ Inactive alert ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if _rv_latest and _rv_inactive_n > 0:
        _rv_zero = _rv_pivot[_rv_pivot[_rv_latest] == 0][['City','BUSINESS NAME','Total','WoW Change']].copy()
        _rv_zero = _rv_zero[_rv_zero['Total'] > 0].sort_values('Total', ascending=False)
        if not _rv_zero.empty:
            with st.expander(f"üî¥ {len(_rv_zero)} restaurants had orders before but ZERO in latest week"):
                st.dataframe(_rv_zero.reset_index(drop=True), use_container_width=True)
                st.caption("Investigate: closed, delisted, or data error?")

    # ‚îÄ‚îÄ Top 15 chart: latest week vs 8-week average ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if _rv_latest and len(_rv_wk_cols) >= 2:
        _rv_chart = _rv_pivot.copy()
        _rv_chart['_prev_avg'] = _rv_chart[_rv_wk_cols[:-1]].mean(axis=1).round(1)
        _rv_chart['_latest']   = _rv_chart[_rv_latest]
        _top15 = _rv_chart.nlargest(15, 'Total').sort_values('_latest', ascending=True)

        _fig_rv, _ax_rv = plt.subplots(figsize=(12, max(5, len(_top15) * 0.58)))
        _yi = list(range(len(_top15)))

        # Bars = 8-week average
        _ax_rv.barh(_yi, _top15['_prev_avg'], height=0.5, color='#90caf9', alpha=0.85,
                    label='8-Week Avg / Week', zorder=2)
        # Dots = latest week
        _ax_rv.scatter(_top15['_latest'], _yi, s=100, zorder=5,
                       color=[('#1b5e20' if l >= a else '#b71c1c')
                              for l, a in zip(_top15['_latest'], _top15['_prev_avg'])],
                       label='Latest Week', edgecolors='white', linewidth=0.8)
        # Connector lines
        for _y, _lt, _av in zip(_yi, _top15['_latest'], _top15['_prev_avg']):
            _ax_rv.plot([_av, _lt], [_y, _y],
                        color=('#2e7d32' if _lt >= _av else '#c62828'),
                        lw=1.6, linestyle='--', alpha=0.6, zorder=3)
            _ax_rv.text(max(_lt, _av) + 0.3, _y, str(int(_lt)),
                        va='center', fontsize=8, fontweight='bold',
                        color='#1b5e20' if _lt >= _av else '#b71c1c')

        _ax_rv.set_yticks(_yi)
        _ax_rv.set_yticklabels(_top15['BUSINESS NAME'].str[:32].tolist(), fontsize=9)
        _ax_rv.set_xlabel("Orders per Week", fontsize=10)
        _ax_rv.set_title(
            "Top 15 Restaurants ‚Äî Latest Week vs 8-Week Average\n"
            "üü¢ Dot above bar = growing  ¬∑  üî¥ Dot below bar = declining",
            fontweight='bold', fontsize=11)
        _ax_rv.legend(fontsize=9, loc='lower right')
        _ax_rv.grid(axis='x', alpha=0.2)
        plt.tight_layout()
        st.pyplot(_fig_rv); plt.close()

    # ‚îÄ‚îÄ Download ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    _rv_dl = _rv_pivot[_rv_col_order].copy() if all(
        c in _rv_pivot.columns for c in _rv_col_order) else _rv_pivot.copy()
    st.download_button(
        "‚¨áÔ∏è Download Restaurant Trend Report (Excel)",
        data=excel_bytes(_rv_dl.reset_index(drop=True), "Restaurant Trend"),
        file_name="Restaurant_Weekly_Trend.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# TAB 2 ‚Äî DELIVERY TIMES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
with tab2:
    st.markdown('<div class="section-header">‚è∞ Delivery Time Analysis</div>', unsafe_allow_html=True)

    df2 = compute_delivery_stages(df)
    df2 = add_distance(df2)
    df2['ISO_Week'] = df2['DELIVERY DATE'].dt.isocalendar().week
    df2['ISO_Year'] = df2['DELIVERY DATE'].dt.isocalendar().year

    # ‚îÄ‚îÄ Week selector ‚Äî default latest week ‚îÄ‚îÄ
    _wk_grp = (df2.groupby(['ISO_Year','ISO_Week']).size().reset_index()[['ISO_Year','ISO_Week']]
               .sort_values(['ISO_Year','ISO_Week']))
    _wk_grp['Label'] = (_wk_grp['ISO_Year'].astype(str) + "-W"
                         + _wk_grp['ISO_Week'].astype(str).str.zfill(2))
    del_week_labels = _wk_grp['Label'].tolist()
    sel_del_week = st.selectbox("üìÖ Select Week (KPI metrics & table, default = latest)",
                                del_week_labels, index=len(del_week_labels)-1, key="del_week_sel")
    _yr = int(sel_del_week.split("-W")[0]); _wn = int(sel_del_week.split("-W")[1])
    df2_week = df2[(df2['ISO_Year']==_yr) & (df2['ISO_Week']==_wn)]

    # ‚îÄ‚îÄ KPI metrics ‚Äî selected week, completed only, OUTLIERS EXCLUDED ‚îÄ‚îÄ
    def _filter_clean_completed(frame):
        """Return only completed orders with all stages within valid operational ranges.
        Excludes outliers that inflate average delivery time.
        """
        _fc = (frame[frame["STATE"].isin(["Delivery Completed By Driver","Completed"])].copy()
               if "STATE" in frame.columns else frame.copy())
        _stage_limits = {
            "Accepted by Business": (0, 15),   # target 2, allow up to 15 before flagging
            "Assigned Time":        (0, 15),
            "Accepted by Driver":   (0, 15),
            "Driver to Business":   (0, 30),   # target 8, allow up to 30
            "Driver in Business":   (0, 45),   # target 12, allow up to 45
            "Pickup to Customer":   (0, 45),   # target varies ~6-18, allow up to 45
            "Average Delivery Time":(0, 120),  # exclude extreme outliers only
        }
        for _fcol, (_lo, _hi) in _stage_limits.items():
            if _fcol in _fc.columns:
                _fc = _fc[(_fc[_fcol] >= _lo) & (_fc[_fcol] <= _hi)]
        return _fc

    _comp = _filter_clean_completed(df2_week)

    # Avg Delivery Time ‚Äî use the masked column computed by compute_delivery_stages
    if not _comp.empty and 'Average Delivery Time' in _comp.columns:
        _adt_s = pd.to_numeric(_comp['Average Delivery Time'], errors='coerce')
        _adt_s = _adt_s.mask(_adt_s < 0, np.nan)  # same mask as source
        avg_adt = round(_adt_s.dropna().mean(), 1)
    else:
        avg_adt = 0.0

    avg_dib = round(_comp["Driver in Business"].mean(), 1) if not _comp.empty else 0.0
    avg_p2c = round(_comp["Pickup to Customer"].mean(), 1) if not _comp.empty else 0.0
    avg_abb = round(_comp["Accepted by Business"].mean(), 1) if not _comp.empty else 0.0

    # Distance-based target for this week's data
    if not _comp.empty and 'DISTANCE (km)' in _comp.columns:
        _wk_avg_dist = round(_comp['DISTANCE (km)'].mean(), 1)
        _wk_p2c_tgt  = round((_wk_avg_dist / STAGE_DRIVING_SPEED_KMH * 60) + STAGE_P2C_OVERHEAD_MIN, 1)
    else:
        _wk_avg_dist = 0.0; _wk_p2c_tgt = 16.0
    _wk_total_tgt = round(sum(STAGE_TARGETS_FIXED.values()) + _wk_p2c_tgt, 1)

    mc1, mc2, mc3, mc4 = st.columns(4)
    mc1.metric("‚è± Avg Delivery Time",
               f"{avg_adt:.1f} min",
               delta=f"Target {_wk_total_tgt:.1f} min",
               delta_color=("normal" if avg_adt <= _wk_total_tgt else "inverse"),
               help=f"Sum of all 6 stages incl. overhead. Target=25.5+P2C({_wk_p2c_tgt:.1f}) for avg {_wk_avg_dist:.1f} km")
    mc2.metric("üç≥ Vendor Prep Time",    f"{avg_dib:.1f} min",
               delta="Target 12 min",  delta_color=("normal" if avg_dib <= 12 else "inverse"))
    mc3.metric("üõµ Pickup‚ÜíCustomer",     f"{avg_p2c:.1f} min",
               delta=f"Target {_wk_p2c_tgt:.1f} min",
               delta_color=("normal" if avg_p2c <= _wk_p2c_tgt else "inverse"),
               help=f"Drive time + 6 min overhead. Avg dist = {_wk_avg_dist:.1f} km")
    mc4.metric("‚úÖ Business Acceptance", f"{avg_abb:.1f} min",
               delta="Target 2 min", delta_color=("normal" if avg_abb <= 2 else "inverse"))

    # ‚îÄ‚îÄ Stage methodology note ‚îÄ‚îÄ
    st.info(
        "**üìê Delivery Time Model** ‚Äî Fixed stage targets: Accept Biz **2 min** ¬∑ Assign **2 min** ¬∑ "
        "Accept Driver **1.5 min** ¬∑ Driver‚ÜíRestaurant **8 min** ¬∑ Prep Time **12 min** ¬∑ "
        "Pickup‚ÜíCustomer = road dist √∑ **30 km/h** √ó 60 + **6 min overhead**. "
        "Road distance = straight-line √ó 1.6."
    )
    st.markdown("""<div style="background:#fff8e1;border:1px solid #f9a825;padding:12px 16px;
    border-radius:8px;font-size:13px;margin-bottom:12px;line-height:1.7">
    <b>üé® Colour Guide ‚Äî How to Read the Tables:</b><br>
    üü¢ <b>Green</b> = At or below the target time ‚Äî <i>performing well</i><br>
    üü° <b>Yellow</b> = Between 1√ó and 1.5√ó the target ‚Äî <i>slightly slow, monitor closely</i><br>
    üî¥ <b>Red</b> = More than 1.5√ó the target ‚Äî <i>significantly delayed, action needed</i><br>
    <small><b>Example:</b> Vendor Prep target = 12 min ‚Üí üü¢ if ‚â§12 min ¬∑ üü° if 12‚Äì18 min ¬∑ üî¥ if &gt;18 min<br>
    <b>vs Target column:</b> A <b>negative</b> number means the city/rider is <b>faster</b> than target ‚úÖ ¬∑ A <b>positive</b> number means <b>slower</b> than target ‚ùå</small>
    </div>""", unsafe_allow_html=True)

    # ‚îÄ‚îÄ Stage table ‚Äî selected week only ‚îÄ‚îÄ
    st.subheader(f"üìä Delivery Stage Avg by City ‚Äî {sel_del_week}")
    stage_cols = ['Accepted by Business','Assigned Time','Accepted by Driver',
                  'Driver to Business','Driver in Business','Pickup to Customer',
                  'Average Delivery Time']

    # City stage averages from clean completed orders only
    _city_grp = _comp.groupby("BUSINESS CITY")
    city_stage = (_city_grp[stage_cols].mean().round(1).reset_index())
    city_stage['Orders'] = _city_grp['ID'].count().values

    # Add avg distance and compute per-city P2C target
    if 'DISTANCE (km)' in _comp.columns:
        city_stage['Avg Dist (km)'] = _city_grp['DISTANCE (km)'].mean().round(2).values
        city_stage['P2C Target'] = city_stage['Avg Dist (km)'].apply(
            lambda d: round((d / STAGE_DRIVING_SPEED_KMH * 60) + STAGE_P2C_OVERHEAD_MIN, 1)
        )
    else:
        city_stage['Avg Dist (km)'] = np.nan
        city_stage['P2C Target'] = 16.0

    city_stage['Total Target'] = (sum(STAGE_TARGETS_FIXED.values()) + city_stage['P2C Target']).round(1)
    city_stage['vs Target'] = (city_stage['Average Delivery Time'] - city_stage['Total Target']).round(1)
    city_stage = city_stage.sort_values("Average Delivery Time", ascending=True)

    # ‚îÄ‚îÄ TOTAL row ‚îÄ‚îÄ
    _total_vals = {'BUSINESS CITY': 'ALL CITIES', 'Orders': int(city_stage['Orders'].sum())}
    for _sc in stage_cols:
        _total_vals[_sc] = round(city_stage[_sc].mean(), 1)
    _avg_dist_total = city_stage['Avg Dist (km)'].mean() if 'Avg Dist (km)' in city_stage else 4.0
    _avg_dist_total = _avg_dist_total if pd.notna(_avg_dist_total) else 4.0
    _total_vals['Avg Dist (km)'] = round(_avg_dist_total, 2)
    _total_vals['P2C Target'] = round((_avg_dist_total / STAGE_DRIVING_SPEED_KMH * 60) + STAGE_P2C_OVERHEAD_MIN, 1)
    _total_vals['Total Target'] = round(sum(STAGE_TARGETS_FIXED.values()) + _total_vals['P2C Target'], 1)
    _total_vals['vs Target'] = round(_total_vals['Average Delivery Time'] - _total_vals['Total Target'], 1)
    city_stage_disp = pd.concat([city_stage, pd.DataFrame([_total_vals])], ignore_index=True)

    # ‚îÄ‚îÄ Target reference row (shown at top) ‚îÄ‚îÄ
    _target_row = {
        'BUSINESS CITY': '‚éØ TARGET ‚éØ', 'Orders': '‚Äî', 'Avg Dist (km)': '‚Äî',
        'Accepted by Business': STAGE_TARGETS_FIXED['Accepted by Business'],
        'Assigned Time':        STAGE_TARGETS_FIXED['Assigned Time'],
        'Accepted by Driver':   STAGE_TARGETS_FIXED['Accepted by Driver'],
        'Driver to Business':   STAGE_TARGETS_FIXED['Driver to Business'],
        'Driver in Business':   STAGE_TARGETS_FIXED['Driver in Business'],
        'Pickup to Customer': f'{STAGE_P2C_OVERHEAD_MIN}+drive',
        'Average Delivery Time': f'{sum(STAGE_TARGETS_FIXED.values())} + P2C',
        'P2C Target': 'dist-based', 'Total Target': 'dist-based', 'vs Target': '‚Äî',
    }
    city_stage_disp = pd.concat([pd.DataFrame([_target_row]), city_stage_disp], ignore_index=True)

    # ‚îÄ‚îÄ Colour styling ‚îÄ‚îÄ
    def _style_stage_table(df_in):
        styles = pd.DataFrame('', index=df_in.index, columns=df_in.columns)
        _fixed_tgts = {
            'Accepted by Business': STAGE_TARGETS_FIXED['Accepted by Business'],
            'Assigned Time':        STAGE_TARGETS_FIXED['Assigned Time'],
            'Accepted by Driver':   STAGE_TARGETS_FIXED['Accepted by Driver'],
            'Driver to Business':   STAGE_TARGETS_FIXED['Driver to Business'],
            'Driver in Business':   STAGE_TARGETS_FIXED['Driver in Business'],
        }
        for _i, row in df_in.iterrows():
            city_name = str(row.get('BUSINESS CITY',''))
            if city_name == '‚éØ TARGET ‚éØ':
                for _c in df_in.columns:
                    styles.at[_i,_c] = 'background-color:#e3f2fd;color:#0d47a1;font-weight:700;font-style:italic'
                continue
            if city_name == 'ALL CITIES':
                for _c in df_in.columns:
                    styles.at[_i,_c] = 'background-color:#212121;color:#fff;font-weight:800'
                continue
            for _col, _tgt in _fixed_tgts.items():
                if _col in df_in.columns:
                    try:
                        v = float(row[_col])
                        if v <= _tgt:
                            styles.at[_i,_col] = 'background-color:#c8e6c9;color:#1b5e20;font-weight:600'
                        elif v <= _tgt * 1.5:
                            styles.at[_i,_col] = 'background-color:#fff9c4;color:#f57f17;font-weight:600'
                        else:
                            styles.at[_i,_col] = 'background-color:#ffcdd2;color:#b71c1c;font-weight:600'
                    except (ValueError, TypeError): pass
            # vs Target: negative = beat target (good=green), positive = over (bad=red)
            if 'vs Target' in df_in.columns:
                try:
                    vt = float(row['vs Target'])
                    if vt <= 0:
                        styles.at[_i,'vs Target'] = 'background-color:#c8e6c9;color:#1b5e20;font-weight:700'
                    elif vt <= 5:
                        styles.at[_i,'vs Target'] = 'background-color:#fff9c4;color:#f57f17;font-weight:700'
                    else:
                        styles.at[_i,'vs Target'] = 'background-color:#ffcdd2;color:#b71c1c;font-weight:700'
                except (ValueError, TypeError): pass
            # Total delivery time vs its own target
            if 'Average Delivery Time' in df_in.columns and 'Total Target' in df_in.columns:
                try:
                    adt_v = float(row['Average Delivery Time']); tgt_v = float(row['Total Target'])
                    if adt_v <= tgt_v:
                        styles.at[_i,'Average Delivery Time'] = 'background-color:#c8e6c9;color:#1b5e20;font-weight:700'
                    elif adt_v <= tgt_v * 1.2:
                        styles.at[_i,'Average Delivery Time'] = 'background-color:#fff9c4;color:#f57f17;font-weight:700'
                    else:
                        styles.at[_i,'Average Delivery Time'] = 'background-color:#ffcdd2;color:#b71c1c;font-weight:700'
                except (ValueError, TypeError): pass
        return styles

    st.dataframe(
        city_stage_disp.style.apply(_style_stage_table, axis=None),
        use_container_width=True,
        height=min(60 + len(city_stage_disp) * 38, 620)
    )
    st.caption("üü¢ At/below target (good)  üü° 1‚Äì1.5√ó target (slightly slow)  üî¥ Over 1.5√ó target (action needed)  |  **vs Target**: negative = faster than target ‚úÖ ¬∑ positive = slower ‚ùå")

    st.download_button("‚¨áÔ∏è Download Delivery Table",
                       data=city_stage_disp.to_csv(index=False).encode(),
                       file_name=f"delivery_{sel_del_week}.csv", mime="text/csv")

    # ‚îÄ‚îÄ Distance Summary + Per-City ADT Targets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.subheader("üìè Distance Summary & Delivery Time Targets by City")
    st.caption("Road distance = straight-line √ó 1.6 | P2C Target = road dist √∑ 30 km/h √ó 60 + 6 min overhead | Total Target = 25.5 min (fixed) + P2C Target")

    if 'DISTANCE (km)' in _comp.columns and 'BUSINESS CITY' in _comp.columns:
        _dist_summ = (_comp.groupby('BUSINESS CITY').agg(
            Orders=('ID','count'),
            Avg_SL_Dist=('DISTANCE (km)', lambda x: round(x.mean() / DIST_ROAD_FACTOR, 1)),
            Avg_Road_Dist=('DISTANCE (km)', 'mean'),
            Min_Dist=('DISTANCE (km)', 'min'),
            Max_Dist=('DISTANCE (km)', 'max'),
        ).round(1).reset_index())
        _dist_summ.columns = ['City','Orders','Avg Straight-line (km)','Avg Road Dist (km)','Min Road (km)','Max Road (km)']

        # Per-city P2C target & total target
        _dist_summ['P2C Target (min)'] = (_dist_summ['Avg Road Dist (km)'] / STAGE_DRIVING_SPEED_KMH * 60 + STAGE_P2C_OVERHEAD_MIN).round(1)
        _dist_summ['Total ADT Target (min)'] = (sum(STAGE_TARGETS_FIXED.values()) + _dist_summ['P2C Target (min)']).round(1)

        # Sort by total target ascending
        _dist_summ = _dist_summ.sort_values('Total ADT Target (min)')

        # OVERALL row
        _ds_overall = {
            'City': 'ALL CITIES',
            'Orders': int(_dist_summ['Orders'].sum()),
            'Avg Straight-line (km)': round(_dist_summ['Avg Straight-line (km)'].mean(), 1),
            'Avg Road Dist (km)': round(_dist_summ['Avg Road Dist (km)'].mean(), 1),
            'Min Road (km)': round(_dist_summ['Min Road (km)'].min(), 1),
            'Max Road (km)': round(_dist_summ['Max Road (km)'].max(), 1),
            'P2C Target (min)': round(_dist_summ['P2C Target (min)'].mean(), 1),
            'Total ADT Target (min)': round(_dist_summ['Total ADT Target (min)'].mean(), 1),
        }
        _dist_summ_disp = pd.concat([_dist_summ, pd.DataFrame([_ds_overall])], ignore_index=True)

        def _style_dist_summ(df_in):
            sty = pd.DataFrame('', index=df_in.index, columns=df_in.columns)
            for _i, row in df_in.iterrows():
                if str(row.get('City','')) == 'ALL CITIES':
                    for _c in df_in.columns: sty.at[_i,_c] = 'background-color:#212121;color:#fff;font-weight:800'
                elif 'Total ADT Target (min)' in df_in.columns:
                    try:
                        t = float(row['Total ADT Target (min)'])
                        sty.at[_i,'Total ADT Target (min)'] = (
                            'background-color:#c8e6c9;color:#1b5e20;font-weight:700' if t <= 40
                            else 'background-color:#fff9c4;color:#f57f17;font-weight:700' if t <= 45
                            else 'background-color:#ffcdd2;color:#b71c1c;font-weight:700')
                    except: pass
            return sty

        st.dataframe(_dist_summ_disp.style.apply(_style_dist_summ, axis=None),
                     use_container_width=True,
                     height=min(80 + len(_dist_summ_disp) * 38, 500))
        st.caption("üü¢ Target ‚â§ 40 min  üü° 40‚Äì45 min  üî¥ > 45 min  |  Cities with longer avg distances have higher but realistic targets.")

        # ‚îÄ‚îÄ Professional per-city target visualisation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _fig_tgt, (_ax_main, _ax_dist) = plt.subplots(1, 2, figsize=(14, max(4, len(_dist_summ) * 0.65)),
                                                        gridspec_kw={'width_ratios':[2,1]})
        _cities_plot  = _dist_summ['City'].tolist()
        _targets_plot = _dist_summ['Total ADT Target (min)'].tolist()
        _fixed_total  = sum(STAGE_TARGETS_FIXED.values())   # 25.5 min
        _p2c_vals     = _dist_summ['P2C Target (min)'].tolist()
        _road_dists   = _dist_summ['Avg Road Dist (km)'].tolist()

        # Left: stacked bar ‚Äî fixed vs P2C component
        _bar_fixed = [_fixed_total] * len(_cities_plot)
        _bars_f = _ax_main.barh(_cities_plot, _bar_fixed, color='#5c6bc0', alpha=0.85,
                                label=f'Fixed stages ({_fixed_total} min)', height=0.65)
        _bars_p = _ax_main.barh(_cities_plot, _p2c_vals, left=_bar_fixed, color='#ef5350', alpha=0.85,
                                label='P2C (distance-based)', height=0.65)

        # Label total on right
        for _ci, (_city, _tgt, _p2c) in enumerate(zip(_cities_plot, _targets_plot, _p2c_vals)):
            _ax_main.text(_tgt + 0.4, _ci, f'  {_tgt:.1f} min', va='center', fontsize=9, fontweight='bold',
                          color='#1a1a2e')
            if _p2c >= 5:
                _ax_main.text(_fixed_total + _p2c/2, _ci, f'+{_p2c:.1f}',
                              va='center', ha='center', fontsize=8, color='white', fontweight='bold')

        # Reference line ‚Äî overall average target
        _avg_tgt = np.mean(_targets_plot)
        _ax_main.axvline(_avg_tgt, color='#212121', lw=1.5, linestyle='--',
                         label=f'Avg target: {_avg_tgt:.1f} min', alpha=0.6)

        _ax_main.set_xlabel("Delivery Time Target (minutes)", fontsize=10)
        _ax_main.set_title(
            f"Per-City ADT Targets \u2014 {sel_del_week}\nBlue = fixed stages  |  Red = drive time (30 km/h + 6 min overhead)",
            fontsize=10, fontweight='bold')
        _ax_main.invert_yaxis()
        _ax_main.legend(fontsize=8, loc='lower right')
        _ax_main.grid(axis='x', alpha=0.2)
        _ax_main.set_xlim(0, max(_targets_plot) * 1.25)

        # Right: avg road distance as horizontal lollipop
        _ax_dist.scatter(_road_dists, range(len(_cities_plot)), color='#0288d1', s=80, zorder=3)
        for _ci, _d in enumerate(_road_dists):
            _ax_dist.plot([0, _d], [_ci, _ci], color='#0288d1', lw=1.8, alpha=0.6)
            _ax_dist.text(_d + 0.1, _ci, f'{_d:.1f}km', va='center', fontsize=8, color='#01579b')
        _ax_dist.set_yticks(range(len(_cities_plot)))
        _ax_dist.set_yticklabels([])
        _ax_dist.invert_yaxis()
        _ax_dist.set_xlabel("Avg Road Distance (km)", fontsize=10)
        _ax_dist.set_title("Avg Road Dist (straight-line x 1.4)", fontsize=10, fontweight='bold')
        _ax_dist.grid(axis='x', alpha=0.2)
        _ax_dist.set_xlim(0, max(_road_dists) * 1.45 if _road_dists else 10)

        plt.tight_layout()
        st.pyplot(_fig_tgt); plt.close()
    else:
        st.info("Distance data not available for this week.")

    # ‚îÄ‚îÄ Weekly Average Delivery Time trend ‚îÄ‚îÄ
    st.subheader("üìà Weekly Average Delivery Time Trend")

    # Per-chart city filter
    _t2_cities_all = sorted(df2['BUSINESS CITY'].dropna().unique().tolist()) if 'BUSINESS CITY' in df2.columns else []
    _t2_city_f = st.multiselect(
        "üèôÔ∏è Filter by City", _t2_cities_all,
        placeholder="All cities (or select one/more)",
        key="t2_adt_city"
    )
    _df2_adt = df2[df2['BUSINESS CITY'].isin(_t2_city_f)] if _t2_city_f else df2.copy()
    if _t2_city_f:
        st.caption(f"Showing: **{', '.join(_t2_city_f)}**")

    _wk_adt_raw = _filter_clean_completed(_df2_adt).copy()
    # Use the masked Average Delivery Time column ‚Äî same as table values
    if 'Average Delivery Time' in _wk_adt_raw.columns:
        _wk_adt_raw = _wk_adt_raw.copy()
        _wk_adt_raw['_adt_clean'] = pd.to_numeric(
            _wk_adt_raw['Average Delivery Time'], errors='coerce').mask(
            _wk_adt_raw['Average Delivery Time'] < 0, np.nan)
    else:
        _wk_adt_raw['_adt_clean'] = np.nan
    _wk_adt = (_wk_adt_raw
               .groupby(_df2_adt.loc[_wk_adt_raw.index, 'DELIVERY DATE'].dt.to_period('W-SUN'))
               .agg(Avg_DT=('_adt_clean', 'mean'))
               .reset_index())
    _wk_adt.columns = ['Week_Period', 'Avg_DT']
    _wk_adt['Avg_DT'] = _wk_adt['Avg_DT'].round(1)
    _wk_adt['Week_Str'] = _wk_adt['Week_Period'].apply(
        lambda p: f"W{p.week}\n({p.start_time.strftime('%d %b')})")

    if len(_wk_adt) >= 2:
        _adt_vals   = _wk_adt['Avg_DT'].tolist()
        _adt_labels = _wk_adt['Week_Str'].tolist()
        _prev_avg   = float(pd.Series(_adt_vals[:-1]).mean())
        _last_val   = _adt_vals[-1]
        _delta      = _last_val - _prev_avg

        # Arrow: for delivery time, UP is BAD (slower), DOWN is GOOD (faster)
        if _delta > 0.5:
            _arrow, _arrow_col = '‚Üë', '#e74c3c'
            _story = (f"Last week avg delivery was **{_last_val:.1f} min** ‚Äî "
                      f"**{_delta:.1f} min slower** than the {len(_adt_vals)-1}-week average "
                      f"of {_prev_avg:.1f} min. ‚Üë Delivery times are worsening.")
        elif _delta < -0.5:
            _arrow, _arrow_col = '‚Üì', '#27ae60'
            _story = (f"Last week avg delivery was **{_last_val:.1f} min** ‚Äî "
                      f"**{abs(_delta):.1f} min faster** than the {len(_adt_vals)-1}-week average "
                      f"of {_prev_avg:.1f} min. ‚Üì Delivery times are improving.")
        else:
            _arrow, _arrow_col = '‚Üí', '#f39c12'
            _story = (f"Last week avg delivery was **{_last_val:.1f} min** ‚Äî "
                      f"stable vs previous average of {_prev_avg:.1f} min ‚Üí.")

        _fig_adt, _ax_adt = plt.subplots(figsize=(max(10, len(_adt_labels) * 1.2), 5))

        # Previous average dashed line
        _ax_adt.axhline(_prev_avg, color='#95a5a6', linestyle='--', lw=1.5, alpha=0.8,
                        label=f"Previous avg: {_prev_avg:.1f} min")

        # Main line in blue
        _ax_adt.plot(range(len(_adt_labels)), _adt_vals,
                     marker='o', color='#FF6B00', lw=2, label='Avg Delivery Time')

        # Last week point highlighted in arrow colour
        _ax_adt.plot(len(_adt_labels) - 1, _last_val, 'o',
                     color=_arrow_col, markersize=12, zorder=5, label='Last week')

        # Numbers on every point
        _y_pad = max(_adt_vals) * 0.025
        for _i, _v in enumerate(_adt_vals):
            _ax_adt.text(_i, _v + _y_pad, f"{_v:.1f}", ha='center', fontsize=9,
                         fontweight='bold',
                         color=(_arrow_col if _i == len(_adt_vals) - 1 else '#2c3e50'))

        # Arrow above last point
        _ax_adt.text(len(_adt_labels) - 1, _last_val + _y_pad * 3.5,
                     _arrow, ha='center', fontsize=20, fontweight='bold', color=_arrow_col)

        # Light shading between prev_avg line and last segment
        _ax_adt.fill_between(
            [len(_adt_labels) - 2, len(_adt_labels) - 1],
            [_prev_avg, _prev_avg],
            [_adt_vals[-2], _last_val],
            alpha=0.12, color=_arrow_col)

        _ax_adt.set_xticks(range(len(_adt_labels)))
        _ax_adt.set_xticklabels(_adt_labels, fontsize=9)
        _ax_adt.set_ylabel("Avg Delivery Time (min)")
        _ax_adt.set_xlabel("Week")
        _adt_city_title = f" ‚Äî {', '.join(_t2_city_f)}" if _t2_city_f else " ‚Äî All Cities"
        _ax_adt.set_title(f"Weekly Avg Delivery Time Trend{_adt_city_title} (Clean Completed Orders)")
        _ax_adt.grid(True, alpha=0.25, axis='y')
        _ax_adt.legend(fontsize=9)
        plt.tight_layout()
        st.pyplot(_fig_adt); plt.close()

        # Story explanation card
        st.markdown(
            f'<div style="background:#f8f9fa;border-left:4px solid {_arrow_col};'
            f'padding:10px 16px;border-radius:6px;font-size:13px;margin:6px 0 14px 0;">'
            f'{_story}</div>',
            unsafe_allow_html=True)
    else:
        st.info("Need at least 2 weeks of data for the trend chart.")

    # ‚îÄ‚îÄ Hourly chart ‚îÄ‚îÄ
    st.subheader("üìà Hourly Delivery Time vs Volume")
    st.caption("Using the same city filter as the Weekly Delivery Time Trend above ‚Üë")
    _df2_clean = _filter_clean_completed(_df2_adt)  # same filtered df as trend chart
    hourly = (_df2_clean[_df2_clean['HOUR'].isin(OPERATING_HOURS)]
              .groupby('HOUR')
              .agg(avg_dt=('Average Delivery Time','mean'), orders=('ID','count'))
              .reset_index())
    hourly['order_idx'] = hourly['HOUR'].apply(lambda h: OPERATING_HOURS.index(h))
    hourly = hourly.sort_values('order_idx')
    hourly['Label'] = hourly['HOUR'].apply(lambda h: f"{h:02d}:00")

    hourly['pct'] = (hourly['orders'] / hourly['orders'].sum() * 100).round(1)

    fig_h, ax_h1 = plt.subplots(figsize=(13, 5))
    ax_h2 = ax_h1.twinx()
    _hbars = ax_h2.bar(hourly['Label'], hourly['pct'], alpha=0.28, color='#5c6bc0',
                       label='% of Daily Orders', width=0.65)
    ax_h1.plot(hourly['Label'], hourly['avg_dt'], marker='o', color='#e53935',
               lw=2.2, label='Avg Delivery Time (min)', zorder=3)
    ax_h1.set_ylabel("Avg Delivery Time (min)", color='#e53935', fontsize=10)
    ax_h1.tick_params(axis='y', labelcolor='#e53935')
    ax_h2.set_ylabel("% of Daily Orders", color='#3949ab', fontsize=10)
    ax_h2.tick_params(axis='y', labelcolor='#3949ab')
    ax_h2.set_ylim(0, hourly['pct'].max() * 2.8)   # keep bars short so line is prominent
    ax_h1.set_xlabel("Hour of Day"); ax_h1.grid(True, alpha=0.2, axis='y')
    h1l, h1lb = ax_h1.get_legend_handles_labels()
    h2l, h2lb = ax_h2.get_legend_handles_labels()
    ax_h1.legend(h1l + h2l, h1lb + h2lb, loc='upper right', fontsize=9)
    _h_city_lbl = ' ‚Äî ' + ', '.join(_t2_city_f) if _t2_city_f else ' ‚Äî All Cities'
    plt.title(f"Hourly Delivery Time & Order Share{_h_city_lbl}", fontweight='bold')
    plt.xticks(rotation=90); plt.tight_layout()
    st.pyplot(fig_h); plt.close()

    # ‚îÄ‚îÄ Area charts (Dar vs Regional) ‚îÄ‚îÄ
    st.subheader("üìç Area Performance Charts")
    for area_name, cities in [("üèôÔ∏è Dar es Salaam", DAR_CITIES), ("üåç Regional", REGIONAL_CITIES)]:
        with st.expander(area_name):
            df_area = df2[df2['BUSINESS CITY'].isin(cities)]
            if df_area.empty:
                st.info("No data for this area in current filter.")
                continue
            for metric, title in [
                ('Average Delivery Time', 'Avg Delivery Time'),
                ('Driver in Business',    'Vendor Prep Time'),
                ('Pickup to Customer',    'Pickup ‚Üí Customer'),
            ]:
                fig_a, ax_a = plt.subplots(figsize=(10, 4))
                for city in cities:
                    cdf = df_area[df_area['BUSINESS CITY']==city]
                    if cdf.empty: continue
                    wk = (cdf.groupby(cdf['DELIVERY DATE'].dt.to_period('W-SUN'))[metric]
                          .mean().reset_index())
                    wk.columns = ['Period', metric]
                    wk = wk.sort_values('Period')
                    wk['Label'] = [f"W{i+1}" for i in range(len(wk))]
                    ax_a.plot(wk['Label'], wk[metric], marker='o', label=city)
                ax_a.set_title(f"{title} ‚Äî {area_name}")
                ax_a.set_ylabel("Minutes"); ax_a.grid(True, alpha=0.3); ax_a.legend()
                plt.tight_layout(); st.pyplot(fig_a); plt.close()

    # AI insight
    ai_insight_button("delivery_time", "Delivery Time Analysis", build_delivery_insight, city_stage, city_label)

    st.divider()

    # ‚îÄ‚îÄ Heatmap ‚îÄ‚îÄ
    st.subheader("üó∫Ô∏è Customer & Business Location Heatmap")
    req_geo = ['CUSTOMER LATITUDE','CUSTOMER LONGITUDE','BUSINESS LATITUDE','BUSINESS LONGITUDE']
    if all(c in df2.columns for c in req_geo):
        geo_all = df2.dropna(subset=req_geo)
        if not geo_all.empty:
            # ‚îÄ‚îÄ City filter for heatmap ‚îÄ‚îÄ
            _hm_cities = sorted(geo_all['BUSINESS CITY'].dropna().unique().tolist())
            _hm_col1, _hm_col2 = st.columns([2, 2])
            with _hm_col1:
                _hm_city_f = st.multiselect(
                    "üèôÔ∏è Filter by City (map)", _hm_cities,
                    placeholder="All cities", key="hm_city_filter"
                )
            with _hm_col2:
                map_type = st.radio("Map View",
                    ["Both","Customer Only","Business Only"], horizontal=True, key="del_map")

            geo = geo_all[geo_all['BUSINESS CITY'].isin(_hm_city_f)] if _hm_city_f else geo_all.copy()

            center = ([geo['CUSTOMER LATITUDE'].mean(), geo['CUSTOMER LONGITUDE'].mean()]
                      if not geo.empty else [-6.8018, 39.2801])
            m = folium.Map(location=center, zoom_start=13)
            if map_type != "Business Only":
                HeatMap(geo[['CUSTOMER LATITUDE','CUSTOMER LONGITUDE']].values.tolist(),
                        radius=12, blur=10).add_to(m)
            if map_type != "Customer Only":
                HeatMap(geo[['BUSINESS LATITUDE','BUSINESS LONGITUDE']].values.tolist(),
                        radius=15, blur=12).add_to(m)
            folium.LayerControl().add_to(m)

            top_n_del = st.slider("Top restaurants on map", 5, 30, 10, key="del_top_n")
            rp = (geo.groupby(['BUSINESS NAME','BUSINESS LATITUDE','BUSINESS LONGITUDE'])
                  .agg(Orders=('ID','count'), Sales=('SUBTOTAL','sum'),
                       AvgDT=('Average Delivery Time','mean'))
                  .reset_index().sort_values('Orders', ascending=False))
            for _, r in rp.head(top_n_del).iterrows():
                folium.CircleMarker(
                    [r['BUSINESS LATITUDE'], r['BUSINESS LONGITUDE']],
                    radius=7, color='navy', fill=True, fill_opacity=0.8,
                    popup=f"<b>{r['BUSINESS NAME']}</b><br>Orders: {int(r['Orders'])}<br>"
                          f"Avg DT: {r['AvgDT']:.1f} min"
                ).add_to(m)
            st.components.v1.html(m._repr_html_(), height=500)

            # ‚îÄ‚îÄ Post-map analysis ‚Äî city + week filterable ‚îÄ‚îÄ
            st.markdown("#### üìä Location-Based Analysis")
            _ma_col1, _ma_col2 = st.columns(2)
            with _ma_col1:
                _ma_city_f = st.multiselect(
                    "Filter by City", _hm_cities,
                    default=_hm_city_f,
                    placeholder="All cities", key="map_analysis_city"
                )
            with _ma_col2:
                _all_weeks_ma = sorted(geo_all['DELIVERY DATE'].dt.to_period('W-SUN').dropna().unique(), reverse=True)
                _week_opts_ma = ["All Weeks"] + [f"W{p.week} ({p.start_time.strftime('%d %b')})" for p in _all_weeks_ma]
                _sel_week_ma = st.selectbox("Filter by Week", _week_opts_ma, key="map_analysis_week")

            _ma_df = geo_all.copy()
            if _ma_city_f:
                _ma_df = _ma_df[_ma_df['BUSINESS CITY'].isin(_ma_city_f)]
            if _sel_week_ma != "All Weeks":
                _ma_wk_idx = _week_opts_ma.index(_sel_week_ma) - 1
                _ma_period = _all_weeks_ma[_ma_wk_idx]
                _ma_start = _ma_period.start_time
                _ma_end   = _ma_period.end_time
                _ma_df = _ma_df[(_ma_df['DELIVERY DATE'] >= _ma_start) & (_ma_df['DELIVERY DATE'] <= _ma_end)]

            if not _ma_df.empty:
                _city_label_ma = ', '.join(_ma_city_f) if _ma_city_f else 'All Cities'
                _wk_label_ma   = _sel_week_ma if _sel_week_ma != 'All Weeks' else 'All Weeks'
                st.caption(f"Showing: **{_city_label_ma}** | **{_wk_label_ma}** ‚Äî {len(_ma_df):,} orders")

                # Distance distribution
                _ma_dist_col, _ma_city_col = st.columns(2)
                with _ma_dist_col:
                    if 'Distance Category' in _ma_df.columns:
                        st.markdown("**Orders by Distance Category**")
                        _dist_grp = (_ma_df.groupby('Distance Category', observed=True)
                                     .agg(Orders=('ID','count'), Avg_DT=('Average Delivery Time','mean'))
                                     .reset_index())
                        _dist_grp['Avg_DT'] = _dist_grp['Avg_DT'].round(1)
                        _dist_grp = _dist_grp.rename(columns={'Distance Category':'Distance','Avg_DT':'Avg DT (min)'})
                        st.dataframe(_dist_grp, use_container_width=True)

                with _ma_city_col:
                    if 'BUSINESS CITY' in _ma_df.columns:
                        st.markdown("**Orders by City**")
                        _city_grp = (_ma_df.groupby('BUSINESS CITY')
                                     .agg(Orders=('ID','count'),
                                          Avg_DT=('Average Delivery Time','mean'),
                                          Avg_Dist=('DISTANCE (km)','mean'))
                                     .reset_index().sort_values('Orders', ascending=False))
                        _city_grp['Avg_DT'] = _city_grp['Avg_DT'].round(1)
                        _city_grp['Avg_Dist'] = _city_grp['Avg_Dist'].round(1)
                        _city_grp = _city_grp.rename(columns={
                            'BUSINESS CITY':'City','Avg_DT':'Avg DT (min)','Avg_Dist':'Avg Dist (km)'})
                        st.dataframe(_city_grp, use_container_width=True)

                # Delivery time breakdown by category ‚Äî percentages only
                st.markdown("**Delivery Time Categorization ‚Äî % of Orders by City**")
                st.caption("Shows share of orders in each delivery time band. üü¢ = on time. Goal: maximise green column.")
                _bins_ma = [0, 40, 50, 60, 90, float('inf')]
                _labels_ma = ['‚úÖ ‚â§40 min','üü° 41‚Äì50','üü† 51‚Äì60','üî¥ 61‚Äì90','‚õî 91+']
                _ma_df2 = _ma_df.copy()
                _ma_df2['DT Cat'] = pd.cut(_ma_df2['Average Delivery Time'], bins=_bins_ma, labels=_labels_ma)
                _dt_counts = (_ma_df2.pivot_table(
                    index='BUSINESS CITY', columns='DT Cat', values='ID',
                    aggfunc='count', fill_value=0, observed=True))
                _dt_totals = _dt_counts.sum(axis=1)
                _dt_pct = (_dt_counts.div(_dt_totals, axis=0) * 100).round(1)
                _dt_pct = _dt_pct.reset_index().rename(columns={'BUSINESS CITY':'City'})

                # Overall row
                _tot_counts = _dt_counts.sum()
                _tot_pct_row = (_tot_counts / _tot_counts.sum() * 100).round(1).to_dict()
                _tot_pct_row['City'] = 'ALL CITIES'
                _dt_pct_disp = pd.concat([_dt_pct, pd.DataFrame([_tot_pct_row])], ignore_index=True)

                # Sort by on-time % descending
                _on_time_col = '‚úÖ ‚â§40 min'
                if _on_time_col in _dt_pct_disp.columns:
                    _data_rows = _dt_pct_disp[_dt_pct_disp['City'] != 'ALL CITIES'].sort_values(_on_time_col, ascending=False)
                    _total_row_disp = _dt_pct_disp[_dt_pct_disp['City'] == 'ALL CITIES']
                    _dt_pct_disp = pd.concat([_data_rows, _total_row_disp], ignore_index=True)

                # Add % symbol for display
                _cat_cols = [c for c in _dt_pct_disp.columns if c != 'City']
                _dt_pct_str = _dt_pct_disp.copy()
                for _cc in _cat_cols:
                    _dt_pct_str[_cc] = _dt_pct_str[_cc].apply(lambda x: f"{x:.1f}%" if pd.notna(x) else "‚Äî")

                def _style_dt_pct(df_in):
                    sty = pd.DataFrame('', index=df_in.index, columns=df_in.columns)
                    _col_colors = {
                        '‚úÖ ‚â§40 min':  ('#1b5e20','#c8e6c9'),
                        'üü° 41‚Äì50':    ('#f57f17','#fff9c4'),
                        'üü† 51‚Äì60':    ('#e65100','#ffe0b2'),
                        'üî¥ 61‚Äì90':    ('#b71c1c','#ffcdd2'),
                        '‚õî 91+':      ('#4a148c','#e1bee7'),
                    }
                    for _i, row in df_in.iterrows():
                        if str(row.get('City','')) == 'ALL CITIES':
                            for _c in df_in.columns: sty.at[_i,_c] = 'background-color:#212121;color:#fff;font-weight:800'
                            continue
                        for _cc, (_tc, _bg) in _col_colors.items():
                            if _cc in df_in.columns:
                                try:
                                    v = float(str(row[_cc]).replace('%',''))
                                    intensity = min(v / 100, 1.0)
                                    sty.at[_i,_cc] = f'background-color:{_bg};color:{_tc};font-weight:{"700" if v > 50 else "500"}'
                                except: pass
                    return sty

                st.dataframe(_dt_pct_str.style.apply(_style_dt_pct, axis=None), use_container_width=True)

                # Horizontal stacked bar chart
                _cat_order = ['‚úÖ ‚â§40 min','üü° 41‚Äì50','üü† 51‚Äì60','üî¥ 61‚Äì90','‚õî 91+']
                _plot_cols = [c for c in _cat_order if c in _dt_pct.columns]
                _plot_cities = _dt_pct['City'].tolist()
                _bar_colors = ['#2e7d32','#f9a825','#e65100','#c62828','#6a1b9a']

                if _plot_cols:
                    _fig_dtcat, _ax_dtcat = plt.subplots(figsize=(11, max(3, len(_plot_cities)*0.55 + 1)))
                    _left = np.zeros(len(_plot_cities))
                    for _ci, (_col, _clr) in enumerate(zip(_plot_cols, _bar_colors[:len(_plot_cols)])):
                        _vals = _dt_pct[_col].fillna(0).values
                        _bars = _ax_dtcat.barh(_plot_cities, _vals, left=_left, color=_clr,
                                               label=_col, height=0.7)
                        for _bi, (_bar, _v) in enumerate(zip(_bars, _vals)):
                            if _v >= 8:
                                _ax_dtcat.text(_left[_bi] + _v/2, _bar.get_y() + _bar.get_height()/2,
                                              f"{_v:.0f}%", ha='center', va='center',
                                              fontsize=8, color='white', fontweight='bold')
                        _left += _vals
                    _ax_dtcat.set_xlabel("% of Orders")
                    _ax_dtcat.set_title("Delivery Time Distribution by City (%)", fontweight='bold')
                    _ax_dtcat.axvline(100, color='#555', lw=0.8, linestyle='--')
                    _ax_dtcat.invert_yaxis()
                    _ax_dtcat.legend(loc='lower right', fontsize=8, ncol=len(_plot_cols))
                    _ax_dtcat.set_xlim(0, 105)
                    plt.tight_layout()
                    st.pyplot(_fig_dtcat); plt.close()

                st.download_button("‚¨áÔ∏è Download Analysis",
                    data=excel_bytes(_dt_pct_disp.round(1), "Location Analysis"),
                    file_name="Location_Analysis.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            else:
                st.info("No data for the selected city/week combination.")

    # PDF report
    st.divider()
    if st.button("üñ®Ô∏è Generate Delivery PDF Report"):
        pdf_d = BytesIO()
        with PdfPages(pdf_d) as pdf:
            plt.figure(figsize=(11,8)); plt.axis('off')
            plt.text(0.5,0.6,"Piki Delivery Performance Report",fontsize=24,ha='center')
            plt.text(0.5,0.45,f"{date_range[0]} ‚Üí {date_range[1]}",fontsize=14,ha='center')
            pdf.savefig(); plt.close()
            for area_name, cities in [("Dar es Salaam", DAR_CITIES), ("Regional", REGIONAL_CITIES)]:
                for metric, title in [
                    ('Average Delivery Time','Avg Delivery Time'),
                    ('Driver in Business','Vendor Prep Time'),
                    ('Pickup to Customer','Pickup‚ÜíCustomer'),
                ]:
                    plt.figure(figsize=(10,5))
                    for city in cities:
                        cdf = df2[df2['BUSINESS CITY']==city]
                        if cdf.empty: continue
                        wk = cdf.groupby(cdf['DELIVERY DATE'].dt.to_period('W-SUN'))[metric].mean().reset_index()
                        wk.columns = ['P', metric]; wk = wk.sort_values('P')
                        plt.plot([f"W{i+1}" for i in range(len(wk))], wk[metric], marker='o', label=city)
                    plt.title(f"{title} ‚Äî {area_name}"); plt.ylabel("Min"); plt.legend(); plt.grid(True)
                    pdf.savefig(); plt.close()
        st.download_button("üì• Download Delivery PDF",
                           data=pdf_d.getvalue(),
                           file_name="Delivery_Performance_Report.pdf",
                           mime="application/pdf")


# TAB 3 ‚Äî RIDER ATTENDANCE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
with tab3:
    st.markdown('<div class="section-header">üö¥ Driver Attendance & Analysis</div>', unsafe_allow_html=True)

    df3 = df.copy()
    df3['DELIVERY DATE'] = pd.to_datetime(df3['DELIVERY DATE'], errors='coerce')

    # Zone map from full raw dataset for accuracy
    _zone_src = raw.copy()
    _zone_src['DELIVERY DATE'] = pd.to_datetime(_zone_src['DELIVERY DATE'], errors='coerce')
    zone_map = (_zone_src.groupby('DRIVER NAME')['BUSINESS CITY']
                .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else None))
    df3['WORKING ZONE'] = df3['DRIVER NAME'].map(zone_map)
    df3['ISO_Week'] = df3['DELIVERY DATE'].dt.isocalendar().week
    df3['ISO_Year'] = df3['DELIVERY DATE'].dt.isocalendar().year
    df3['Day of Week'] = df3['DELIVERY DATE'].dt.day_name()

    # ‚îÄ‚îÄ Week selector ‚Äî default latest ‚îÄ‚îÄ
    _att_wk = (df3.groupby(['ISO_Year','ISO_Week']).size().reset_index()[['ISO_Year','ISO_Week']]
               .sort_values(['ISO_Year','ISO_Week']))
    _att_wk['Label'] = (_att_wk['ISO_Year'].astype(str) + "-W"
                        + _att_wk['ISO_Week'].astype(str).str.zfill(2))
    att_labels = _att_wk['Label'].tolist()
    sel_week_att = st.selectbox("üìÖ Select ISO Week (default = latest)",
                                att_labels, index=len(att_labels)-1, key="att_week")
    _ayr = int(sel_week_att.split("-W")[0]); _awn = int(sel_week_att.split("-W")[1])
    df_week = df3[(df3['ISO_Year']==_ayr) & (df3['ISO_Week']==_awn)]

    # ‚îÄ‚îÄ Build attendance pivot ‚îÄ‚îÄ
    pivot_rows = []
    for _, tr in TARGET_RIDERS.iterrows():
        city = tr['Business City']
        row  = {'WORKING ZONE': city}
        city_df = df_week[df_week['WORKING ZONE'] == city]
        deficits, surplus = [], []
        for day in DAY_NAMES:
            dtype  = 'Weekend' if day in ['Saturday','Sunday'] else 'Weekday'
            std    = tr[f'{dtype} Active Riders']
            actual = city_df[city_df['Day of Week']==day]['DRIVER NAME'].nunique()
            row[day] = f"‚úÖ {actual}" if actual >= std else f"‚ö†Ô∏è {actual}/{std}"
            if actual < std:
                deficits.append(std - actual)
            else:
                surplus.append(actual - std)
        row['Avg Deficiency'] = round(sum(deficits)/len(deficits), 1) if deficits else 0.0
        row['Avg Surplus']    = round(sum(surplus)/len(surplus), 1)   if surplus  else 0.0
        row['Status'] = (f"‚ûï Add {int(round(sum(deficits)/len(deficits)))} rider(s)"
                         if deficits else "‚úÖ Sufficient")
        pivot_rows.append(row)

    att_pivot = pd.DataFrame(pivot_rows)

    # ‚îÄ‚îÄ 4 summary KPI metrics ‚îÄ‚îÄ
    n_deficient = len(att_pivot[att_pivot['Avg Deficiency'] > 0])
    n_ok        = len(att_pivot) - n_deficient
    worst_city  = (att_pivot.nlargest(1, 'Avg Deficiency')['WORKING ZONE'].values[0]
                   if n_deficient else "‚Äî")
    _ok_zones   = att_pivot[att_pivot['Avg Deficiency'] == 0]
    best_city   = (_ok_zones.nlargest(1, 'Avg Surplus')['WORKING ZONE'].values[0]
                   if not _ok_zones.empty else "‚Äî")

    _a1, _a2, _a3, _a4 = st.columns(4)
    _a1.metric("‚úÖ Cities at Target",    n_ok)
    _a2.metric("‚ö†Ô∏è Cities Understaffed", n_deficient)
    _a3.metric("üî¥ Worst Zone",          worst_city)
    _a4.metric("üü¢ Best Zone",           best_city)

    # Show pivot without surplus column for clean display
    _disp_cols = ['WORKING ZONE'] + DAY_NAMES + ['Avg Deficiency','Status']
    st.dataframe(att_pivot[_disp_cols], use_container_width=True)
    st.download_button("‚¨áÔ∏è Download Attendance Report",
                       data=excel_bytes(att_pivot, "Attendance"),
                       file_name=f"attendance_{sel_week_att}.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    # ‚îÄ‚îÄ Per-zone individual charts ‚îÄ‚îÄ
    st.subheader("üìä Daily Active Drivers by Zone")
    daily_drivers = (df_week.groupby(['WORKING ZONE','Day of Week'])['DRIVER NAME']
                     .nunique().reset_index(name='Active Drivers'))
    daily_drivers['Day of Week'] = pd.Categorical(daily_drivers['Day of Week'],
                                                   categories=DAY_NAMES, ordered=True)
    daily_drivers = daily_drivers.sort_values(['WORKING ZONE','Day of Week'])

    for group_name, group_cities in [("üèôÔ∏è Dar es Salaam", DAR_CITIES),
                                      ("üåç Regional", REGIONAL_CITIES)]:
        active_zones = [z for z in group_cities
                        if z in daily_drivers['WORKING ZONE'].values or
                           z in att_pivot['WORKING ZONE'].values]
        if not active_zones:
            continue
        st.markdown(f"#### {group_name}")
        # 2 charts per row
        for i in range(0, len(active_zones), 2):
            _cols = st.columns(2)
            for j, zone in enumerate(active_zones[i:i+2]):
                _zd = (daily_drivers[daily_drivers['WORKING ZONE']==zone]
                       .set_index('Day of Week').reindex(DAY_NAMES))
                _tr = TARGET_RIDERS[TARGET_RIDERS['Business City']==zone]
                if _tr.empty:
                    continue
                _wt = int(_tr['Weekday Active Riders'].values[0])
                _wet = int(_tr['Weekend Active Riders'].values[0])
                _targets = [_wet if d in ['Saturday','Sunday'] else _wt for d in DAY_NAMES]
                _actual  = _zd['Active Drivers'].fillna(0).values

                with _cols[j]:
                    fig_z, ax_z = plt.subplots(figsize=(6, 3.5))
                    _colors = ['#28a745' if a >= t else '#dc3545'
                               for a, t in zip(_actual, _targets)]
                    ax_z.bar(DAY_NAMES, _actual, color=_colors, alpha=0.8, label='Actual')
                    ax_z.step(range(len(DAY_NAMES)), _targets, where='mid',
                              color='black', linestyle='--', lw=1.5, label='Target')
                    ax_z.set_title(zone, fontsize=11, fontweight='bold')
                    ax_z.set_ylabel("Drivers"); ax_z.set_ylim(bottom=0)
                    ax_z.set_xticklabels([d[:3] for d in DAY_NAMES], fontsize=8)
                    ax_z.legend(fontsize=7); ax_z.grid(True, alpha=0.2, axis='y')
                    plt.tight_layout()
                    st.pyplot(fig_z); plt.close()

    # ‚îÄ‚îÄ AI Insight ‚Äî Attendance ‚îÄ‚îÄ
    _att_btn_key = "show_ins_rider_attendance"
    if _att_btn_key not in st.session_state:
        st.session_state[_att_btn_key] = False
    st.markdown(
        '''<div style="margin:12px 0 4px 0;">
        <span style="font-size:12px;color:#888;">AI-powered analysis of attendance patterns & KPI gaps</span>
        </div>''', unsafe_allow_html=True)
    if st.button("ü§ñ Generate AI Insight ‚Äî Attendance", key="btn_rider_att",
                 type="primary", use_container_width=False):
        st.session_state[_att_btn_key] = True
    if st.session_state[_att_btn_key]:
        with st.spinner("Analyzing attendance‚Ä¶"):
            ins3, ctx3 = build_attendance_insight(att_pivot, sel_week_att, df_week)
        ai_block("rider_attendance", ctx3, ins3)

    st.divider()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # DRIVER PERFORMANCE REVIEW ‚Äî Last 8 Weeks
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    st.markdown('<div class="section-header">üèÜ Driver Performance Review ‚Äî Last 8 Weeks</div>', unsafe_allow_html=True)

    # ‚îÄ‚îÄ Compute delivery stage metrics for completed orders ‚îÄ‚îÄ
    _dr_df = raw.copy()
    _dr_df['DELIVERY DATE'] = pd.to_datetime(_dr_df['DELIVERY DATE'], errors='coerce')
    _dr_df['Week'] = _dr_df['DELIVERY DATE'].dt.to_period('W-SUN').apply(lambda r: r.start_time)
    _dr_df = compute_delivery_stages(_dr_df)

    # Working zone map
    _dr_zone = (_dr_df.groupby('DRIVER NAME')['BUSINESS CITY']
                .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else "Unknown"))

    # ‚îÄ‚îÄ‚îÄ UNIFIED FILTER ‚Äî applies to all 4 sections ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    _uf_col1, _uf_col2 = st.columns(2)
    _all_dr_weeks = sorted(_dr_df['Week'].dropna().unique(), reverse=True)
    _dr_week_opts = ["All 8 Weeks"] + [f"W{int(w.isocalendar()[1])} ({w.strftime('%d %b')})" for w in _all_dr_weeks[:8]]

    with _uf_col1:
        _perf_zones_raw = sorted(_dr_df['BUSINESS CITY'].dropna().unique())
        _unified_zone = st.multiselect(
            "üèôÔ∏è Filter by Working Zone", _perf_zones_raw,
            placeholder="All zones ‚Äî affects all sections below", key="unified_zone_filter"
        )
    with _uf_col2:
        _unified_week = st.selectbox(
            "üìÖ Filter by Week (attendance view)", _dr_week_opts, key="unified_week_filter"
        )

    st.caption("üí° These filters apply to: Weekly Attendance, Driver KPI, Top/Bottom Performers, and Trend Chart")
    st.markdown("---")

    # Apply unified filters to _dr_df
    _dr_df_f = _dr_df.copy()
    if _unified_zone:
        _dr_df_f = _dr_df_f[_dr_df_f['BUSINESS CITY'].isin(_unified_zone)]
    if _unified_week != "All 8 Weeks":
        _uw_idx = _dr_week_opts.index(_unified_week) - 1
        _uw_period = _all_dr_weeks[_uw_idx]
        _dr_df_f = _dr_df_f[_dr_df_f['Week'] == _uw_period]

    # ‚îÄ‚îÄ‚îÄ Section A: Attendance ‚Äî last 8 weeks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("### üìÖ A. Weekly Attendance (Last 8 Weeks)")
    _weekdays_order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
    _recent_8_weeks = _dr_df_f['Week'].drop_duplicates().sort_values(ascending=False).head(8)

    _all_att = []
    for _wk in _recent_8_weeks:
        _wk_data = _dr_df_f[_dr_df_f['Week'] == _wk]
        _iso_w = int(_wk.isocalendar()[1])
        _wk_label = f"W{_iso_w}"
        _pivot = pd.pivot_table(_wk_data, values='ID', index='DRIVER NAME',
                                columns=_wk_data['DELIVERY DATE'].dt.day_name(),
                                aggfunc='count', fill_value=0)
        _pivot = _pivot.reindex(columns=_weekdays_order, fill_value=0)
        _pivot = _pivot.applymap(lambda x: '‚úî' if x > 0 else '‚Äî')
        _pivot['Days'] = (_pivot == '‚úî').sum(axis=1)
        _pivot['Orders'] = _wk_data.groupby('DRIVER NAME')['ID'].count()
        _pivot['Week'] = _wk_label
        _pivot = _pivot.reset_index()
        _all_att.append(_pivot)

    if _all_att:
        _att_all = pd.concat(_all_att, ignore_index=True)
        _att_all['Working Zone'] = _att_all['DRIVER NAME'].map(_dr_zone)
        _att_cols = ['Week','DRIVER NAME','Working Zone'] + _weekdays_order + ['Days','Orders']
        _att_all = _att_all[[c for c in _att_cols if c in _att_all.columns]]
        _perf_zones = sorted(_att_all['Working Zone'].dropna().unique())
        _att_show = _att_all.copy()

        # Total row
        _att_numeric = _att_show[['Days','Orders']].sum()
        _att_total_row = pd.DataFrame([{
            'Week': '‚Äî', 'DRIVER NAME': 'TOTAL', 'Working Zone': f"{_att_show['DRIVER NAME'].nunique()} drivers",
            **{d: '' for d in _weekdays_order},
            'Days': _att_numeric['Days'], 'Orders': int(_att_numeric['Orders'])
        }])
        _att_display = pd.concat([_att_show, _att_total_row], ignore_index=True)

        # Color-code rows
        def _style_att(v):
            if v == '‚úî': return 'background-color:#d4edda;color:#155724'
            if v == '‚Äî':  return 'background-color:#fff3cd;color:#856404'
            return ''

        st.dataframe(_att_display.style.applymap(_style_att,
                     subset=[c for c in _weekdays_order if c in _att_display.columns]),
                     use_container_width=True, height=400)
        st.download_button("‚¨áÔ∏è Download Attendance (8 weeks)",
                           data=excel_bytes(_att_all, "Attendance"),
                           file_name="Driver_Attendance_8W.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        # ‚îÄ‚îÄ Visualisations ‚îÄ‚îÄ
        _v1, _v2, _v3 = st.columns(3)
        with _v1:
            st.markdown("**Days worked distribution**")
            _days_dist = _att_all.groupby('DRIVER NAME')['Days'].mean().round(1)
            _fd, _ad = plt.subplots(figsize=(5,3))
            _days_dist.value_counts().sort_index().plot(kind='bar', ax=_ad,
                color='#4d96ff', edgecolor='white')
            _ad.set_xlabel("Avg days/week"); _ad.set_ylabel("# Drivers")
            _ad.set_title("Days Worked Distribution"); plt.tight_layout()
            st.pyplot(_fd); plt.close()

        with _v2:
            st.markdown("**Attendance rate by day**")
            _day_rate = _att_all[[d for d in _weekdays_order if d in _att_all.columns]].apply(
                lambda col: (col=='‚úî').sum() / len(col) * 100)
            _fr, _ar = plt.subplots(figsize=(5,3))
            _day_rate.plot(kind='bar', ax=_ar, color=['#28a745' if v>=60 else '#dc3545' for v in _day_rate])
            _ar.set_ylabel("Attendance %"); _ar.set_ylim(0,100)
            _ar.set_title("Attendance Rate by Day")
            _ar.set_xticklabels([d[:3] for d in _day_rate.index], rotation=0)
            plt.tight_layout(); st.pyplot(_fr); plt.close()

        with _v3:
            st.markdown("**Worked vs Missed (overall)**")
            _total_worked = (_att_all[[d for d in _weekdays_order if d in _att_all.columns]] == '‚úî').values.sum()
            _total_missed = (_att_all[[d for d in _weekdays_order if d in _att_all.columns]] == '‚Äî').values.sum()
            _fp, _ap = plt.subplots(figsize=(4,3))
            _ap.pie([_total_worked, _total_missed], labels=['Worked','Missed'],
                    colors=['#28a745','#ffc107'], autopct='%1.0f%%',
                    startangle=90, wedgeprops={'edgecolor':'white','lw':2})
            _ap.set_title("Overall Attendance"); plt.tight_layout()
            st.pyplot(_fp); plt.close()

    # ‚îÄ‚îÄ‚îÄ Section B: KPI Performance ‚Äî last 8 weeks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("### üìä B. Driver KPI Performance (Last 8 Weeks)")
    st.caption("Only clean completed deliveries used for time KPIs (outliers excluded). Distance = road estimate (haversine √ó 1.4)")

    # Apply distance to the filtered df
    _dr_df_dist = add_distance(_dr_df_f)
    _dr_comp = _dr_df_dist[_dr_df_dist['STATE'].isin(['Delivery Completed By Driver','Completed'])].copy()

    def _cat_issues(row):
        checks = [('Accepted by Business',30),('Assigned Time',30),('Accepted by Driver',45),
                  ('Driver to Business',45),('Driver in Business',90),('Pickup to Customer',45),
                  ('Average Delivery Time',100)]
        return ", ".join(c for c,l in checks
                         if pd.isnull(row.get(c,0)) or row.get(c,0) < 0 or row.get(c,0) > l)

    _dr_comp['Issues'] = _dr_comp.apply(_cat_issues, axis=1)
    _dr_comp_clean = _dr_comp[_dr_comp['Issues'] == ''].copy()

    _recent_8_kpi = _dr_comp_clean['Week'].drop_duplicates().sort_values(ascending=False).head(8)
    _all_kpis = []

    def _iso_w(ts):
        ic = ts.isocalendar()
        return ic.week if hasattr(ic,'week') else ic[1]

    for _wk in _recent_8_kpi:
        _wk_data = _dr_comp_clean[_dr_comp_clean['Week'] == _wk].copy()
        # Distance already applied via add_distance above; fill missing with 0
        if 'DISTANCE (km)' not in _wk_data.columns:
            _wk_data = add_distance(_wk_data)
        _wk_data['DISTANCE (km)'] = pd.to_numeric(_wk_data['DISTANCE (km)'], errors='coerce').fillna(0)
        _kpi = _wk_data.groupby('DRIVER NAME').agg(
            Avg_DT=('Average Delivery Time','mean'),
            Accepted_Biz=('Accepted by Business','mean'),
            Assigned_T=('Assigned Time','mean'),
            Accepted_Drv=('Accepted by Driver','mean'),
            Drv_to_Biz=('Driver to Business','mean'),
            Drv_in_Biz=('Driver in Business','mean'),
            Pickup_Cust=('Pickup to Customer','mean'),
            Total_Orders=('ID','count'),
            Total_KM=('DISTANCE (km)','sum'),
            Avg_KM=('DISTANCE (km)','mean')
        ).round(1).reset_index()
        _kpi.columns = ['DRIVER NAME','Avg DT (min)','Accepted by Biz','Assigned Time',
                        'Accepted by Driver','Driver‚ÜíBusiness','Driver in Biz','Pickup‚ÜíCustomer',
                        'Total Orders','Total KM','Avg KM/Order']
        _kpi['Week'] = f"W{int(_iso_w(_wk))}"; _kpi['Working Zone'] = _kpi['DRIVER NAME'].map(_dr_zone)
        _all_kpis.append(_kpi)

    _kpi_all = pd.DataFrame()
    if _all_kpis:
        _kpi_all = pd.concat(_all_kpis, ignore_index=True)
        _kpi_all = _kpi_all[['Week','DRIVER NAME','Working Zone','Total Orders',
                              'Avg DT (min)','Accepted by Biz','Assigned Time','Accepted by Driver',
                              'Driver‚ÜíBusiness','Driver in Biz','Pickup‚ÜíCustomer','Total KM','Avg KM/Order']]

        # Sort most-recent week first per driver
        _kpi_all['_wn'] = _kpi_all['Week'].str.extract(r'(\d+)').astype(int)
        _kpi_all = _kpi_all.sort_values(['DRIVER NAME','_wn'], ascending=[True,False]).drop(columns='_wn')

        _kpi_show = _kpi_all.copy()  # unified filter already applied via _dr_df_f

        # Total row
        _kpi_numeric_cols = ['Total Orders','Avg DT (min)','Accepted by Biz','Assigned Time',
                             'Accepted by Driver','Driver‚ÜíBusiness','Driver in Biz','Pickup‚ÜíCustomer',
                             'Total KM','Avg KM/Order']
        _kpi_total_vals = {'Week': '‚Äî', 'DRIVER NAME': f'TOTAL ({_kpi_show["DRIVER NAME"].nunique()} drivers)',
                           'Working Zone': '‚Äî'}
        for _nc in _kpi_numeric_cols:
            if _nc in _kpi_show.columns:
                if _nc in ('Total Orders','Total KM'):
                    _kpi_total_vals[_nc] = round(_kpi_show[_nc].sum(), 1)
                else:
                    _kpi_total_vals[_nc] = round(_kpi_show[_nc].mean(), 1)
        _kpi_show_disp = pd.concat([_kpi_show, pd.DataFrame([_kpi_total_vals])], ignore_index=True)

        # Per-row distance-based target for KPI table
        # Avg KM/Order is already road distance (√ó1.4 applied); use for per-row target
        def _kpi_row_target(avg_km):
            try:
                km = float(avg_km)
                if km <= 0: return 44.0
                p2c = round((km / STAGE_DRIVING_SPEED_KMH * 60) + STAGE_P2C_OVERHEAD_MIN, 1)
                return round(sum(STAGE_TARGETS_FIXED.values()) + p2c, 1)
            except: return 44.0

        if 'Avg KM/Order' in _kpi_show_disp.columns:
            _kpi_show_disp = _kpi_show_disp.copy()
            _kpi_show_disp['ADT Target'] = _kpi_show_disp['Avg KM/Order'].apply(_kpi_row_target)
            _kpi_show_disp['vs Target'] = (_kpi_show_disp['Avg DT (min)'].apply(
                lambda x: round(float(x) - _kpi_row_target(0), 1) if str(x) == '‚Äî' else x) - 
                _kpi_show_disp['ADT Target']).round(1)

        # Professional full-row styling for KPI table
        def _style_kpi_table(df_in):
            sty = pd.DataFrame('', index=df_in.index, columns=df_in.columns)
            for _i, row in df_in.iterrows():
                driver = str(row.get('DRIVER NAME',''))
                # Total row ‚Äî dark
                if 'TOTAL' in driver:
                    for _c in df_in.columns: sty.at[_i,_c] = 'background-color:#1a1a2e;color:#fff;font-weight:800'
                    continue
                # Avg DT vs distance-based target
                try:
                    adt_v = float(row.get('Avg DT (min)', 0))
                    tgt_v = float(row.get('ADT Target', 44.0)) if 'ADT Target' in df_in.columns else 44.0
                    if adt_v <= tgt_v:
                        sty.at[_i,'Avg DT (min)'] = 'background-color:#c8e6c9;color:#1b5e20;font-weight:700'
                    elif adt_v <= tgt_v * 1.15:
                        sty.at[_i,'Avg DT (min)'] = 'background-color:#fff9c4;color:#f57f17;font-weight:700'
                    else:
                        sty.at[_i,'Avg DT (min)'] = 'background-color:#ffcdd2;color:#b71c1c;font-weight:700'
                except: pass
                # vs Target column
                if 'vs Target' in df_in.columns:
                    try:
                        vt = float(row.get('vs Target', 0))
                        sty.at[_i,'vs Target'] = ('background-color:#c8e6c9;color:#1b5e20;font-weight:700' if vt <= 0
                                                   else 'background-color:#fff9c4;color:#f57f17;font-weight:700' if vt <= 5
                                                   else 'background-color:#ffcdd2;color:#b71c1c;font-weight:700')
                    except: pass
                # Fixed stage targets
                for _col, _tgt in STAGE_TARGETS_FIXED.items():
                    _alias = {'Accepted by Business':'Accepted by Biz',
                              'Assigned Time':'Assigned Time',
                              'Accepted by Driver':'Accepted by Driver',
                              'Driver to Business':'Driver‚ÜíBusiness',
                              'Driver in Business':'Driver in Biz'}.get(_col, _col)
                    if _alias in df_in.columns:
                        try:
                            v = float(row.get(_alias, 0))
                            sty.at[_i,_alias] = ('background-color:#e8f5e9;color:#1b5e20' if v <= _tgt
                                                  else 'background-color:#fffde7;color:#f57f17' if v <= _tgt*1.5
                                                  else 'background-color:#ffebee;color:#b71c1c')
                        except: pass
                # High orders = highlight
                if 'Total Orders' in df_in.columns:
                    try:
                        if float(row['Total Orders']) >= 40:
                            sty.at[_i,'Total Orders'] = 'background-color:#e3f2fd;color:#0d47a1;font-weight:700'
                    except: pass
            return sty

        # Reorder columns to put ADT Target and vs Target right after Avg DT
        _col_order = ['Week','DRIVER NAME','Working Zone','Total Orders','Avg DT (min)']
        if 'ADT Target' in _kpi_show_disp.columns: _col_order.append('ADT Target')
        if 'vs Target' in _kpi_show_disp.columns:  _col_order.append('vs Target')
        _col_order += [c for c in _kpi_show_disp.columns if c not in _col_order]
        _kpi_show_disp = _kpi_show_disp[[c for c in _col_order if c in _kpi_show_disp.columns]]

        st.dataframe(_kpi_show_disp.style.apply(_style_kpi_table, axis=None),
                     use_container_width=True, height=440)
        st.caption("üü¢ At/below target  üü° Within 15% over  üî¥ More than 15% over  |  **ADT Target** = 25.5 min fixed + P2C (road dist √∑ 30 km/h √ó 60 + 6 min overhead)")
        st.download_button("‚¨áÔ∏è Download Driver KPIs (8 weeks)",
                           data=excel_bytes(_kpi_all, "Driver KPIs"),
                           file_name="Driver_KPIs_8W.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        # ‚îÄ‚îÄ Top / Bottom performers visual ‚îÄ‚îÄ
        st.markdown("#### üèÖ Top & Bottom Performers (8-Week Average Delivery Time)")
        _perf_sum = (_kpi_all.groupby(['DRIVER NAME','Working Zone'])['Avg DT (min)']
                     .mean().round(1).reset_index()
                     .rename(columns={'Avg DT (min)':'8W Avg DT (min)'})
                     .sort_values('8W Avg DT (min)'))
        _pg1, _pg2 = st.columns(2)
        with _pg1:
            st.markdown("üü¢ **Top 10 Fastest Riders**")
            _top10 = _perf_sum.head(10)
            _ftop, _atop = plt.subplots(figsize=(6,3.5))
            _bars_top = _atop.barh(_top10['DRIVER NAME'], _top10['8W Avg DT (min)'], color='#28a745')
            _atop.bar_label(_bars_top, fmt='%.1f', padding=3, fontsize=8)
            _atop.axvline(45, color='green', lw=1.5, linestyle='--', label='Target')
            _atop.set_xlabel("Avg DT (min)"); _atop.invert_yaxis()
            _atop.set_title("Fastest Riders"); _atop.legend(fontsize=7); plt.tight_layout()
            st.pyplot(_ftop); plt.close()
            st.dataframe(_top10[['DRIVER NAME','Working Zone','8W Avg DT (min)']],
                         use_container_width=True)
        with _pg2:
            st.markdown("üî¥ **Bottom 10 ‚Äî Need Coaching**")
            _bot10 = _perf_sum.tail(10).sort_values('8W Avg DT (min)', ascending=False)
            _fbot, _abot = plt.subplots(figsize=(6,3.5))
            _bars_bot = _abot.barh(_bot10['DRIVER NAME'], _bot10['8W Avg DT (min)'], color='#dc3545')
            _abot.bar_label(_bars_bot, fmt='%.1f', padding=3, fontsize=8)
            _abot.axvline(55, color='red', lw=1.5, linestyle=':', label='Alert')
            _abot.set_xlabel("Avg DT (min)"); _abot.invert_yaxis()
            _abot.set_title("Needs Coaching"); _abot.legend(fontsize=7); plt.tight_layout()
            st.pyplot(_fbot); plt.close()
            st.dataframe(_bot10[['DRIVER NAME','Working Zone','8W Avg DT (min)']],
                         use_container_width=True)

        # ‚îÄ‚îÄ Weekly trend chart ‚Äî 3 views ‚îÄ‚îÄ
        st.markdown("#### üìà Delivery Time Trend")
        _trend_view = st.radio(
            "Chart view",
            ["By Volume ‚Äî Top 10 Riders", "Delivery Time: Best (fastest first)", "Delivery Time: Worst (slowest first)"],
            horizontal=True, key="trend_view_radio"
        )

        _perf_sum_chart = (_kpi_all.groupby('DRIVER NAME')
                           .agg(**{'8W Avg DT': ('Avg DT (min)','mean'), 'Total Orders': ('Total Orders','sum')})
                           .round(1).reset_index())

        if _trend_view == "By Volume ‚Äî Top 10 Riders":
            _chart_riders = _perf_sum_chart.sort_values('Total Orders', ascending=False).head(10)['DRIVER NAME'].tolist()
            _chart_title = "Weekly Delivery Time Trend ‚Äî Top 10 by Volume"
        elif _trend_view == "Delivery Time: Best (fastest first)":
            _chart_riders = _perf_sum_chart.sort_values('8W Avg DT').head(10)['DRIVER NAME'].tolist()
            _chart_title = "Delivery Time Trend ‚Äî Top 10 Fastest Riders"
        else:
            _chart_riders = _perf_sum_chart.sort_values('8W Avg DT', ascending=False).head(10)['DRIVER NAME'].tolist()
            _chart_title = "Delivery Time Trend ‚Äî Top 10 Slowest Riders (Needs Coaching)"

        _td = _kpi_all[_kpi_all['DRIVER NAME'].isin(_chart_riders)]
        _fig_tr, _ax_tr = plt.subplots(figsize=(13,5))
        for _rn in _chart_riders:
            _rd = _td[_td['DRIVER NAME']==_rn].sort_values('Week')
            if _rd.empty: continue
            _ax_tr.plot(_rd['Week'], _rd['Avg DT (min)'], marker='o', lw=1.5, label=_rn)
        _ax_tr.axhline(45, color='green', lw=2, linestyle='--', label='Target (45 min)')
        _ax_tr.axhline(55, color='red', lw=1.5, linestyle=':', label='Alert (55 min)')
        _ax_tr.set_xlabel("Week"); _ax_tr.set_ylabel("Avg DT (min)")
        _ax_tr.set_title(_chart_title)
        _ax_tr.legend(fontsize=7, ncol=4); _ax_tr.grid(True, alpha=0.3)
        plt.tight_layout(); st.pyplot(_fig_tr); plt.close()

    # ‚îÄ‚îÄ‚îÄ Section E: Individual Rider Deep Dive ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("### üîç E. Individual Rider Search")
    st.caption("Default shows the top rider by order volume. Search by name or select from the dropdown.")

    _all_drivers_list = sorted(_dr_df['DRIVER NAME'].dropna().unique().tolist())

    # Default = top rider by total order volume
    _vol_rank = (_dr_df.groupby('DRIVER NAME')['ID'].count()
                 .sort_values(ascending=False).reset_index())
    _default_rider = _vol_rank['DRIVER NAME'].iloc[0] if not _vol_rank.empty else (_all_drivers_list[0] if _all_drivers_list else None)

    _e_col1, _e_col2 = st.columns([2, 3])
    with _e_col1:
        _rider_search = st.text_input("üîé Filter list by name", placeholder="Type to narrow‚Ä¶", key="rider_search_input")
    with _e_col2:
        if _rider_search:
            _matched = [d for d in _all_drivers_list if _rider_search.lower() in d.lower()]
            if not _matched:
                st.warning(f"No driver matching '{_rider_search}'")
                _matched = _all_drivers_list
        else:
            _matched = _all_drivers_list

        _default_idx = _matched.index(_default_rider) if _default_rider in _matched else 0
        _sel_driver = st.selectbox(
            "Select Driver (default = top by volume)",
            _matched, index=_default_idx, key="rider_select_box"
        )

    if _sel_driver:
        # Full data for this driver (all weeks, all states)
        _ind_df = _dr_df[_dr_df['DRIVER NAME'] == _sel_driver].copy()
        _ind_df = add_distance(_ind_df)
        _ind_comp = _ind_df[_ind_df['STATE'].isin(['Delivery Completed By Driver','Completed'])].copy()

        # Per-order targets using new model
        if 'DISTANCE (km)' in _ind_comp.columns and not _ind_comp.empty:
            _ind_comp = _ind_comp.copy()
            _ind_comp['P2C Target'] = (_ind_comp['DISTANCE (km)'] / STAGE_DRIVING_SPEED_KMH * 60 + STAGE_P2C_OVERHEAD_MIN).round(1)
            _ind_comp['Total Target'] = (sum(STAGE_TARGETS_FIXED.values()) + _ind_comp['P2C Target']).round(1)
            _ind_comp['vs Target'] = (_ind_comp['Average Delivery Time'] - _ind_comp['Total Target']).round(1)

        _zone_name = _dr_zone.get(_sel_driver, "Unknown")
        _avg_dt   = round(_ind_comp['Average Delivery Time'].mean(), 1) if not _ind_comp.empty else None
        _avg_dist = round(_ind_comp['DISTANCE (km)'].mean(), 1) if ('DISTANCE (km)' in _ind_comp.columns and not _ind_comp.empty) else None
        _avg_tgt  = round(_ind_comp['Total Target'].mean(), 1) if ('Total Target' in _ind_comp.columns and not _ind_comp.empty) else None
        _vs_tgt   = round(_avg_dt - _avg_tgt, 1) if (_avg_dt and _avg_tgt) else None
        _rnk_row  = _vol_rank[_vol_rank['DRIVER NAME'] == _sel_driver]
        _vol_rank_pos = int(_rnk_row.index[0]) + 1 if not _rnk_row.empty else '‚Äî'

        # Header banner
        st.markdown(f"""
<div style="background:linear-gradient(135deg,#1a237e,#283593);color:#fff;border-radius:12px;padding:18px 24px;margin-bottom:16px;">
  <div style="font-size:1.4rem;font-weight:800;margin-bottom:4px;">üö¥ {_sel_driver}</div>
  <div style="font-size:0.95rem;opacity:0.85;">Zone: {_zone_name}&nbsp;&nbsp;|&nbsp;&nbsp;Volume Rank: #{_vol_rank_pos} of {len(_all_drivers_list)} riders</div>
</div>""", unsafe_allow_html=True)

        # KPI scorecard
        _sc1, _sc2, _sc3, _sc4, _sc5 = st.columns(5)
        _sc1.metric("üì¶ Total Orders", f"{len(_ind_df):,}")
        _sc2.metric("‚úÖ Completed", f"{len(_ind_comp):,}")
        _sc3.metric("‚è± Avg Delivery Time",
                    f"{_avg_dt:.1f} min" if _avg_dt else "‚Äî",
                    delta=f"Target {_avg_tgt:.1f} min" if _avg_tgt else None,
                    delta_color="normal" if (_avg_dt and _avg_tgt and _avg_dt <= _avg_tgt) else "inverse")
        _sc4.metric("üìè Avg Road Dist",
                    f"{_avg_dist:.1f} km" if _avg_dist else "‚Äî",
                    help="Straight-line √ó 1.6 road factor")
        _sc5.metric("üéØ vs Target",
                    f"{_vs_tgt:+.1f} min" if _vs_tgt is not None else "‚Äî",
                    delta_color="normal" if (_vs_tgt is not None and _vs_tgt <= 0) else "inverse")

        # Inner tabs
        _rt1, _rt2, _rt3 = st.tabs(["üìÖ Weekly Breakdown", "üìê Stage Analysis", "üìç Delivery Map"])

        with _rt1:
            if not _ind_comp.empty:
                if 'Total Target' in _ind_comp.columns:
                    _ind_wk = (_ind_comp.groupby('Week').agg(
                        Orders=('ID','count'),
                        Avg_DT=('Average Delivery Time','mean'),
                        Avg_Dist=('DISTANCE (km)','mean'),
                        Avg_Target=('Total Target','mean'),
                    ).round(1).reset_index())
                    _ind_wk['vs Target'] = (_ind_wk['Avg_DT'] - _ind_wk['Avg_Target']).round(1)
                    _ind_wk['Status'] = _ind_wk['vs Target'].apply(
                        lambda x: '‚úÖ On Target' if x <= 0 else ('‚ö†Ô∏è Near' if x <= 5 else '‚ùå Over'))
                else:
                    _ind_wk = (_ind_comp.groupby('Week').agg(
                        Orders=('ID','count'), Avg_DT=('Average Delivery Time','mean'),
                        Avg_Dist=('DISTANCE (km)','mean')).round(1).reset_index())

                _ind_wk['Week'] = _ind_wk['Week'].apply(
                    lambda w: f"W{int(w.isocalendar()[1])} ({w.strftime('%d %b')})")

                # OVERALL row
                _ovr = {'Week': 'OVERALL', 'Orders': int(_ind_wk['Orders'].sum())}
                for _nc in [c for c in _ind_wk.columns if c not in ('Week','Status','Orders')]:
                    try: _ovr[_nc] = round(float(_ind_wk[_nc].mean()), 1)
                    except: pass
                if 'vs Target' in _ind_wk.columns:
                    _ovr_vt = float(_ovr.get('vs Target', 0))
                    _ovr['Status'] = '‚úÖ On Target' if _ovr_vt <= 0 else ('‚ö†Ô∏è Near' if _ovr_vt <= 5 else '‚ùå Over')
                _ind_wk_disp = pd.concat([_ind_wk, pd.DataFrame([_ovr])], ignore_index=True)

                def _style_rdr_wk(df_in):
                    sty = pd.DataFrame('', index=df_in.index, columns=df_in.columns)
                    for _i, row in df_in.iterrows():
                        if str(row.get('Week','')) == 'OVERALL':
                            for _c in df_in.columns: sty.at[_i,_c] = 'background-color:#212121;color:#fff;font-weight:800'
                            continue
                        if 'vs Target' in df_in.columns:
                            try:
                                vt = float(row['vs Target'])
                                _cs = ('background-color:#c8e6c9;color:#1b5e20;font-weight:700' if vt <= 0
                                       else 'background-color:#fff9c4;color:#f57f17;font-weight:700' if vt <= 5
                                       else 'background-color:#ffcdd2;color:#b71c1c;font-weight:700')
                                for _c in ('vs Target','Status','Avg_DT'): 
                                    if _c in df_in.columns: sty.at[_i,_c] = _cs
                            except: pass
                    return sty

                st.dataframe(_ind_wk_disp.style.apply(_style_rdr_wk, axis=None), use_container_width=True)
                st.caption("üü¢ On/under target  üü° Within 5 min  üî¥ Over target  |  vs Target: -ve = faster than target ‚úÖ")

                if len(_ind_wk) > 1 and 'Avg_DT' in _ind_wk.columns:
                    _fig_rw, _ax_rw = plt.subplots(figsize=(10, 3))
                    _wl = _ind_wk['Week'].tolist()
                    _ax_rw.plot(_wl, _ind_wk['Avg_DT'], marker='o', color='#e53935', lw=2, label='Avg DT')
                    if 'Avg_Target' in _ind_wk.columns:
                        _ax_rw.plot(_wl, _ind_wk['Avg_Target'], marker='s', color='#43a047',
                                    lw=1.5, linestyle='--', label='Target (dist-based)')
                        _ax_rw.fill_between(range(len(_wl)), 0, _ind_wk['Avg_Target'].values,
                                            alpha=0.07, color='green')
                    _ax_rw.set_title(f"Weekly DT vs Target ‚Äî {_sel_driver}")
                    _ax_rw.set_ylabel("Minutes"); _ax_rw.grid(True, alpha=0.3); _ax_rw.legend(fontsize=8)
                    plt.xticks(rotation=30, ha='right'); plt.tight_layout()
                    st.pyplot(_fig_rw); plt.close()
            else:
                st.info("No completed orders found for this rider.")

        with _rt2:
            if not _ind_comp.empty and 'Distance Category' in _ind_comp.columns:
                st.markdown("**Performance by Distance Category**")
                st.caption(f"P2C Target = road dist √∑ {STAGE_DRIVING_SPEED_KMH} km/h √ó 60 + {STAGE_P2C_OVERHEAD_MIN} min overhead")
                _agg_d = {c: 'mean' for c in ['Average Delivery Time','Accepted by Business','Assigned Time',
                           'Accepted by Driver','Driver to Business','Driver in Business','Pickup to Customer','DISTANCE (km)']
                           if c in _ind_comp.columns}
                _agg_d['ID'] = 'count'
                _rn_map = {'ID':'Orders','Average Delivery Time':'Avg DT','DISTANCE (km)':'Avg Dist (km)'}
                _ind_dist = (_ind_comp.groupby('Distance Category', observed=True).agg(**{
                    (_rn_map.get(k,k)): (k,v) for k,v in _agg_d.items()}).round(1).reset_index())
                if 'Avg Dist (km)' in _ind_dist.columns:
                    _ind_dist['P2C Target'] = (_ind_dist['Avg Dist (km)'] / STAGE_DRIVING_SPEED_KMH * 60 + STAGE_P2C_OVERHEAD_MIN).round(1)
                    _ind_dist['Total Target'] = (sum(STAGE_TARGETS_FIXED.values()) + _ind_dist['P2C Target']).round(1)
                    _ind_dist['vs Target'] = (_ind_dist['Avg DT'] - _ind_dist['Total Target']).round(1)
                # TOTAL row
                _dt_tot = {'Distance Category': 'ALL'}
                for _nc in _ind_dist.columns:
                    if _nc == 'Distance Category': continue
                    try: _dt_tot[_nc] = round(float(_ind_dist[_nc].mean()), 1)
                    except: pass
                if 'Orders' in _ind_dist.columns:
                    _dt_tot['Orders'] = int(_ind_dist['Orders'].sum())
                _ind_dist_disp = pd.concat([_ind_dist, pd.DataFrame([_dt_tot])], ignore_index=True)

                def _style_dist_tbl(df_in):
                    sty = pd.DataFrame('', index=df_in.index, columns=df_in.columns)
                    for _i, row in df_in.iterrows():
                        if str(row.get('Distance Category','')) == 'ALL':
                            for _c in df_in.columns: sty.at[_i,_c] = 'background-color:#212121;color:#fff;font-weight:800'
                            continue
                        for _col, _tgt in STAGE_TARGETS_FIXED.items():
                            if _col in df_in.columns:
                                try:
                                    v = float(row[_col])
                                    sty.at[_i,_col] = ('background-color:#c8e6c9;color:#1b5e20;font-weight:600' if v <= _tgt
                                                        else 'background-color:#fff9c4;color:#f57f17;font-weight:600' if v <= _tgt*1.5
                                                        else 'background-color:#ffcdd2;color:#b71c1c;font-weight:600')
                                except: pass
                        if 'vs Target' in df_in.columns:
                            try:
                                vt = float(row['vs Target'])
                                sty.at[_i,'vs Target'] = ('background-color:#c8e6c9;color:#1b5e20;font-weight:700' if vt <= 0
                                                           else 'background-color:#fff9c4;color:#f57f17;font-weight:700' if vt <= 5
                                                           else 'background-color:#ffcdd2;color:#b71c1c;font-weight:700')
                            except: pass
                    return sty

                st.dataframe(_ind_dist_disp.style.apply(_style_dist_tbl, axis=None), use_container_width=True)
                st.caption("üü¢ At/below target (good)  üü° 1‚Äì1.5√ó target (slightly slow)  üî¥ Over 1.5√ó target (action needed)  |  vs Target: -ve = faster ‚úÖ  +ve = slower ‚ùå")
            else:
                st.info("Distance data not available.")

        with _rt3:
            if all(c in _ind_comp.columns for c in ['CUSTOMER LATITUDE','CUSTOMER LONGITUDE']):
                _heat_data = _ind_comp[['CUSTOMER LATITUDE','CUSTOMER LONGITUDE']].dropna().values.tolist()
                if _heat_data:
                    st.caption(f"{len(_heat_data)} delivery locations")
                    _m_ind = folium.Map(location=[-6.8018, 39.2801], zoom_start=13)
                    HeatMap(_heat_data, radius=15, blur=10, max_zoom=1).add_to(_m_ind)
                    st.components.v1.html(_m_ind._repr_html_(), height=450)
                else:
                    st.info("No GPS coordinates.")
            else:
                st.info("GPS data not available.")

        _show_cols = [c for c in ['ID','BUSINESS NAME','DELIVERY DATE','DISTANCE (km)','Distance Category',
                                   'Accepted by Business','Assigned Time','Accepted by Driver',
                                   'Driver to Business','Driver in Business','Pickup to Customer',
                                   'Average Delivery Time','Total Target','vs Target','STATE'] if c in _ind_df.columns]
        with st.expander("üìã Recent Orders (last 50)"):
            st.dataframe(_ind_df[_show_cols].sort_values('DELIVERY DATE', ascending=False).head(50),
                         use_container_width=True)

        if not _ind_comp.empty:
            st.download_button("‚¨áÔ∏è Download Rider Data",
                               data=excel_bytes(_ind_comp[[c for c in _show_cols if c in _ind_comp.columns]], "Rider Data"),
                               file_name=f"Rider_{_sel_driver.replace(' ','_')}.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    st.divider()

    # ‚îÄ‚îÄ‚îÄ Section B2: Dar es Salaam Monthly Bonus ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.divider()
    st.markdown("### üåü B2. Dar es Salaam Monthly Rider Bonus")
    st.caption("Monthly bonus based on a custom date range. Default = last 4 calendar weeks from data.")

    # ‚îÄ‚îÄ DATE RANGE FILTER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("##### üìÖ Bonus Period ‚Äî Select Date Range")
    st.info(
        "**Default:** last 4 weeks in the data.  "
        "**To calculate a real bonus month** (e.g. 29 Jan ‚Üí 28 Feb), select the exact dates below. "
        "The system will use ALL orders within the selected range.",
        icon="‚ÑπÔ∏è"
    )

    _dar_raw_all = raw.copy()
    _dar_raw_all['DELIVERY DATE'] = pd.to_datetime(_dar_raw_all['DELIVERY DATE'], errors='coerce')
    _dar_raw_dar = _dar_raw_all[_dar_raw_all['BUSINESS CITY'].isin(DAR_CITIES)].copy()

    # Compute default: last 4 complete weeks in data
    _dar_raw_dar['_wk'] = _dar_raw_dar['DELIVERY DATE'].dt.to_period('W-SUN')
    _dar_avail_wks = sorted(_dar_raw_dar['_wk'].dropna().unique(), reverse=True)
    _dar_default_4wks = _dar_avail_wks[:4]
    if _dar_default_4wks:
        _dar_default_start = _dar_default_4wks[-1].start_time.date()   # earliest week start
        _dar_default_end   = _dar_default_4wks[0].end_time.date()      # latest week end
    else:
        import datetime as _dt_lib
        _dar_default_end   = _dt_lib.date.today()
        _dar_default_start = _dar_default_end - _dt_lib.timedelta(days=27)

    _dar_min_date = _dar_raw_dar['DELIVERY DATE'].min().date() if not _dar_raw_dar.empty else _dar_default_start
    _dar_max_date = _dar_raw_dar['DELIVERY DATE'].max().date() if not _dar_raw_dar.empty else _dar_default_end

    _dc1, _dc2 = st.columns(2)
    with _dc1:
        _dar_bonus_start = st.date_input(
            "üìÖ Bonus Period Start",
            value=_dar_default_start,
            min_value=_dar_min_date,
            max_value=_dar_max_date,
            key="dar_bonus_start",
            help="Start of the bonus calculation period (e.g. 29 January)"
        )
    with _dc2:
        _dar_bonus_end = st.date_input(
            "üìÖ Bonus Period End",
            value=_dar_default_end,
            min_value=_dar_min_date,
            max_value=_dar_max_date,
            key="dar_bonus_end",
            help="End of the bonus calculation period (e.g. 28 February)"
        )

    if _dar_bonus_start > _dar_bonus_end:
        st.error("‚ö†Ô∏è Start date must be before end date. Please adjust the date range.")
        st.stop()

    _dar_period_days = (_dar_bonus_end - _dar_bonus_start).days + 1
    st.caption(
        f"üìÜ **Selected period:** {_dar_bonus_start.strftime('%d %b %Y')} ‚Üí "
        f"{_dar_bonus_end.strftime('%d %b %Y')}  ({_dar_period_days} days)  |  "
        f"Default was: {_dar_default_start.strftime('%d %b')} ‚Üí {_dar_default_end.strftime('%d %b')} (4 weeks)"
    )

    # ‚îÄ‚îÄ Filter Dar data to selected date range ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    _dar_df = _dar_raw_dar[
        (_dar_raw_dar['DELIVERY DATE'].dt.date >= _dar_bonus_start) &
        (_dar_raw_dar['DELIVERY DATE'].dt.date <= _dar_bonus_end)
    ].copy()
    _dar_df['Week'] = _dar_df['DELIVERY DATE'].dt.to_period('W-SUN').apply(lambda r: r.start_time)
    _dar_df = _dar_df[_dar_df['HOUR'].isin(OPERATING_HOURS)] if 'HOUR' in _dar_df.columns else _dar_df.copy()
    if 'HOUR' not in _dar_df.columns:
        _dar_df['HOUR'] = _dar_df['DELIVERY TIME'].dt.hour if 'DELIVERY TIME' in _dar_df.columns else 12

    _dar_4wks = sorted(_dar_df['Week'].dropna().unique())   # all weeks in range (not just 4)
    _dar_df4  = _dar_df.copy()                               # all filtered data = bonus window
    _dar_date_start = _dar_bonus_start.strftime('%d %b %Y')
    _dar_date_end   = _dar_bonus_end.strftime('%d %b %Y')

    if _dar_df4.empty:
        st.info("No Dar es Salaam data found.")
    else:
        _dar4_stages = compute_delivery_stages(_dar_df4)
        _dar4_stages = add_distance(_dar4_stages)
        _dar4_comp = _dar4_stages[_dar4_stages['STATE'].isin(['Delivery Completed By Driver','Completed'])].copy()

        # Per-order P2C target using distance model
        if 'DISTANCE (km)' in _dar4_comp.columns:
            _dar4_comp = _dar4_comp.copy()
            _dar4_comp['P2C Target'] = (_dar4_comp['DISTANCE (km)'] / STAGE_DRIVING_SPEED_KMH * 60 + STAGE_P2C_OVERHEAD_MIN).round(1)
            _dar4_comp['Total Target'] = (sum(STAGE_TARGETS_FIXED.values()) + _dar4_comp['P2C Target']).round(1)
            # Estimated DT = fixed stages + P2C target (purely distance-based estimate)
            _dar4_comp['Est DT (min)'] = _dar4_comp['Total Target']

        _dar4_all = _dar4_stages.copy()  # all orders including non-completed for acceptance & working days

        # ‚îÄ‚îÄ DRIVER ID mapping ‚îÄ‚îÄ
        _did_map = {}
        if 'DRIVER ID' in _dar4_all.columns:
            _did_map = _dar4_all.dropna(subset=['DRIVER ID']).groupby('DRIVER NAME')['DRIVER ID'].first().to_dict()

        # ‚ïê‚ïê BONUS CONSTANTS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        _acc_bonus_tgt  = 2.0    # Avg acceptance ‚â§ this (min)
        _acc_bonus_amt  = 20000  # Tsh
        _days_bonus_tgt = 23     # Must work > this many days
        _days_bonus_amt = 40000  # Tsh
        _dt_bonus_amt   = 40000  # Tsh - DT < zone average
        _time_bonus_tgt = 26     # Must have > this orders in target hours
        _time_bonus_amt = 20000  # Tsh
        _fee_qual_tgt   = 400000 # Tsh - minimum total delivery fee to qualify
        _max_bonus      = _acc_bonus_amt + _days_bonus_amt + _dt_bonus_amt + _time_bonus_amt  # 120,000

        # ‚îÄ‚îÄ PRE-FILTER: Delivery fee qualification (Tsh 400,000+) ‚îÄ
        if 'DELIVERY FEE' in _dar4_all.columns:
            _fee_grp = (_dar4_all.groupby('DRIVER NAME')['DELIVERY FEE']
                        .sum().reset_index())
            _fee_grp.columns = ['DRIVER NAME','Total Delivery Fee (Tsh)']
            _fee_grp['Fee Qualified'] = _fee_grp['Total Delivery Fee (Tsh)'].apply(
                lambda x: 'Yes' if pd.notna(x) and x >= _fee_qual_tgt else 'No')
        else:
            _fee_grp = pd.DataFrame({'DRIVER NAME': [], 'Total Delivery Fee (Tsh)': [], 'Fee Qualified': []})

        _qualified_drivers = set(_fee_grp[_fee_grp['Fee Qualified'] == 'Yes']['DRIVER NAME'])

        # ‚îÄ‚îÄ 1. Acceptance Time Bonus (Tsh 20,000) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _acc_grp = (_dar4_all.groupby('DRIVER NAME')['Accepted by Driver']
                    .mean().round(1).reset_index())
        _acc_grp.columns = ['DRIVER NAME','Avg Acceptance (min)']
        _acc_grp['Accept Bonus Eligible'] = _acc_grp.apply(
            lambda r: 'Yes' if (r['DRIVER NAME'] in _qualified_drivers
                                and pd.notna(r['Avg Acceptance (min)'])
                                and r['Avg Acceptance (min)'] <= _acc_bonus_tgt) else 'No', axis=1)

        # ‚îÄ‚îÄ 2. Working Days Bonus (Tsh 40,000) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _days_grp = (_dar4_all.groupby('DRIVER NAME')['DELIVERY DATE']
                     .nunique().reset_index())
        _days_grp.columns = ['DRIVER NAME','Days Worked']
        _days_grp['Days Bonus Eligible'] = _days_grp.apply(
            lambda r: 'Yes' if (r['DRIVER NAME'] in _qualified_drivers
                                and r['Days Worked'] > _days_bonus_tgt) else 'No', axis=1)

        # ‚îÄ‚îÄ 3. Delivery Time Bonus (Tsh 40,000) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _dt_grp = _dar4_comp.groupby('DRIVER NAME').agg(
            Avg_DT=('Average Delivery Time','mean'),
            Avg_Dist=('DISTANCE (km)','mean'),
            Est_DT=('Est DT (min)','mean') if 'Est DT (min)' in _dar4_comp.columns else ('Average Delivery Time','mean'),
            Orders=('ID','count'),
        ).round(1).reset_index()
        _dt_grp.columns = ['DRIVER NAME','Avg DT (min)','Avg Dist (km)','Est DT (min)','Orders']
        _dt_grp['Working Zone'] = _dt_grp['DRIVER NAME'].map(_dr_zone)
        _zone_avg_dt = _dar4_comp.groupby('BUSINESS CITY')['Average Delivery Time'].mean().round(1)
        _dt_grp['Zone Avg DT (min)'] = _dt_grp['Working Zone'].map(_zone_avg_dt).round(1)
        _dt_grp['DT Bonus Eligible'] = _dt_grp.apply(
            lambda r: 'Yes' if (r['DRIVER NAME'] in _qualified_drivers
                                and pd.notna(r['Avg DT (min)']) and pd.notna(r['Zone Avg DT (min)'])
                                and r['Avg DT (min)'] < r['Zone Avg DT (min)']) else 'No', axis=1)

        # ‚îÄ‚îÄ 4. Night / Morning Orders Bonus (Tsh 20,000) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _target_hours = [22, 23, 0, 1, 2, 3, 7, 8, 9, 10]
        _time_df = _dar4_all[_dar4_all['HOUR'].isin(_target_hours)].copy()
        _time_grp = _time_df.groupby('DRIVER NAME').size().reset_index(name='Target-Hour Orders')
        _time_grp['Time Bonus Eligible'] = _time_grp.apply(
            lambda r: 'Yes' if (r['DRIVER NAME'] in _qualified_drivers
                                and r['Target-Hour Orders'] > _time_bonus_tgt) else 'No', axis=1)

        # ‚îÄ‚îÄ Merge all into bonus table ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _all_drivers_dar = sorted(
            set(_fee_grp['DRIVER NAME']) |
            set(_acc_grp['DRIVER NAME']) | set(_days_grp['DRIVER NAME']) | set(_dt_grp['DRIVER NAME']))

        _bonus_base = pd.DataFrame({'DRIVER NAME': _all_drivers_dar})
        _bonus_base = _bonus_base.merge(_fee_grp[['DRIVER NAME','Total Delivery Fee (Tsh)','Fee Qualified']],
                                        on='DRIVER NAME', how='left')
        _bonus_base = _bonus_base.merge(_acc_grp[['DRIVER NAME','Avg Acceptance (min)','Accept Bonus Eligible']],
                                        on='DRIVER NAME', how='left')
        _bonus_base = _bonus_base.merge(_days_grp[['DRIVER NAME','Days Worked','Days Bonus Eligible']],
                                        on='DRIVER NAME', how='left')
        _bonus_base = _bonus_base.merge(_dt_grp[['DRIVER NAME','Working Zone','Avg DT (min)','Avg Dist (km)',
                                                  'Est DT (min)','Zone Avg DT (min)','DT Bonus Eligible']],
                                        on='DRIVER NAME', how='left')
        _bonus_base = _bonus_base.merge(_time_grp[['DRIVER NAME','Target-Hour Orders','Time Bonus Eligible']],
                                        on='DRIVER NAME', how='left')

        # Bonus amounts
        _bonus_base['Accept Bonus (Tsh)'] = _bonus_base['Accept Bonus Eligible'].apply(
            lambda x: _acc_bonus_amt if x == 'Yes' else 0)
        _bonus_base['Days Bonus (Tsh)'] = _bonus_base['Days Bonus Eligible'].apply(
            lambda x: _days_bonus_amt if x == 'Yes' else 0)
        _bonus_base['DT Bonus (Tsh)'] = _bonus_base['DT Bonus Eligible'].apply(
            lambda x: _dt_bonus_amt if x == 'Yes' else 0)
        _bonus_base['Time Bonus (Tsh)'] = _bonus_base['Time Bonus Eligible'].apply(
            lambda x: _time_bonus_amt if x == 'Yes' else 0)
        _max_bonus = _acc_bonus_amt + _days_bonus_amt + _dt_bonus_amt + _time_bonus_amt
        _bonus_base['TOTAL BONUS (Tsh)'] = (_bonus_base['Accept Bonus (Tsh)'] + _bonus_base['Days Bonus (Tsh)']
                                            + _bonus_base['DT Bonus (Tsh)'] + _bonus_base['Time Bonus (Tsh)'])

        # Add DRIVER ID and sort
        _bonus_base.insert(0, 'DRIVER ID', _bonus_base['DRIVER NAME'].map(_did_map))
        _bonus_base = _bonus_base.sort_values('DRIVER ID', na_position='last').reset_index(drop=True)

        # Round numerics to 1 decimal
        for _nc in ['Avg Acceptance (min)','Avg DT (min)','Avg Dist (km)','Est DT (min)','Zone Avg DT (min)']:
            if _nc in _bonus_base.columns:
                _bonus_base[_nc] = pd.to_numeric(_bonus_base[_nc], errors='coerce').round(1)

        # ‚îÄ‚îÄ Bonus criteria cards ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        st.markdown("#### üìã Bonus Criteria (Must have Tsh 400,000+ delivery fee to qualify)")
        _bonus_cards = st.columns(5)
        _fee_qual_count = int((_bonus_base.get('Fee Qualified', pd.Series(['No']*len(_bonus_base))) == 'Yes').sum())
        with _bonus_cards[0]:
            st.markdown(f"""<div style="background:#37474f;color:#fff;border-radius:10px;padding:14px 10px;text-align:center;margin-bottom:8px;border:2px solid #ff9800">
            <div style="font-size:0.75rem;opacity:0.85;margin-bottom:4px">üîë ELIGIBILITY GATE</div>
            <div style="font-size:1rem;font-weight:800">Tsh 400,000+</div>
            <div style="font-size:0.7rem;opacity:0.7">Total Delivery Fee<br>{_fee_qual_count} qualified</div></div>""", unsafe_allow_html=True)
        for _bidx, (_bname, _bamt, _btgt, _icon, _col) in enumerate([
            ("Acceptance ‚â§2.0 min", f"Tsh {_acc_bonus_amt:,}", f"Avg accept time ‚â§ 2.0 min", "‚ö°", "#1565c0"),
            ("Days Worked >23", f"Tsh {_days_bonus_amt:,}", f"In 4-week window", "üìÖ", "#2e7d32"),
            ("DT < Zone Average", f"Tsh {_dt_bonus_amt:,}", "Faster than city avg", "üöÄ", "#6a1b9a"),
            ("Target Hours >26 orders", f"Tsh {_time_bonus_amt:,}", "22‚Äì3h & 7‚Äì10h", "üåô", "#c62828"),
        ]):
            with _bonus_cards[_bidx + 1]:
                st.markdown(f"""<div style="background:{_col};color:#fff;border-radius:10px;padding:14px 10px;text-align:center;margin-bottom:8px">
                <div style="font-size:0.75rem;opacity:0.85;margin-bottom:4px">{_icon} {_bname}</div>
                <div style="font-size:1.1rem;font-weight:800">{_bamt}</div>
                <div style="font-size:0.7rem;opacity:0.7">{_btgt}</div></div>""", unsafe_allow_html=True)

        # ‚îÄ‚îÄ Summary KPI metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _max_bonus = _acc_bonus_amt + _days_bonus_amt + _dt_bonus_amt + _time_bonus_amt
        _full_bonus_n  = int((_bonus_base['TOTAL BONUS (Tsh)'] == _max_bonus).sum())
        _partial_n     = int((_bonus_base['TOTAL BONUS (Tsh)'].between(1, _max_bonus-1)).sum())
        _zero_n        = int((_bonus_base['TOTAL BONUS (Tsh)'] == 0).sum())
        _total_payout  = int(_bonus_base['TOTAL BONUS (Tsh)'].sum())
        _acc_elig_n    = int((_bonus_base['Accept Bonus Eligible'] == 'Yes').sum())
        _days_elig_n   = int((_bonus_base['Days Bonus Eligible'] == 'Yes').sum())
        _dt_elig_n     = int((_bonus_base['DT Bonus Eligible'] == 'Yes').sum())
        _time_elig_n   = int((_bonus_base['Time Bonus Eligible'] == 'Yes').sum())

        _krow1 = st.columns(5)
        _krow1[0].metric("üë• Total Riders", len(_bonus_base))
        _krow1[1].metric("üîë Fee Qualified", _fee_qual_count, delta=f"{_fee_qual_count/max(len(_bonus_base),1)*100:.0f}%")
        _krow1[2].metric("üèÜ Full Bonus", _full_bonus_n, delta=f"Tsh {_max_bonus:,} each")
        _krow1[3].metric("ü•à Partial Bonus", _partial_n)
        _krow1[4].metric("üí∞ Total Payout", f"{_total_payout:,.0f}", delta="Tsh")

        # ‚îÄ‚îÄ Visualizations ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        _vcol1, _vcol2 = st.columns(2)

        with _vcol1:
            # Donut: Award distribution
            st.markdown("**üèÜ Bonus Award Distribution**")
            _fig_donut, _ax_donut = plt.subplots(figsize=(5, 4))
            _donut_vals  = [_full_bonus_n, _partial_n, _zero_n]
            _donut_labels= [f'Full ({_full_bonus_n})', f'Partial ({_partial_n})', f'None ({_zero_n})']
            _donut_colors= ['#2e7d32','#f9a825','#ef5350']
            _donut_vals_f = [v for v in _donut_vals if v > 0]
            _donut_labs_f = [l for v,l in zip(_donut_vals, _donut_labels) if v > 0]
            _donut_cols_f = [cl for v,cl in zip(_donut_vals, _donut_colors) if v > 0]
            if sum(_donut_vals_f) > 0:
                _wedges, _texts, _autotexts = _ax_donut.pie(
                    _donut_vals_f, labels=_donut_labs_f, colors=_donut_cols_f,
                    autopct='%1.0f%%', startangle=90, pctdistance=0.7,
                    wedgeprops=dict(width=0.55, edgecolor='white', linewidth=2))
                for _at in _autotexts: _at.set_fontsize(10); _at.set_fontweight('bold')
                _ax_donut.text(0, 0, f"{_total_payout//1000}K\nTsh", ha='center', va='center', fontsize=11, fontweight='bold', color='#1a1a2e')
            _ax_donut.set_title(f"Total Payout: Tsh {_total_payout:,}", fontweight='bold', fontsize=11)
            plt.tight_layout(); st.pyplot(_fig_donut); plt.close()

        with _vcol2:
            # Bar: Eligibility per criteria
            st.markdown("**üìä Eligibility by Criteria**")
            _fig_elig, _ax_elig = plt.subplots(figsize=(5, 4))
            _elig_names = ['Fee Qual','Accept','Days','DT','Peak Hrs']
            _elig_counts= [_fee_qual_count, _acc_elig_n, _days_elig_n, _dt_elig_n, _time_elig_n]
            _elig_colors= ['#ff9800','#1565c0','#2e7d32','#6a1b9a','#c62828']
            _bars_elig = _ax_elig.bar(_elig_names, _elig_counts, color=_elig_colors,
                                      edgecolor='white', linewidth=1.5, width=0.6)
            _ax_elig.bar_label(_bars_elig, fmt='%d', fontweight='bold', fontsize=10)
            _ax_elig.axhline(len(_bonus_base), color='#888', lw=1.2, linestyle='--',
                             label=f'Total riders ({len(_bonus_base)})')
            _ax_elig.set_ylabel("No. of Riders"); _ax_elig.set_ylim(0, max(len(_bonus_base)*1.2, 5))
            _ax_elig.set_title("Riders Eligible per Bonus Category", fontweight='bold', fontsize=11)
            _ax_elig.legend(fontsize=8); _ax_elig.grid(axis='y', alpha=0.2)
            plt.tight_layout(); st.pyplot(_fig_elig); plt.close()

        # Payout by zone
        if 'Working Zone' in _bonus_base.columns:
            st.markdown("**üèôÔ∏è Total Bonus Payout by Zone**")
            _zone_payout = (_bonus_base.groupby('Working Zone')['TOTAL BONUS (Tsh)']
                            .agg(['sum','count']).reset_index())
            _zone_payout.columns = ['Zone','Total Payout','Riders']
            _zone_payout = _zone_payout.sort_values('Total Payout', ascending=True)
            _fig_zone, _ax_zone = plt.subplots(figsize=(10, max(3, len(_zone_payout)*0.5)))
            _bars_z = _ax_zone.barh(_zone_payout['Zone'], _zone_payout['Total Payout'],
                                    color='#1565c0', edgecolor='white', linewidth=1)
            _zp_payout_vals = _zone_payout['Total Payout'].values
            _zp_riders_vals = _zone_payout['Riders'].values
            for _bi, _bar in enumerate(_bars_z):
                _ax_zone.text(_bar.get_width() + _zone_payout['Total Payout'].max() * 0.01,
                              _bar.get_y() + _bar.get_height()/2,
                              f"Tsh {int(_zp_payout_vals[_bi]):,}  ({int(_zp_riders_vals[_bi])} riders)",
                              va='center', fontsize=9, fontweight='bold')
            _ax_zone.set_xlabel("Total Payout (Tsh)")
            _ax_zone.set_title("Bonus Payout by Working Zone", fontweight='bold')
            _ax_zone.grid(axis='x', alpha=0.2); plt.tight_layout()
            st.pyplot(_fig_zone); plt.close()

        # Bonus breakdown waterfall bars (top riders)
        _top_bonus_riders = _bonus_base[_bonus_base['TOTAL BONUS (Tsh)'] > 0].copy()
        if len(_top_bonus_riders) > 0:
            st.markdown(f"**üéØ Top Riders ‚Äî Bonus Breakdown (showing up to 25)**")
            _top_bonus_riders = _top_bonus_riders.sort_values('TOTAL BONUS (Tsh)', ascending=False).head(25)
            _fig_stack, _ax_stack = plt.subplots(figsize=(12, max(4, len(_top_bonus_riders)*0.42)))
            _categories = [('Accept Bonus (Tsh)',  '#1565c0', '‚ö° Accept'),
                           ('Days Bonus (Tsh)',    '#2e7d32', 'üìÖ Days'),
                           ('DT Bonus (Tsh)',      '#6a1b9a', 'üöÄ DT'),
                           ('Time Bonus (Tsh)',    '#c62828', 'üåô Peak')]
            _left = np.zeros(len(_top_bonus_riders))
            for _col_b, _clr, _lbl in _categories:
                if _col_b in _top_bonus_riders.columns:
                    _vals = pd.to_numeric(_top_bonus_riders[_col_b], errors='coerce').fillna(0).values
                    _bars_s = _ax_stack.barh(_top_bonus_riders['DRIVER NAME'], _vals,
                                             left=_left, color=_clr, label=_lbl, height=0.7)
                    for _bsi, (_bar, _v) in enumerate(zip(_bars_s, _vals)):
                        if _v >= 8000:
                            _ax_stack.text(_left[_bsi] + _v/2, _bar.get_y() + _bar.get_height()/2,
                                          f"{int(_v//1000)}K", ha='center', va='center',
                                          fontsize=7, color='white', fontweight='bold')
                    _left += _vals
            _ax_stack.set_xlabel("Bonus Amount (Tsh)")
            _ax_stack.set_title("Individual Bonus Breakdown by Category", fontweight='bold')
            _ax_stack.invert_yaxis()
            _ax_stack.axvline(_max_bonus, color='gold', lw=1.5, linestyle='--', label=f'Max: Tsh {_max_bonus:,}')
            _ax_stack.legend(loc='lower right', fontsize=8, ncol=3)
            _ax_stack.grid(axis='x', alpha=0.2); plt.tight_layout()
            st.pyplot(_fig_stack); plt.close()

        # ‚îÄ‚îÄ Main bonus table with styling ‚îÄ‚îÄ
        st.markdown("**üìã Dar es Salaam Rider Bonus Table (Last 4 Weeks)**")

        def _style_dar_bonus(df_in):
            sty = pd.DataFrame('', index=df_in.index, columns=df_in.columns)
            _elig_cols = {'Fee Qualified':          'Total Delivery Fee (Tsh)',
                          'Accept Bonus Eligible': 'Accept Bonus (Tsh)',
                          'Days Bonus Eligible':   'Days Bonus (Tsh)',
                          'DT Bonus Eligible':     'DT Bonus (Tsh)',
                          'Time Bonus Eligible':   'Time Bonus (Tsh)'}
            for _i, row in df_in.iterrows():
                # Eligibility columns
                for _ec, _bc in _elig_cols.items():
                    if _ec in df_in.columns:
                        val = str(row.get(_ec,''))
                        sty.at[_i,_ec] = ('background-color:#c8e6c9;color:#1b5e20;font-weight:700' if val == 'Yes'
                                          else 'background-color:#ffcdd2;color:#b71c1c;font-weight:600')
                    if _bc in df_in.columns:
                        try:
                            bv = float(row.get(_bc, 0))
                            sty.at[_i,_bc] = ('background-color:#c8e6c9;color:#1b5e20;font-weight:700' if bv > 0
                                              else 'background-color:#f5f5f5;color:#888')
                        except: pass
                # Total bonus
                if 'TOTAL BONUS (Tsh)' in df_in.columns:
                    try:
                        tv = float(row['TOTAL BONUS (Tsh)'])
                        max_bonus = _acc_bonus_amt + _days_bonus_amt + _dt_bonus_amt + _time_bonus_amt
                        sty.at[_i,'TOTAL BONUS (Tsh)'] = (
                            'background-color:#1b5e20;color:#fff;font-weight:800;font-size:1.05em' if tv == max_bonus
                            else 'background-color:#2e7d32;color:#fff;font-weight:700' if tv >= max_bonus * 0.75
                            else 'background-color:#f9a825;color:#212121;font-weight:700' if tv > 0
                            else 'background-color:#f5f5f5;color:#888')
                    except: pass
                # vs target for DT
                if 'Avg DT (min)' in df_in.columns and 'Zone Avg DT (min)' in df_in.columns:
                    try:
                        adt = float(row['Avg DT (min)']); zadt = float(row['Zone Avg DT (min)'])
                        sty.at[_i,'Avg DT (min)'] = ('background-color:#c8e6c9;color:#1b5e20;font-weight:700' if adt < zadt
                                                      else 'background-color:#ffcdd2;color:#b71c1c;font-weight:600')
                    except: pass
            return sty

        st.dataframe(_bonus_base.style.apply(_style_dar_bonus, axis=None),
                     use_container_width=True,
                     height=min(80 + len(_bonus_base) * 38, 600))
        st.caption(f"üü¢ Eligible ¬∑ üî¥ Not eligible  |  Bonus Period: {_dar_date_start} to {_dar_date_end}  ({len(_dar_4wks)} weeks)")

        # ‚îÄ‚îÄ Download ‚îÄ‚îÄ
        st.download_button("‚¨áÔ∏è Download DAR Bonus Report",
                           data=excel_bytes(_bonus_base, "DAR Bonus"),
                           file_name="DAR_Monthly_Bonus.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    # ‚îÄ‚îÄ‚îÄ Section C: Regional Bonus Calculator ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("### üí∞ C. Regional Rider Bonus Calculator")
    st.caption(
        "**Availability:** orders ‚â• zone average √∑ 1.5 (rider gets bonus even if slightly below avg, "
        "e.g. zone with 20 orders / 2 riders ‚Üí threshold = 6.7 ‚Üí both 9 and 11 qualify)  |  "
        "**Delivery Time:** avg DT ‚â§ zone average (not a fixed target)")

    _BONUS = 15000
    _regional_df = raw.copy()
    _regional_df['DELIVERY DATE'] = pd.to_datetime(_regional_df['DELIVERY DATE'], errors='coerce')
    _regional_df['Week'] = _regional_df['DELIVERY DATE'].dt.to_period('W-SUN').apply(lambda r: r.start_time)

    _bonus_comp = compute_delivery_stages(_regional_df)
    _bonus_comp = _bonus_comp[_bonus_comp['STATE'].isin(['Delivery Completed By Driver','Completed'])].copy()

    # Bonus week selector
    _bonus_weeks_avail = sorted(_bonus_comp['Week'].dropna().unique(), reverse=True)
    _bonus_week_opts   = [str(w.date()) for w in _bonus_weeks_avail]
    _sel_bonus_week_str = st.selectbox("Select week for bonus calculation (default = latest)",
                                        _bonus_week_opts, index=0, key="bonus_week_sel")
    _sel_bonus_week = _bonus_weeks_avail[_bonus_week_opts.index(_sel_bonus_week_str)]

    _bonus_reg = _regional_df[
        (_regional_df['Week'] == _sel_bonus_week) &
        (_regional_df['BUSINESS CITY'].isin(REGIONAL_CITIES))
    ].copy()
    _bonus_comp_reg = _bonus_comp[
        (_bonus_comp['Week'] == _sel_bonus_week) &
        (_bonus_comp['BUSINESS CITY'].isin(REGIONAL_CITIES))
    ].copy()

    if _bonus_reg.empty:
        st.info("No regional data for the selected week.")
    else:
        _drivers_reg = pd.Index(sorted(
            set(_bonus_reg['DRIVER NAME'].dropna()) | set(_bonus_comp_reg['DRIVER NAME'].dropna())))

        _tot_ord = _bonus_reg.groupby('DRIVER NAME')['ID'].count().reindex(_drivers_reg, fill_value=0)
        _avg_dt  = _bonus_comp_reg.groupby('DRIVER NAME')['Average Delivery Time'].mean().reindex(_drivers_reg, fill_value=np.nan)
        _wzone   = (_bonus_reg.groupby('DRIVER NAME')['BUSINESS CITY']
                    .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else "Unknown")
                    .reindex(_drivers_reg, fill_value="Unknown"))

        # Zone total orders, riders, average per rider, and min threshold (avg / 1.5)
        _city_ord_total = _bonus_reg.groupby('BUSINESS CITY')['ID'].count()
        _city_drv_count = _bonus_reg.groupby('BUSINESS CITY')['DRIVER NAME'].nunique()
        _zone_avg_orders = (_city_ord_total / _city_drv_count).fillna(0)  # avg orders per rider per zone
        # Availability threshold: zone_avg / 1.5  (riders within 1.5√ó below avg still qualify)
        _zone_avail_thresh = (_zone_avg_orders / 1.5).round(1)

        # Zone average DT (for DT eligibility)
        _zone_avg_dt_reg = _bonus_comp_reg.groupby('BUSINESS CITY')['Average Delivery Time'].mean()

        _bonus_df = pd.DataFrame({
            'Rider Name': _drivers_reg,
            'Working Zone': _wzone.values,
            'Total Orders': _tot_ord.values,
            'Avg Delivery Time (min)': _avg_dt.round(1).values
        })
        _bonus_df['Zone Avg Orders/Rider'] = _bonus_df['Working Zone'].map(_zone_avg_orders).round(1)
        _bonus_df['Avail Threshold (√∑1.5)'] = _bonus_df['Working Zone'].map(_zone_avail_thresh).round(1)
        _bonus_df['Zone Avg DT (min)'] = _bonus_df['Working Zone'].map(_zone_avg_dt_reg).round(1)

        # Availability: rider orders >= zone_avg / 1.5
        _bonus_df['Availability Eligible'] = _bonus_df.apply(
            lambda r: '‚úÖ Yes' if r['Total Orders'] >= r['Avail Threshold (√∑1.5)'] else '‚ùå No', axis=1)
        # DT eligibility: rider avg DT <= zone avg DT
        _bonus_df['DT Eligible'] = _bonus_df.apply(
            lambda r: ('‚úÖ Yes' if pd.notna(r['Avg Delivery Time (min)']) and
                       pd.notna(r['Zone Avg DT (min)']) and
                       r['Avg Delivery Time (min)'] <= r['Zone Avg DT (min)']
                       else '‚ùå No'), axis=1)
        _bonus_df['Availability Bonus'] = _bonus_df['Availability Eligible'].apply(
            lambda x: _BONUS if x == '‚úÖ Yes' else 0)
        _bonus_df['DT Bonus'] = _bonus_df['DT Eligible'].apply(
            lambda x: _BONUS if x == '‚úÖ Yes' else 0)
        _bonus_df['Total Bonus (TZS)'] = _bonus_df['Availability Bonus'] + _bonus_df['DT Bonus']

        # Summary metrics
        _b1, _b2, _b3, _b4 = st.columns(4)
        _b1.metric("üë• Eligible Riders",     f"{len(_bonus_df[_bonus_df['Total Bonus (TZS)']>0])}")
        _b2.metric("üí∞ Total Bonus Payout",  f"{_bonus_df['Total Bonus (TZS)'].sum():,.0f} TZS")
        _b3.metric("‚ö° Avg Orders/Rider",    f"{_bonus_df['Total Orders'].mean():.1f}")
        _b4.metric("‚è± Avg DT (region)",     f"{_avg_dt.mean():.1f} min" if not _avg_dt.isna().all() else "‚Äî")

        st.dataframe(_bonus_df.sort_values('Total Bonus (TZS)', ascending=False),
                     use_container_width=True)

        # Bonus breakdown chart
        _fig_bon, _ax_bon = plt.subplots(figsize=(12,4))
        _top_bon = _bonus_df.sort_values('Total Bonus (TZS)', ascending=False).head(20)
        _bars_b  = _ax_bon.bar(_top_bon['Rider Name'], _top_bon['Total Bonus (TZS)'],
                               color=['#28a745' if v == _BONUS*2 else ('#ffc107' if v == _BONUS else '#dc3545')
                                      for v in _top_bon['Total Bonus (TZS)']])
        _ax_bon.set_ylabel("Bonus (TZS)"); _ax_bon.set_ylim(0, _BONUS * 2.5)
        _ax_bon.set_title(f"Regional Bonus Breakdown ‚Äî Week of {_sel_bonus_week_str}")
        plt.xticks(rotation=45, ha='right', fontsize=8); plt.tight_layout()
        st.pyplot(_fig_bon); plt.close()

        st.download_button("‚¨áÔ∏è Download Bonus Report",
                           data=excel_bytes(_bonus_df, "Bonus"),
                           file_name=f"Regional_Bonus_{_sel_bonus_week_str}.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        # AI insight for bonus
        _bonus_ctx = (f"REGIONAL BONUS REPORT ‚Äî Week {_sel_bonus_week_str}\n"
                      f"Total riders assessed: {len(_bonus_df)}\n"
                      f"Eligible for bonus: {len(_bonus_df[_bonus_df['Total Bonus (TZS)']>0])}\n"
                      f"Total payout: {_bonus_df['Total Bonus (TZS)'].sum():,.0f} TZS\n"
                      f"Avg delivery time: {_avg_dt.mean():.1f} min\n\n"
                      + _bonus_df.sort_values('Total Bonus (TZS)', ascending=False).head(10).to_string(index=False))
        _bonus_prompt = (
            "Senior BI analyst for a Tanzanian food delivery company.\n\n"
            + _bonus_ctx + "\n\n"
            "Provide:\n"
            "1. **Bonus Summary** ‚Äî What % of riders earned full bonus? Partial? None?\n"
            "2. **Performance Patterns** ‚Äî Which zones are performing best?\n"
            "3. **Underperformers** ‚Äî Who needs coaching and on which metric?\n"
            "4. **Trend Alert** ‚Äî Is regional delivery time improving or declining?\n"
            "5. **Actions** ‚Äî 2 specific ops actions for next week.\nUse real numbers."
        )
        def _run_bonus_insight():
            return claude_insight(_bonus_prompt, max_tokens=700), _bonus_ctx
        ai_insight_button("rider_bonus", "Driver Bonus Analysis", _run_bonus_insight)

        # ‚îÄ‚îÄ‚îÄ Section D: Delivery Time Trends pivot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        st.markdown("### üìà D. Driver Delivery Time Trends (8 Weeks Pivot)")
        _trend_pivot = (_kpi_all.pivot_table(index='DRIVER NAME', columns='Week',
                                              values='Avg DT (min)', aggfunc='mean')
                        .round(1).reset_index() if _all_kpis else pd.DataFrame())
        if not _trend_pivot.empty:
            _trend_pivot['Working Zone'] = _trend_pivot['DRIVER NAME'].map(_dr_zone)
            _trend_pivot['Avg DT (overall)'] = (_kpi_all.groupby('DRIVER NAME')['Avg DT (min)']
                                                   .mean().round(1).reindex(_trend_pivot['DRIVER NAME']).values)
            st.dataframe(_trend_pivot.sort_values('Avg DT (overall)'), use_container_width=True)
            st.download_button("‚¨áÔ∏è Download DT Trends Pivot",
                               data=excel_bytes(_trend_pivot, "DT Trends"),
                               file_name="Driver_DT_Trends_8W.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# TAB 4 ‚Äî PRODUCTS & GEO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
with tab4:
    st.markdown('<div class="section-header">üì¶ Product Trends & Geographic Analysis</div>', unsafe_allow_html=True)

    # ‚îÄ‚îÄ 8-week default analysis window ‚îÄ‚îÄ
    _p4_all = compute_delivery_stages(df)
    _p4_latest_date = _p4_all['DELIVERY DATE'].dropna().max()
    _p4_8w_start    = _p4_latest_date - pd.Timedelta(weeks=8)
    # Current/latest week bounds for date picker default
    _p4_cw_monday   = _p4_latest_date - pd.Timedelta(days=_p4_latest_date.weekday())
    _p4_cw_sunday   = _p4_cw_monday + pd.Timedelta(days=6)

    st.markdown(
        f"""<div style="background:#FFF4EC;border-left:3px solid #FF6B00;
            padding:10px 14px;border-radius:6px;margin-bottom:12px;font-size:13px;">
        üìÖ <b>Analysis period:</b> Last 8 weeks 
        ({_p4_8w_start.strftime('%d %b')} ‚Äì {_p4_latest_date.strftime('%d %b %Y')}) &nbsp;|&nbsp;
        Latest week: <b>{_p4_cw_monday.strftime('%d %b')} ‚Äì {_p4_cw_sunday.strftime('%d %b %Y')}</b>
        </div>""", unsafe_allow_html=True)

    # Compute date bounds ‚Äî always available
    _p4_min_date   = _p4_all['DELIVERY DATE'].min().date()
    _p4_max_date   = _p4_latest_date.date()
    _p4_8w_clamped = max(_p4_8w_start.date(), _p4_min_date)

    # Always render date pickers (expander keeps them visible/interactive)
    with st.expander("üóìÔ∏è Customize date range (default = last 8 weeks)", expanded=False):
        _p4fc1, _p4fc2 = st.columns(2)
        _p4_from = _p4fc1.date_input("From", value=_p4_8w_clamped,
                                      min_value=_p4_min_date, max_value=_p4_max_date, key="p4_from")
        _p4_to   = _p4fc2.date_input("To",   value=_p4_max_date,
                                      min_value=_p4_min_date, max_value=_p4_max_date, key="p4_to")
    # Retrieve from session state as fallback in case expander hasn't been opened
    _p4_from = st.session_state.get("p4_from", _p4_8w_clamped)
    _p4_to   = st.session_state.get("p4_to",   _p4_max_date)

    # Apply date filter
    _p4_mask = ((_p4_all['DELIVERY DATE'].dt.date >= _p4_from) &
                (_p4_all['DELIVERY DATE'].dt.date <= _p4_to))
    df4 = _p4_all[_p4_mask].copy()

    if df4.empty:
        st.warning("No data in selected date range.")
        st.stop()

    # ‚îÄ‚îÄ Product aggregation ‚îÄ‚îÄ
    product_totals     = defaultdict(int)
    weekly_prod_totals = defaultdict(lambda: defaultdict(int))
    prod_biz_map       = defaultdict(set)

    # Optional product filter within this tab
    prod_filter = st.multiselect("Filter by Product (optional)",
                                  sorted(set(PRODUCT_MAPPING.values())),
                                  key="prod_tab_filter")

    for _, row in df4.iterrows():
        try:
            wk_period = row['DELIVERY DATE'].to_period('W-SUN').start_time
        except Exception:
            continue
        bname = row.get('BUSINESS NAME', '')
        for pname, qty in extract_products(row.get('PRODUCTS', '')):
            pstd = standardize_product(pname)
            if prod_filter and pstd not in prod_filter:
                continue
            product_totals[pstd]                   += qty
            weekly_prod_totals[wk_period][pstd]    += qty
            prod_biz_map[pstd].add(bname)

    if product_totals:
        total_prod_df = pd.DataFrame(product_totals.items(), columns=['Product','Total Quantity'])
        total_prod_df['Businesses Selling']    = total_prod_df['Product'].apply(lambda x: len(prod_biz_map[x]))
        total_prod_df['Associated Businesses'] = total_prod_df['Product'].apply(
            lambda x: ", ".join(sorted(prod_biz_map[x])))
        total_prod_df = total_prod_df.sort_values('Total Quantity', ascending=False)
    else:
        total_prod_df = pd.DataFrame(columns=['Product','Total Quantity','Businesses Selling','Associated Businesses'])
        st.warning("No product data found. Check that the PRODUCTS column has data in format '1 x Item Name'.")

    # ‚îÄ‚îÄ Business performance ‚îÄ‚îÄ
    biz_perf = (df4.groupby('BUSINESS NAME')
                .agg(Total_Orders=('ID','count'), Total_Sales=('SUBTOTAL','sum'),
                     Avg_DT=('Average Delivery Time','mean'))
                .reset_index()
                .sort_values('Total_Orders', ascending=False)
                .head(10)
                .rename(columns={'Avg_DT':'Avg Delivery (min)'}))
    biz_perf['Avg Delivery (min)'] = biz_perf['Avg Delivery (min)'].round(1)

    # ‚îÄ‚îÄ Two column layout ‚îÄ‚îÄ
    pc1, pc2 = st.columns(2)

    with pc1:
        st.subheader("üèÜ Top 10 Businesses")
        st.dataframe(biz_perf, use_container_width=True)
        fig_biz, ax_biz = plt.subplots(figsize=(7, 4))
        ax_biz.barh(biz_perf['BUSINESS NAME'], biz_perf['Total_Orders'], color='#FF6B00')
        ax_biz.set_xlabel("Orders"); ax_biz.invert_yaxis()
        ax_biz.set_title("Top 10 by Orders"); plt.tight_layout()
        st.pyplot(fig_biz); plt.close()

    with pc2:
        st.subheader("üì¶ Top 15 Products")
        st.dataframe(total_prod_df.head(15)[['Product','Total Quantity','Businesses Selling']],
                     use_container_width=True)
        top15 = total_prod_df.head(15)
        fig_prod, ax_prod = plt.subplots(figsize=(7, 4))
        ax_prod.barh(top15['Product'], top15['Total Quantity'], color='#2ca02c')
        ax_prod.set_xlabel("Quantity"); ax_prod.invert_yaxis()
        ax_prod.set_title("Top 15 Products"); plt.tight_layout()
        st.pyplot(fig_prod); plt.close()

    # Downloads
    dc1, dc2 = st.columns(2)
    dc1.download_button("‚¨áÔ∏è Download Business Report",
                        data=excel_bytes(biz_perf, "Top Businesses"),
                        file_name="Top_Businesses.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    dc2.download_button("‚¨áÔ∏è Download Product Trend",
                        data=excel_bytes(total_prod_df, "Products"),
                        file_name="Total_Product_Trend.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    st.divider()

    # ‚îÄ‚îÄ Weekly Product Movement ‚îÄ‚îÄ
    st.subheader("üìÜ Weekly Product Movement")
    wp_rows = [[w, p, q] for w, prods in weekly_prod_totals.items()
                          for p, q in prods.items()]
    wp_df = pd.DataFrame(wp_rows, columns=['Week','Product','Quantity'])
    if not wp_df.empty:
        # Pivot: products √ó weeks for top 10
        top_prods = total_prod_df.head(10)['Product'].tolist()
        wp_pivot = (wp_df[wp_df['Product'].isin(top_prods)]
                    .pivot_table(index='Product', columns='Week',
                                 values='Quantity', aggfunc='sum', fill_value=0))
        st.dataframe(wp_pivot, use_container_width=True)

        # Line chart ‚Äî top 8
        fig_wp, ax_wp = plt.subplots(figsize=(13, 5))
        for prod in top_prods[:8]:
            prod_data = wp_df[wp_df['Product']==prod].sort_values('Week')
            if prod_data.empty: continue
            ax_wp.plot([str(w.date()) for w in prod_data['Week']],
                       prod_data['Quantity'], marker='o', label=prod)
        ax_wp.set_xlabel("Week"); ax_wp.set_ylabel("Quantity Sold")
        ax_wp.set_title("Weekly Product Trend ‚Äî Top 8 Products")
        ax_wp.legend(fontsize=8, ncol=2); ax_wp.grid(True, alpha=0.3)
        plt.xticks(rotation=45, ha='right'); plt.tight_layout()
        st.pyplot(fig_wp); plt.close()

    # AI
    ai_insight_button("products", "Product Trends", build_product_insight, total_prod_df, biz_perf, wp_df)

    st.divider()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # GEO INTELLIGENCE ‚Äî Two-panel layout
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    st.divider()
    st.markdown('''<div class="section-header">üó∫Ô∏è Geographic Intelligence ‚Äî Area & Service Analysis</div>''',
                unsafe_allow_html=True)

    _req_geo = ['CUSTOMER LATITUDE','CUSTOMER LONGITUDE','BUSINESS LATITUDE','BUSINESS LONGITUDE']
    if not all(c in df4.columns for c in _req_geo):
        st.info("Geo columns not found in dataset.")
    else:
        _geo4 = df4.dropna(subset=_req_geo).copy()
        if _geo4.empty:
            st.info("No valid geo data for current filter.")
        else:
            # ‚îÄ‚îÄ Compute per-customer delivery metrics ‚îÄ‚îÄ
            _geo4['DT'] = _geo4['Average Delivery Time'].fillna(0)
            _geo4['DistKm'] = _geo4.apply(
                lambda r: haversine(r['BUSINESS LATITUDE'], r['BUSINESS LONGITUDE'],
                                    r['CUSTOMER LATITUDE'], r['CUSTOMER LONGITUDE']), axis=1)

            _center = ([_geo4['CUSTOMER LATITUDE'].mean(), _geo4['CUSTOMER LONGITUDE'].mean()]
                       if city_sel else [-6.8018, 39.2801])

            _rp4 = (_geo4.groupby(['BUSINESS NAME','BUSINESS LATITUDE','BUSINESS LONGITUDE'])
                    .agg(Orders=('ID','count'), Sales=('SUBTOTAL','sum'),
                         AvgDT=('Average Delivery Time','mean'),
                         AvgDist=('DistKm','mean'))
                    .reset_index().sort_values('Orders', ascending=False))

            # ‚îÄ‚îÄ PANEL 1: Density + Polygon Area Analysis ‚îÄ‚îÄ
            st.markdown("### üìç Panel 1 ‚Äî Density Map & Area Analysis")
            st.markdown(
                '''<div style="background:#FFF4EC;border-left:3px solid #FF6B00;padding:8px 14px;
                border-radius:6px;font-size:13px;margin-bottom:10px;">
                üîµ <b>Blue heatmap</b> = Customer density &nbsp;|&nbsp;
                üî¥ <b>Red circles</b> = Restaurants &nbsp;|&nbsp;
                ‚úèÔ∏è <b>Draw a polygon</b> (left toolbar) to analyze any area in detail
                </div>''', unsafe_allow_html=True)

            _p1c1, _p1c2 = st.columns([3,1])
            with _p1c2:
                _map4_type = st.radio("Show layer",
                    ["Both","Customers","Businesses"], key="geo4_type2", label_visibility="collapsed")
                _top_n4    = st.slider("Top restaurants", 5, 50, 20, key="geo4_top2")
                st.caption("üñ±Ô∏è Click any restaurant pin for details")

            with _p1c1:
                _m4 = folium.Map(location=_center, zoom_start=13, tiles="CartoDB positron")

                # Customer heatmap ‚Äî folium default palette (matches Delivery Times tab)
                if _map4_type != "Businesses":
                    _cust_coords = _geo4[['CUSTOMER LATITUDE','CUSTOMER LONGITUDE']].values.tolist()
                    HeatMap(_cust_coords, radius=12, blur=10).add_to(_m4)

                # Restaurant circle markers
                if _map4_type != "Customers":
                    for _, _r in _rp4.head(_top_n4).iterrows():
                        _sz = max(6, min(18, int(_r['Orders'] / max(_rp4['Orders'].max(),1) * 18)))
                        folium.CircleMarker(
                            [_r['BUSINESS LATITUDE'], _r['BUSINESS LONGITUDE']],
                            radius=_sz, color='#e74c3c', fill=True, fill_opacity=0.85,
                            popup=folium.Popup(
                                f"<b>üçΩÔ∏è {_r['BUSINESS NAME']}</b><br>"
                                f"üì¶ <b>{int(_r['Orders']):,}</b> orders<br>"
                                f"üí∞ {int(_r['Sales']):,} TZS<br>"
                                f"‚è±Ô∏è Avg: {_r['AvgDT']:.1f} min &nbsp;|&nbsp; üìè {_r['AvgDist']:.1f} km",
                                max_width=240),
                            tooltip=f"üçΩÔ∏è {_r['BUSINESS NAME']} ({int(_r['Orders']):,} orders)"
                        ).add_to(_m4)

                # Polygon draw tool
                Draw(draw_options={"polyline":False,"polygon":True,"circle":False,
                                   "rectangle":True,"marker":False,"circlemarker":False},
                     edit_options={"edit":True,"remove":True}).add_to(_m4)
                folium.LayerControl().add_to(_m4)
                _map4_data = st_folium(_m4, height=500, key="geo4_map_v2", use_container_width=True)

            # ‚îÄ‚îÄ Polygon analysis ‚îÄ‚îÄ
            if _map4_data and _map4_data.get("all_drawings"):
                _coords = _map4_data["all_drawings"][-1]["geometry"]["coordinates"][0]
                _poly   = Polygon([(c[1], c[0]) for c in _coords])
                _geo4["_in_poly"] = _geo4.apply(
                    lambda r: _poly.contains(Point(r["CUSTOMER LATITUDE"], r["CUSTOMER LONGITUDE"])), axis=1)
                _area_df = _geo4[_geo4["_in_poly"]].copy()

                if not _area_df.empty:
                    st.markdown("---")
                    st.markdown(f"### üìä Selected Area Analysis ‚Äî **{len(_area_df):,} orders**")

                    _ac1, _ac2, _ac3, _ac4, _ac5 = st.columns(5)
                    _ac1.metric("üì¶ Orders", f"{len(_area_df):,}")
                    _ac2.metric("üí∞ Sales", f"{_area_df['SUBTOTAL'].sum()/1e6:.2f}M TZS")
                    _ac3.metric("‚è±Ô∏è Avg Delivery", f"{_area_df['DT'].mean():.1f} min")
                    _ac4.metric("üìè Avg Distance", f"{_area_df['DistKm'].mean():.1f} km")
                    _ac5.metric("üë§ Unique Customers", f"{_area_df['CUSTOMER NAME'].nunique():,}")

                    _ab_c1, _ab_c2 = st.columns(2)
                    with _ab_c1:
                        st.markdown("##### üçΩÔ∏è Top Businesses in Area")
                        _area_biz = (_area_df.groupby("BUSINESS NAME")
                                     .agg(Orders=("ID","count"), Sales=("SUBTOTAL","sum"),
                                          AvgDT=("DT","mean"), AvgDist=("DistKm","mean"))
                                     .reset_index().sort_values("Orders", ascending=False))
                        _area_biz["Sales"] = _area_biz["Sales"].apply(lambda x: f"{int(x):,}")
                        _area_biz["AvgDT"] = _area_biz["AvgDT"].round(1)
                        _area_biz["AvgDist"] = _area_biz["AvgDist"].round(2)
                        st.dataframe(_area_biz.head(10), use_container_width=True)

                    with _ab_c2:
                        st.markdown("##### üë• Top Customers in Area")
                        _area_cust = (_area_df.groupby("CUSTOMER NAME")
                                      .agg(Orders=("ID","count"), Spend=("SUBTOTAL","sum"),
                                           AvgDT=("DT","mean"))
                                      .reset_index().sort_values("Spend", ascending=False))
                        _area_cust["Spend"] = _area_cust["Spend"].apply(lambda x: f"{int(x):,} TZS")
                        st.dataframe(_area_cust.head(10), use_container_width=True)

                    st.download_button("‚¨áÔ∏è Download Area Orders (CSV)",
                                       data=_area_df.drop(columns=["_in_poly","_in_cluster"], errors="ignore").to_csv(index=False).encode(),
                                       file_name="selected_area_orders.csv", mime="text/csv",
                                       key="dl_area_orders")

                    # Auto AI insight for polygon selection
                    _area_ctx = (
                        f"AREA SELECTED: {len(_area_df):,} orders | "
                        f"{_area_df['SUBTOTAL'].sum()/1e6:.2f}M TZS sales | "
                        f"Avg delivery {_area_df['DT'].mean():.1f} min | "
                        f"Avg distance {_area_df['DistKm'].mean():.1f} km | "
                        f"{_area_df['CUSTOMER NAME'].nunique()} unique customers\n\n"
                        f"Top businesses:\n{_area_biz.head(8).to_string(index=False)}"
                    )
                    _area_prompt = (
                        "You are a senior operations analyst for a Tanzanian food delivery company.\n"
                        + _area_ctx + "\n\n"
                        "Analyze this specific geographic area:\n"
                        "1. **Zone Health** ‚Äî Is this area well-served or underserved given the delivery times?\n"
                        "2. **Service Quality** ‚Äî Is avg delivery time and distance acceptable? Any bottlenecks?\n"
                        "3. **Business Mix** ‚Äî Which businesses drive the area? Any gaps or opportunities?\n"
                        "4. **Customer Value** ‚Äî What is the revenue concentration in this zone?\n"
                        "5. **Action** ‚Äî One specific operational recommendation for this zone.\n"
                        "Use real numbers. Be direct and specific."
                    )
                    with st.spinner("ü§ñ Analyzing selected area‚Ä¶"):
                        _area_ins = claude_insight(_area_prompt, 600)
                    ai_block("geo_area_v2", _area_ctx, _area_ins)
                else:
                    st.warning("‚ö†Ô∏è No orders found inside the drawn area. Try a larger polygon.")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # PANEL 2 ‚Äî Service Quality Cluster Map
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            st.divider()
            st.markdown("### üî¥ Panel 2 ‚Äî Service Quality Intelligence: Hard-to-Serve Areas")
            st.markdown('''
            <div style="background:#fff3cd;border-left:3px solid #f39c12;padding:10px 16px;
                        border-radius:6px;font-size:13px;margin-bottom:12px;">
            <b>How to read this map:</b> Circles = customer zones clustered by proximity (1 km radius).
            Color shows <b>average delivery time</b> ‚Äî üî¥ Red = struggling zones (slow delivery),
            üü¢ Green = well-served. Circle size = order volume.
            <b>Click any circle</b> for detailed zone analysis.
            </div>''', unsafe_allow_html=True)

            # Control row
            _sq_c1, _sq_c2, _sq_c3 = st.columns([2,2,2])
            with _sq_c1:
                _dt_thresh = st.slider("üî¥ Flag zones slower than (min)", 20, 90, 45, key="geo_dt_thresh",
                                       help="Delivery time threshold ‚Äî zones above this are flagged red")
            with _sq_c2:
                _min_orders = st.slider("Min orders to show zone", 1, 20, 3, key="geo_min_orders",
                                        help="Filter out low-activity zones")
            with _sq_c3:
                _cluster_km = st.select_slider("Cluster radius", options=[0.5,1.0,1.5,2.0,3.0],
                                               value=1.0, key="geo_cluster_km",
                                               help="Group customers within this radius into one zone")

            # ‚îÄ‚îÄ Cluster customers by grid approximation (fast, no sklearn needed) ‚îÄ‚îÄ
            # Round lat/lon to cluster_km degree equivalent
            _deg_per_km = 1.0 / 111.0
            _grid_size  = _cluster_km * _deg_per_km
            _geo4["_lat_g"] = (_geo4["CUSTOMER LATITUDE"]  / _grid_size).round(0) * _grid_size
            _geo4["_lon_g"] = (_geo4["CUSTOMER LONGITUDE"] / _grid_size).round(0) * _grid_size

            _clusters = (_geo4.groupby(["_lat_g","_lon_g"])
                         .agg(Orders=('ID','count'),
                              Sales=('SUBTOTAL','sum'),
                              AvgDT=('DT','mean'),
                              AvgDist=('DistKm','mean'),
                              Unique_Cust=('CUSTOMER NAME','nunique'),
                              AvgOrder=('SUBTOTAL','mean'),
                              Lat=('CUSTOMER LATITUDE','mean'),
                              Lon=('CUSTOMER LONGITUDE','mean'))
                         .reset_index()
                         .rename(columns={"_lat_g":"GridLat","_lon_g":"GridLon"}))

            _clusters = _clusters[_clusters["Orders"] >= _min_orders].copy()
            _clusters["ServiceScore"] = _clusters["AvgDT"]  # higher = worse

            # Color by delivery time vs threshold
            def _zone_color(avg_dt):
                if avg_dt >= _dt_thresh:           return "#e74c3c"   # üî¥ struggling
                elif avg_dt >= _dt_thresh * 0.75:  return "#f39c12"   # üü† moderate
                elif avg_dt >= _dt_thresh * 0.55:  return "#f1c40f"   # üü° ok
                else:                               return "#27ae60"   # üü¢ good

            # ‚îÄ‚îÄ Build service quality map ‚îÄ‚îÄ
            _m5 = folium.Map(location=_center, zoom_start=13, tiles="CartoDB positron")

            # Add restaurant markers (smaller, grey)
            for _, _r in _rp4.head(30).iterrows():
                folium.CircleMarker(
                    [_r['BUSINESS LATITUDE'], _r['BUSINESS LONGITUDE']],
                    radius=6, color='#636e72', fill=True, fill_opacity=0.7,
                    tooltip=f"üçΩÔ∏è {_r['BUSINESS NAME']}",
                    popup=folium.Popup(
                        f"<b>{_r['BUSINESS NAME']}</b><br>"
                        f"Avg delivery: {_r['AvgDT']:.1f} min | {_r['AvgDist']:.1f} km avg",
                        max_width=200)
                ).add_to(_m5)

            # Add customer zone circles
            _max_orders = max(_clusters["Orders"].max(), 1)
            for _, _cl in _clusters.iterrows():
                _col   = _zone_color(_cl["AvgDT"])
                _rad   = max(8, min(30, int(_cl["Orders"] / _max_orders * 30)))
                _border = "#c0392b" if _cl["AvgDT"] >= _dt_thresh else "#2c3e50"

                # Build rich popup HTML
                _dt_flag = "üî¥ SLOW" if _cl["AvgDT"] >= _dt_thresh else ("üü†" if _cl["AvgDT"] >= _dt_thresh*0.75 else "üü¢ Good")
                _popup_html = (
                    f"<div style='min-width:220px;font-size:13px;'>"
                    f"<b style='font-size:14px;'>üìç Customer Zone</b><br>"
                    f"<hr style='margin:4px 0;'>"
                    f"üì¶ <b>{int(_cl['Orders']):,}</b> orders &nbsp;|&nbsp; "
                    f"üë§ {int(_cl['Unique_Cust']):,} customers<br>"
                    f"üí∞ Avg order: <b>{int(_cl['AvgOrder']):,} TZS</b><br>"
                    f"‚è±Ô∏è Avg delivery: <b>{_cl['AvgDT']:.1f} min</b> {_dt_flag}<br>"
                    f"üìè Avg distance: <b>{_cl['AvgDist']:.1f} km</b><br>"
                    f"üíµ Zone revenue: <b>{int(_cl['Sales']):,} TZS</b>"
                    f"</div>"
                )

                folium.CircleMarker(
                    [_cl["Lat"], _cl["Lon"]],
                    radius=_rad,
                    color=_border, fill=True,
                    fill_color=_col, fill_opacity=0.65,
                    popup=folium.Popup(_popup_html, max_width=280),
                    tooltip=(f"‚è±Ô∏è {_cl['AvgDT']:.0f} min | üì¶ {int(_cl['Orders']):,} orders")
                ).add_to(_m5)

            # Legend
            folium.Marker(
                location=[_center[0] - 0.02, _center[1] + 0.04],
                icon=folium.DivIcon(html=f"""
                <div style='background:white;border:1px solid #ccc;border-radius:6px;
                             padding:8px 12px;font-size:12px;box-shadow:2px 2px 6px rgba(0,0,0,0.15);
                             white-space:nowrap;'>
                  <b>Service Level</b><br>
                  <span style='color:#27ae60;'>‚óè</span> Good (&lt;{int(_dt_thresh*0.55)}min)<br>
                  <span style='color:#f1c40f;'>‚óè</span> OK ({int(_dt_thresh*0.55)}‚Äì{int(_dt_thresh*0.75)}min)<br>
                  <span style='color:#f39c12;'>‚óè</span> Moderate ({int(_dt_thresh*0.75)}‚Äì{_dt_thresh}min)<br>
                  <span style='color:#e74c3c;'>‚óè</span> Slow (&gt;{_dt_thresh}min)<br>
                  <span style='color:#636e72;'>‚óè</span> Restaurant
                </div>""", icon_size=(0,0), icon_anchor=(0,0))
            ).add_to(_m5)

            st.components.v1.html(_m5._repr_html_(), height=520)

            # ‚îÄ‚îÄ Struggling zones table + comparison ‚îÄ‚îÄ
            _struggling = _clusters[_clusters["AvgDT"] >= _dt_thresh].sort_values("AvgDT", ascending=False)
            _good_zones = _clusters[_clusters["AvgDT"] < _dt_thresh * 0.55].sort_values("Orders", ascending=False)

            _sq_t1, _sq_t2 = st.columns(2)
            with _sq_t1:
                st.markdown(f"#### üî¥ Struggling Zones (>{_dt_thresh} min avg delivery)")
                if not _struggling.empty:
                    _str_disp = _struggling[['Lat','Lon','Orders','AvgDT','AvgDist','AvgOrder','Sales']].copy()
                    _str_disp['Lat'] = _str_disp['Lat'].round(4)
                    _str_disp['Lon'] = _str_disp['Lon'].round(4)
                    _str_disp['AvgDT'] = _str_disp['AvgDT'].round(1)
                    _str_disp['AvgDist'] = _str_disp['AvgDist'].round(2)
                    _str_disp['AvgOrder'] = _str_disp['AvgOrder'].apply(lambda x: f"{int(x):,}")
                    _str_disp['Sales'] = _str_disp['Sales'].apply(lambda x: f"{int(x):,}")
                    _str_disp.index = range(1, len(_str_disp)+1)
                    st.dataframe(_str_disp, use_container_width=True)
                else:
                    st.success(f"‚úÖ No zones with avg delivery > {_dt_thresh} min!")

            with _sq_t2:
                st.markdown("#### üü¢ Best-Served Zones (fastest delivery)")
                if not _good_zones.empty:
                    _good_disp = _good_zones[['Lat','Lon','Orders','AvgDT','AvgDist','AvgOrder','Sales']].copy()
                    _good_disp['Lat'] = _good_disp['Lat'].round(4)
                    _good_disp['Lon'] = _good_disp['Lon'].round(4)
                    _good_disp['AvgDT'] = _good_disp['AvgDT'].round(1)
                    _good_disp['AvgDist'] = _good_disp['AvgDist'].round(2)
                    _good_disp['AvgOrder'] = _good_disp['AvgOrder'].apply(lambda x: f"{int(x):,}")
                    _good_disp['Sales'] = _good_disp['Sales'].apply(lambda x: f"{int(x):,}")
                    _good_disp.index = range(1, len(_good_disp)+1)
                    st.dataframe(_good_disp, use_container_width=True)
                else:
                    st.info("Adjust threshold to see well-served zones.")

            # ‚îÄ‚îÄ Download cluster data ‚îÄ‚îÄ
            _sq_d1, _sq_d2 = st.columns(2)
            _sq_d1.download_button("‚¨áÔ∏è All Zones (Excel)",
                data=excel_bytes(_clusters.drop(columns=["GridLat","GridLon","_lat_g","_lon_g"], errors="ignore")
                                 .rename(columns={"Lat":"Center Lat","Lon":"Center Lon"})
                                 .sort_values("AvgDT", ascending=False), "All Zones"),
                file_name="Service_Quality_Zones.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="dl_zones")
            _sq_d2.download_button("‚¨áÔ∏è Struggling Zones (Excel)",
                data=excel_bytes(_struggling.rename(columns={"Lat":"Center Lat","Lon":"Center Lon"}), "Struggling"),
                file_name="Struggling_Zones.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="dl_struggling")

            # ‚îÄ‚îÄ AI Insight for service quality ‚îÄ‚îÄ
            if not _struggling.empty:
                _sq_ctx = (
                    f"GEOGRAPHIC SERVICE QUALITY ANALYSIS\n"
                    f"Total zones: {len(_clusters)} | Struggling zones (>{_dt_thresh}min): {len(_struggling)}\n"
                    f"Overall avg delivery: {_clusters['AvgDT'].mean():.1f} min | "
                    f"Worst zone: {_struggling['AvgDT'].max():.1f} min avg\n"
                    f"Avg distance struggling zones: {_struggling['AvgDist'].mean():.1f} km\n\n"
                    f"TOP STRUGGLING ZONES:\n{_struggling.head(8)[['Lat','Lon','Orders','AvgDT','AvgDist','Sales']].round(2).to_string(index=False)}\n\n"
                    f"BEST ZONES:\n{_good_zones.head(5)[['Lat','Lon','Orders','AvgDT','AvgDist']].round(2).to_string(index=False)}"
                )
                _sq_prompt = (
                    "You are a senior logistics analyst for Piki, a Tanzanian food delivery company.\n\n"
                    + _sq_ctx + "\n\n"
                    "Provide a geographic service quality analysis:\n"
                    "1. **Coverage Gaps** ‚Äî Which areas are consistently underserved? What patterns do you see?\n"
                    "2. **Distance vs Time** ‚Äî Is poor service caused by distance or operational issues?\n"
                    "3. **Revenue at Risk** ‚Äî How much revenue is at risk in struggling zones due to poor service?\n"
                    "4. **Quick Wins** ‚Äî Which 2-3 struggling zones should be prioritized first and why?\n"
                    "5. **Recommendations** ‚Äî Specific actions: add restaurant, deploy riders, set delivery boundaries?\n"
                    "Use real numbers. Be operational and specific."
                )
                ai_insight_button("geo_service_quality", "Service Quality Analysis", lambda: (claude_insight(_sq_prompt, 700), _sq_ctx))

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# TAB 5 ‚Äî PIKI PARTY STORE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
with tab5:
    st.markdown("""
    <div style="background:linear-gradient(135deg,#ff6b6b,#ffd93d,#6bcb77,#4d96ff);
                padding:20px 24px; border-radius:14px; margin-bottom:20px;">
        <h2 style="color:white;margin:0;text-shadow:1px 1px 3px rgba(0,0,0,0.4);">
            üéâ Piki Party Store ‚Äî Intelligence Dashboard
        </h2>
        <p style="color:rgba(255,255,255,0.92);margin:6px 0 0 0;font-size:15px;">
            Product trends ¬∑ Category analysis ¬∑ Customer insights
        </p>
    </div>
    """, unsafe_allow_html=True)

    # ‚îÄ‚îÄ Filter to Piki Party only ‚îÄ‚îÄ
    _pp_df = raw.copy()
    _pp_df['DELIVERY DATE'] = pd.to_datetime(_pp_df['DELIVERY DATE'], errors='coerce')
    _pp_df['DELIVERY TIME'] = pd.to_datetime(_pp_df['DELIVERY TIME'], errors='coerce')
    _pp_df['HOUR'] = _pp_df['DELIVERY TIME'].dt.hour
    _pp_df = _pp_df[_pp_df['HOUR'].isin(OPERATING_HOURS)]

    _pp_df = _pp_df[_pp_df['BUSINESS NAME'].str.strip().str.lower() == 'piki party'].copy()

    if _pp_df.empty:
        st.warning("No 'Piki Party' orders found in the uploaded data. Check that BUSINESS NAME contains 'Piki Party'.")
        st.stop()

    _iso = _pp_df['DELIVERY DATE'].dt.isocalendar()
    _pp_df['ISO_Year'] = _iso.year
    _pp_df['ISO_Week'] = _iso.week

    # ‚îÄ‚îÄ Load category master ‚îÄ‚îÄ
    _cat_loaded = False
    _product_category_map = {}
    try:
        _cdf = pd.read_csv("Products Category.csv", encoding='utf-8')
    except Exception:
        try:
            _cdf = pd.read_csv("Products Category.csv", encoding='latin1')
        except Exception:
            _cdf = pd.DataFrame(columns=['Product','Category'])
            st.info("Products Category.csv not found ‚Äî categories will show as UNCATEGORIZED.")

    if not _cdf.empty:
        _cdf['Product']  = _cdf['Product'].str.strip().str.lower()
        _cdf['Category'] = _cdf['Category'].str.strip()
        _product_category_map = dict(zip(_cdf['Product'], _cdf['Category']))
        _cat_loaded = True

    # ‚îÄ‚îÄ KPI Summary ‚îÄ‚îÄ
    _pp_comp = _pp_df[_pp_df['STATE'].isin(['Completed','Delivery Completed By Driver'])]
    _pp_fail = _pp_df[_pp_df['STATE'] == 'Delivery Failed By Driver']
    _pp_rej  = _pp_df[_pp_df['STATE'].str.contains('Reject', na=False)]

    _pk1,_pk2,_pk3,_pk4,_pk5 = st.columns(5)
    _pk1.metric("üì¶ Total Orders",    f"{len(_pp_df):,}")
    _pk2.metric("‚úÖ Completed",        f"{len(_pp_comp):,}")
    _pk3.metric("‚ùå Failed",           f"{len(_pp_fail)}")
    _pk4.metric("üö´ Rejected",         f"{len(_pp_rej)}")
    _pk5.metric("üí∞ Total Sales",      f"{_pp_comp['SUBTOTAL'].sum()/1e6:.2f}M TZS")

    # ‚îÄ‚îÄ Filters row ‚îÄ‚îÄ
    st.markdown("---")
    st.markdown("#### üîé Filters")
    _pf1,_pf2,_pf3,_pf4 = st.columns(4)

    with _pf1:
        _pp_states = sorted(_pp_df['STATE'].dropna().unique())
        _state_sel = st.multiselect("Order Status", _pp_states, default=_pp_states, key="pp_state")

    with _pf2:
        _all_cats = sorted(set(_product_category_map.values())) if _product_category_map else []
        _cat_sel  = st.multiselect("Category", _all_cats, key="pp_cat")

    with _pf3:
        _pp_min_d = _pp_df['DELIVERY DATE'].min().date()
        _pp_max_d = _pp_df['DELIVERY DATE'].max().date()
        _pp_date_range = st.date_input("Date Range",
            value=[_pp_min_d, _pp_max_d],
            min_value=_pp_min_d, max_value=_pp_max_d,
            key="pp_dates")

    with _pf4:
        _pp_hour_opt = st.selectbox("Time Period",
            ["All Day","Morning (7-11)","Afternoon (12-16)","Evening (17-22)","Late Night (23-2)"],
            key="pp_hour")

    # Apply filters
    if _state_sel:
        _pp_df = _pp_df[_pp_df['STATE'].isin(_state_sel)]
    if len(_pp_date_range) == 2:
        _pp_df = _pp_df[
            (_pp_df['DELIVERY DATE'] >= pd.to_datetime(_pp_date_range[0])) &
            (_pp_df['DELIVERY DATE'] <= pd.to_datetime(_pp_date_range[1]))]
    if _pp_hour_opt == "Morning (7-11)":
        _pp_df = _pp_df[_pp_df['HOUR'].between(7,11)]
    elif _pp_hour_opt == "Afternoon (12-16)":
        _pp_df = _pp_df[_pp_df['HOUR'].between(12,16)]
    elif _pp_hour_opt == "Evening (17-22)":
        _pp_df = _pp_df[_pp_df['HOUR'].between(17,22)]
    elif _pp_hour_opt == "Late Night (23-2)":
        _pp_df = _pp_df[(_pp_df['HOUR']>=23)|(_pp_df['HOUR']<=2)]

    _pp_comp = _pp_df[_pp_df['STATE'].isin(['Completed','Delivery Completed By Driver'])]

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # WEEKLY ORDERS & SALES TREND
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    st.markdown('<div class="section-header">üìà Weekly Orders & Sales Trend</div>', unsafe_allow_html=True)

    _pp_weekly = (_pp_comp.groupby(['ISO_Year','ISO_Week'])
                  .agg(Total_Orders=('ID','count'), Total_Sales=('SUBTOTAL','sum'))
                  .reset_index()
                  .sort_values(['ISO_Year','ISO_Week']))
    _pp_weekly['Week_Label'] = (_pp_weekly['ISO_Year'].astype(str) + "-W"
                                + _pp_weekly['ISO_Week'].astype(str).str.zfill(2))

    if not _pp_weekly.empty:
        _fw, _ax1p = plt.subplots(figsize=(12,5))
        _ax1p.plot(_pp_weekly['Week_Label'], _pp_weekly['Total_Orders'],
                   marker='o', color='#4d96ff', lw=2, label='Orders')
        _ax1p.set_ylabel("Orders", color='#4d96ff'); _ax1p.grid(True, alpha=0.3)
        _ax2p = _ax1p.twinx()
        _ax2p.bar(_pp_weekly['Week_Label'], _pp_weekly['Total_Sales'],
                  alpha=0.3, color='#6bcb77', label='Sales')
        _ax2p.yaxis.set_major_formatter(fmt_millions); _ax2p.set_ylabel("Sales (TZS)")
        _l1,_lb1 = _ax1p.get_legend_handles_labels()
        _l2,_lb2 = _ax2p.get_legend_handles_labels()
        _ax1p.legend(_l1+_l2, _lb1+_lb2, loc='upper left')
        plt.title("Piki Party ‚Äî Weekly Orders & Sales"); plt.xticks(rotation=35, ha='right')
        plt.tight_layout(); st.pyplot(_fw); plt.close()
        st.dataframe(_pp_weekly[['Week_Label','Total_Orders','Total_Sales']].rename(
            columns={'Week_Label':'Week','Total_Orders':'Orders','Total_Sales':'Sales (TZS)'}),
            use_container_width=True)
    else:
        st.info("No completed orders in selected period.")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # PRODUCT ANALYSIS
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    st.markdown('<div class="section-header">üì¶ Product & Category Analysis</div>', unsafe_allow_html=True)

    # Build product-week matrix
    _pp_prod_totals = defaultdict(int)
    _pp_wk_prod     = defaultdict(lambda: defaultdict(int))

    for _, _row in _pp_comp.iterrows():
        _wk = int(_row['ISO_Week'])
        for _pn, _qty in extract_products(_row.get('PRODUCTS','')):
            _ps = standardize_product(_pn)
            _pp_prod_totals[_ps]      += _qty
            _pp_wk_prod[_ps][_wk]     += _qty

    if _pp_prod_totals:
        _week_cols_pp = sorted(_pp_weekly['ISO_Week'].unique().astype(int))[-8:]

        _pp_matrix_rows = []
        for _prod, _total in _pp_prod_totals.items():
            _r = {'Product': _prod,
                  'Category': _product_category_map.get(_prod.lower(), 'UNCATEGORIZED')}
            for _w in _week_cols_pp:
                _r[f'W{_w}'] = _pp_wk_prod[_prod].get(_w, 0)
            _r['Total Qty'] = _total
            _pp_matrix_rows.append(_r)

        _pp_matrix = pd.DataFrame(_pp_matrix_rows).sort_values('Total Qty', ascending=False)

        if _cat_sel:
            _pp_matrix = _pp_matrix[_pp_matrix['Category'].isin(_cat_sel)]

        _wcols_disp = [f'W{w}' for w in _week_cols_pp]

        # Display with ‚ùå for zeros
        _pp_display = _pp_matrix.copy()
        for _c in _wcols_disp:
            _pp_display[_c] = _pp_display[_c].apply(lambda x: "‚ùå" if x==0 else int(x))

        _pt1, _pt2 = st.tabs(["üî• Top Selling Items", "üìä Category Rankings"])

        with _pt1:
            st.dataframe(_pp_display[['Product','Category']+_wcols_disp+['Total Qty']],
                         use_container_width=True)

        with _pt2:
            _cat_rank = (_pp_matrix.groupby('Category')[_wcols_disp+['Total Qty']]
                         .sum().reset_index().sort_values('Total Qty', ascending=False))
            _cat_rank = _cat_rank[_cat_rank['Category'] != 'UNCATEGORIZED']
            _cat_disp = _cat_rank.copy()
            for _c in _wcols_disp:
                _cat_disp[_c] = _cat_disp[_c].apply(lambda x: "‚ùå" if x==0 else int(x))
            st.dataframe(_cat_disp, use_container_width=True)

        # ‚îÄ‚îÄ Charts ‚îÄ‚îÄ
        _vc1, _vc2 = st.columns(2)

        with _vc1:
            st.markdown("##### üèÜ Top 10 Products")
            _top10p = _pp_matrix.head(10)
            _fpt, _apt = plt.subplots(figsize=(6,4))
            _bars = _apt.barh(_top10p['Product'], _top10p['Total Qty'],
                              color=plt.cm.Set3(np.linspace(0,1,len(_top10p))))
            _apt.invert_yaxis(); _apt.set_xlabel("Qty")
            _apt.bar_label(_bars, padding=3, fontsize=8)
            plt.tight_layout(); st.pyplot(_fpt); plt.close()

        with _vc2:
            st.markdown("##### ü•ß Category Share")
            _cat_pie = _pp_matrix.groupby('Category')['Total Qty'].sum().reset_index()
            _cat_pie = _cat_pie[_cat_pie['Category'] != 'UNCATEGORIZED']
            _total_qty = _cat_pie['Total Qty'].sum()
            _major = _cat_pie[_cat_pie['Total Qty']/_total_qty >= 0.015]
            _others_v = _cat_pie[_cat_pie['Total Qty']/_total_qty < 0.015]['Total Qty'].sum()
            if _others_v > 0:
                _major = pd.concat([_major, pd.DataFrame({'Category':['Others'],'Total Qty':[_others_v]})])
            _fpc, _apc = plt.subplots(figsize=(6,4))
            _apc.pie(_major['Total Qty'], labels=_major['Category'],
                     autopct='%1.1f%%', startangle=90,
                     colors=plt.cm.Set3(np.linspace(0,1,len(_major))))
            _apc.axis('equal'); plt.tight_layout(); st.pyplot(_fpc); plt.close()

        # ‚îÄ‚îÄ Category Trend ‚îÄ‚îÄ
        st.markdown("##### üìà Category Weekly Trend")
        if len(_wcols_disp) >= 2 and not _cat_rank.empty:
            _fct, _act = plt.subplots(figsize=(12,4))
            for _, _crow in _cat_rank.iterrows():
                _vals = [_pp_matrix[_pp_matrix['Category']==_crow['Category']][_c].sum()
                         for _c in _wcols_disp]
                _act.plot([c.replace('W','W') for c in _wcols_disp], _vals,
                          marker='o', lw=2, label=_crow['Category'])
            _act.set_xlabel("Week"); _act.set_ylabel("Qty"); _act.grid(True, alpha=0.3)
            _act.legend(fontsize=8, ncol=3); plt.xticks(rotation=30)
            plt.title("Category Volume by Week"); plt.tight_layout()
            st.pyplot(_fct); plt.close()

        # ‚îÄ‚îÄ WoW Growth ‚îÄ‚îÄ
        if len(_wcols_disp) >= 2:
            st.markdown("##### üìä Week-over-Week Category Growth %")
            _last_w, _prev_w = _wcols_disp[-1], _wcols_disp[-2]
            _cat_rank = _cat_rank.copy()
            _cat_rank['WoW %'] = ((_cat_rank[_last_w] - _cat_rank[_prev_w])
                                   / _cat_rank[_prev_w].replace(0, np.nan) * 100).fillna(0)
            _gwow = _cat_rank.sort_values('WoW %', ascending=False)
            _fwow, _awow = plt.subplots(figsize=(10,4))
            _colors_wow = ['#28a745' if v >= 0 else '#dc3545' for v in _gwow['WoW %']]
            _awow.bar(_gwow['Category'], _gwow['WoW %'], color=_colors_wow)
            _awow.axhline(0, color='black', lw=0.8)
            _awow.set_ylabel("Growth %"); _awow.set_title(f"WoW Growth: {_prev_w} ‚Üí {_last_w}")
            plt.xticks(rotation=35, ha='right'); plt.tight_layout()
            st.pyplot(_fwow); plt.close()

        # ‚îÄ‚îÄ Growth vs Volume bubble ‚îÄ‚îÄ
        st.markdown("##### ü´ß Category: Growth Trajectory vs Volume")
        if len(_wcols_disp) >= 3 and not _cat_rank.empty:
            _slopes = []
            for _, _cr in _cat_rank.iterrows():
                _v = [_pp_matrix[_pp_matrix['Category']==_cr['Category']][_c].sum()
                      for _c in _wcols_disp]
                _slopes.append(np.polyfit(range(len(_v)), _v, 1)[0] if sum(_v) > 0 else 0)
            _cat_rank['Slope'] = _slopes
            _fbub, _abub = plt.subplots(figsize=(10,5))
            _abub.scatter(_cat_rank['Total Qty'], _cat_rank['Slope'],
                          s=(_cat_rank['Total Qty']/max(_cat_rank['Total Qty'].max(),1)*800+50),
                          c=plt.cm.Set2(np.linspace(0,1,len(_cat_rank))), alpha=0.8, edgecolors='white', lw=1.5)
            for _, _cr in _cat_rank.iterrows():
                _abub.annotate(_cr['Category'], (_cr['Total Qty'], _cr['Slope']),
                               fontsize=8, ha='center', va='bottom')
            _abub.axhline(0, color='gray', lw=1, linestyle='--')
            _abub.set_xlabel("Total Volume"); _abub.set_ylabel("Trend (slope)")
            _abub.set_title("Growth Trajectory vs Volume ‚Äî bigger bubble = more volume")
            plt.tight_layout(); st.pyplot(_fbub); plt.close()

    else:
        st.info("No product data could be extracted from PRODUCTS column.")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # TOP ORDERS BY VALUE
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    st.markdown('<div class="section-header">üí∞ Top Orders by Value</div>', unsafe_allow_html=True)

    _top_ord = _pp_comp.sort_values('SUBTOTAL', ascending=False).copy()
    _top_ord['Order Date']       = _top_ord['DELIVERY DATE'].dt.date
    _top_ord['Products Ordered'] = _top_ord['PRODUCTS'].apply(format_products_clean)
    _top_ord_view = _top_ord[['ID','Order Date','CUSTOMER NAME','Products Ordered','SUBTOTAL']].head(20)
    _top_ord_view = _top_ord_view.rename(columns={'ID':'Order ID','CUSTOMER NAME':'Customer',
                                                   'SUBTOTAL':'Value (TZS)'})
    st.dataframe(_top_ord_view, use_container_width=True)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # DEEP ANALYTICS SECTIONS
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    st.markdown('<div class="section-header">üî¨ Deep Analytics</div>', unsafe_allow_html=True)

    _da_tab1, _da_tab2, _da_tab3, _da_tab4, _da_tab5 = st.tabs([
        "üç∂ Soju Analysis", "üì¶ Wholesale", "‚ùå Cancelled Orders", "üöó Pickup Orders", "üåô Late Night"
    ])

    # ‚îÄ‚îÄ Build useful derived data ‚îÄ‚îÄ
    _all_pp = raw[raw['BUSINESS NAME'].str.strip().str.lower() == 'piki party'].copy()
    _all_pp['DELIVERY DATE'] = pd.to_datetime(_all_pp['DELIVERY DATE'], errors='coerce')
    _all_pp['DELIVERY TIME'] = pd.to_datetime(_all_pp['DELIVERY TIME'], errors='coerce')
    _all_pp['HOUR'] = _all_pp['DELIVERY TIME'].dt.hour
    _all_pp_iso = _all_pp['DELIVERY DATE'].dt.isocalendar()
    _all_pp['ISO_Week'] = _all_pp_iso.week
    _all_pp['ISO_Year'] = _all_pp_iso.year

    # Identify latest & previous weeks ‚Äî use (Year, Week) pair to avoid year boundary bugs
    _pp_latest_row = (_all_pp.dropna(subset=['DELIVERY DATE'])
                      .sort_values('DELIVERY DATE').iloc[-1])
    _pp_max_yr  = int(_pp_latest_row['ISO_Year'])
    _pp_max_wk  = int(_pp_latest_row['ISO_Week'])
    # Previous week ‚Äî handle year boundary (week 1 of new year follows week 52/53)
    if _pp_max_wk > 1:
        _pp_prev_wk = _pp_max_wk - 1
        _pp_prev_yr = _pp_max_yr
    else:
        _pp_prev_yr = _pp_max_yr - 1
        # Check if prev year had 53 ISO weeks (e.g. 2020, 2015 had 53)
        _dec28_prev = pd.Timestamp(f"{_pp_prev_yr}-12-28")
        _pp_prev_wk = int(_dec28_prev.isocalendar()[1])  # Dec 28 always in last ISO week
    # Filter helpers
    def _pp_is_cur(r):   return int(r['ISO_Year'])==_pp_max_yr and int(r['ISO_Week'])==_pp_max_wk
    def _pp_is_prev(r):  return int(r['ISO_Year'])==_pp_prev_yr and int(r['ISO_Week'])==_pp_prev_wk
    # ‚îÄ‚îÄ Pre-compute data for all deep analytics tabs (outside tab blocks for scoping) ‚îÄ‚îÄ
    # Soju data
    _soju_rows = []
    for _, _r in _all_pp.iterrows():
        for _pn, _qty in extract_products(_r.get('PRODUCTS','')):
            if 'soju' in _pn.lower():
                _soju_rows.append({'Product': _pn.strip().title(),
                                   'Qty': _qty, 'Week': int(_r['ISO_Week']),
                                   'Year': int(_r['ISO_Year']), 'Sales': _r.get('SUBTOTAL',0)})
    _soju_df = pd.DataFrame(_soju_rows) if _soju_rows else pd.DataFrame()
    # Add composite key for safe year-boundary filtering
    if not _soju_df.empty:
        _soju_df['YW'] = _soju_df['Year'] * 100 + _soju_df['Week']
    _pp_cur_yw  = _pp_max_yr  * 100 + _pp_max_wk
    _pp_prev_yw = _pp_prev_yr * 100 + _pp_prev_wk

    # Cancelled data
    _can_df = _all_pp[_all_pp['STATE'].str.contains('Reject|Cancel|Failed', case=False, na=False)].copy()
    _can_prods = defaultdict(int)
    if not _can_df.empty:
        for _, _r in _can_df.iterrows():
            for _pn, _qty in extract_products(_r.get('PRODUCTS','')):
                _can_prods[standardize_product(_pn)] += _qty

    # Late night data
    _ln_df = _all_pp[(_all_pp['HOUR'] >= 23) | (_all_pp['HOUR'] <= 2)].copy()
    _total_all = len(_all_pp)

    # Pickup data
    if 'DELIVERY TYPE' in _all_pp.columns:
        _pick_df = _all_pp[_all_pp['DELIVERY TYPE'].str.lower().str.contains('pickup|pick_up|pick up', na=False)].copy()
    else:
        _pick_df = pd.DataFrame()
    _comp_all_pp = _all_pp[_all_pp['STATE'].isin(['Completed','Delivery Completed By Driver'])]
    _total_comp_pp = len(_comp_all_pp)

    # OOS data ‚Äî pre-build product weekly data from _pp_wk_prod (populated after tab5 product section runs)
    _oos_rows_precomp = []
    _oos_df = pd.DataFrame()  # will be populated after product analysis runs

    with _da_tab1:
        st.markdown("#### üç∂ Soju Product Analysis")
        if not _soju_df.empty:
            _soju_cur  = _soju_df[_soju_df['YW']==_pp_cur_yw]  if 'YW' in _soju_df.columns else _soju_df[(_soju_df['Week']==_pp_max_wk)&(_soju_df['Year']==_pp_max_yr)]
            _soju_prev = _soju_df[_soju_df['YW']==_pp_prev_yw] if 'YW' in _soju_df.columns else _soju_df[(_soju_df['Week']==_pp_prev_wk)&(_soju_df['Year']==_pp_prev_yr)]

            _sc1, _sc2, _sc3 = st.columns(3)
            _sc1.metric("Soju Units This Week", f"{int(_soju_cur['Qty'].sum()):,}")
            _sc2.metric("Soju Units Prev Week", f"{int(_soju_prev['Qty'].sum()):,}",
                        delta=f"{int(_soju_cur['Qty'].sum() - _soju_prev['Qty'].sum()):+}")
            _sc3.metric("Soju Revenue (TZS)", f"{_soju_cur['Sales'].sum()/1e3:.0f}K")

            # Weekly trend per soju variant
            _soju_wk = (_soju_df.groupby(['Year','Week','Product'])['Qty'].sum().reset_index())
            _soju_wk['Period'] = _soju_wk['Year'].astype(str) + "-W" + _soju_wk['Week'].astype(str).str.zfill(2)
            _soju_pivot = _soju_wk.pivot_table(index='Product', columns='Period', values='Qty', aggfunc='sum').fillna(0).astype(int)
            st.dataframe(_soju_pivot, use_container_width=True)

            _sfig, _sax = plt.subplots(figsize=(11,4))
            _soju_weekly_total = _soju_df.groupby('YW')['Qty'].sum().reset_index()
            _soju_weekly_total['Label'] = (_soju_weekly_total['YW'] // 100).astype(str) + "-W" + (_soju_weekly_total['YW'] % 100).astype(str).str.zfill(2)
            _sax.bar(_soju_weekly_total['Label'], _soju_weekly_total['Qty'], color='#9b59b6', alpha=0.8)
            _sax.set_xlabel("Year-Week"); _sax.set_ylabel("Units Sold")
            _sax.set_title("Total Soju Sales by Week"); _sax.grid(True, alpha=0.3, axis='y')
            plt.tight_layout(); st.pyplot(_sfig); plt.close()
        else:
            st.info("No soju products found in PRODUCTS column.")

    with _da_tab2:
        st.markdown("#### üì¶ Wholesale Orders Analysis")
        st.caption("High-value orders (‚â• 100,000 TZS subtotal) treated as potential wholesale")
        _WHOLESALE_MIN = 100_000
        _ws_df = _all_pp[_all_pp['SUBTOTAL'] >= _WHOLESALE_MIN].copy()
        if not _ws_df.empty:
            _ww1, _ww2, _ww3, _ww4 = st.columns(4)
            _ww1.metric("Wholesale Orders", f"{len(_ws_df):,}")
            _ww2.metric("Total Revenue", f"{_ws_df['SUBTOTAL'].sum()/1e6:.2f}M TZS")
            _ww3.metric("Avg Order Value", f"{_ws_df['SUBTOTAL'].mean()/1e3:.0f}K TZS")
            _ww4.metric("% of All Orders",
                        f"{len(_ws_df)/max(len(_all_pp),1)*100:.1f}%")

            _ws_weekly = (_ws_df.groupby(['ISO_Year','ISO_Week'])
                          .agg(Orders=('ID','count'), Revenue=('SUBTOTAL','sum'))
                          .reset_index().sort_values(['ISO_Year','ISO_Week']))
            _ws_weekly['Week_Label'] = "W" + _ws_weekly['ISO_Week'].astype(str)
            _wfig, _wax = plt.subplots(figsize=(11,4))
            _wax.bar(_ws_weekly['Week_Label'], _ws_weekly['Revenue']/1e3, color='#27ae60', alpha=0.8)
            _wax.set_ylabel("Revenue (K TZS)"); _wax.set_title("Wholesale Revenue by Week")
            _wax.grid(True, alpha=0.3, axis='y'); plt.tight_layout()
            st.pyplot(_wfig); plt.close()

            st.markdown("##### Top Wholesale Customers")
            _ws_cust = (_ws_df.groupby('CUSTOMER NAME')
                        .agg(Orders=('ID','count'), Revenue=('SUBTOTAL','sum'),
                             Avg_Order=('SUBTOTAL','mean'))
                        .reset_index().sort_values('Revenue', ascending=False))
            _ws_cust['Revenue'] = _ws_cust['Revenue'].apply(lambda x: f"{int(x):,}")
            _ws_cust['Avg_Order'] = _ws_cust['Avg_Order'].apply(lambda x: f"{int(x):,}")
            st.dataframe(_ws_cust.head(20), use_container_width=True)
        else:
            st.info("No wholesale-level orders found.")

    with _da_tab3:
        st.markdown("#### ‚ùå Cancelled & Rejected Orders")
        if not _can_df.empty:
            _ca1, _ca2, _ca3 = st.columns(3)
            _ca1.metric("Total Cancelled/Rejected", f"{len(_can_df):,}")
            _ca2.metric("This Week",
                        f"{len(_can_df[(_can_df['ISO_Week']==_pp_max_wk) & (_can_df['ISO_Year']==_pp_max_yr)]):,}")
            _ca3.metric("Cancellation Rate",
                        f"{len(_can_df)/max(len(_all_pp),1)*100:.1f}%")

            # State breakdown
            _can_state = _can_df['STATE'].value_counts().reset_index()
            _can_state.columns = ['Reason','Count']
            st.dataframe(_can_state, use_container_width=True)

            # Products in cancelled orders
            st.markdown("##### üè∑Ô∏è Products Most Appearing in Cancelled Orders")
            if _can_prods:
                _cp_df = pd.DataFrame(_can_prods.items(), columns=['Product','Qty in Cancellations'])
                _cp_df = _cp_df.sort_values('Qty in Cancellations', ascending=False)
                st.dataframe(_cp_df.head(15), use_container_width=True)

                _cpf, _cpa = plt.subplots(figsize=(10,4))
                _top_cp = _cp_df.head(10)
                _cpa.barh(_top_cp['Product'], _top_cp['Qty in Cancellations'], color='#e74c3c')
                _cpa.invert_yaxis(); _cpa.set_xlabel("Qty")
                _cpa.set_title("Top Products in Cancelled Orders"); plt.tight_layout()
                st.pyplot(_cpf); plt.close()

            # Weekly cancellation trend
            _can_wk = (_can_df.groupby('ISO_Week').size().reset_index(name='Cancellations'))
            _canwf, _canwa = plt.subplots(figsize=(10,3))
            _canwa.plot(_can_wk['ISO_Week'].astype(str), _can_wk['Cancellations'],
                        marker='o', color='#e74c3c', lw=2)
            _canwa.set_title("Cancellations by Week"); _canwa.grid(True, alpha=0.3)
            plt.tight_layout(); st.pyplot(_canwf); plt.close()
        else:
            st.info("No cancelled/rejected orders found.")

    with _da_tab4:
        st.markdown("#### üöó Pickup Orders Analysis")
        st.caption("STATE = 'Completed' orders analyzed for pickup vs delivery split")
        _comp_all = _comp_all_pp
        _total_comp = _total_comp_pp

        if not _pick_df.empty:
            _pi1, _pi2, _pi3, _pi4 = st.columns(4)
            _pi1.metric("Pickup Orders", f"{len(_pick_df):,}")
            _pi2.metric("Pickup Revenue", f"{_pick_df['SUBTOTAL'].sum()/1e6:.2f}M TZS")
            _pi3.metric("% of Completed Orders",
                        f"{len(_pick_df)/max(_total_comp,1)*100:.1f}%")
            _pi4.metric("Avg Pickup Value", f"{_pick_df['SUBTOTAL'].mean()/1e3:.0f}K TZS")

            _pick_wk = (_pick_df.groupby(['ISO_Year','ISO_Week'])
                        .agg(Orders=('ID','count'), Revenue=('SUBTOTAL','sum'))
                        .reset_index().sort_values(['ISO_Year','ISO_Week']))
            _pick_wk['Week_Label'] = "W" + _pick_wk['ISO_Week'].astype(str)
            _pifig, _piax = plt.subplots(figsize=(11,4))
            _piax.bar(_pick_wk['Week_Label'], _pick_wk['Orders'], color='#FF6B00', alpha=0.8, label='Pickup Orders')
            _piax.set_title("Pickup Orders by Week"); _piax.grid(True, alpha=0.3, axis='y')
            _piax.legend(); plt.tight_layout(); st.pyplot(_pifig); plt.close()

            # Top customers for pickup
            st.markdown("##### üë§ Top Pickup Customers")
            _pick_cust = (_pick_df.groupby('CUSTOMER NAME')
                          .agg(Pickup_Orders=('ID','count'), Total_Spend=('SUBTOTAL','sum'),
                               Avg_Order=('SUBTOTAL','mean'))
                          .reset_index().sort_values('Pickup_Orders', ascending=False))
            _pick_cust['Total_Spend'] = _pick_cust['Total_Spend'].apply(lambda x: f"{int(x):,} TZS")
            _pick_cust['Avg_Order']   = _pick_cust['Avg_Order'].apply(lambda x: f"{int(x):,} TZS")
            _pick_cust.index = range(1, len(_pick_cust)+1)
            st.dataframe(_pick_cust.head(20), use_container_width=True)

            # Top customers for pickup orders
            st.markdown("##### üëë Top Customers ‚Äî Pickup Orders")
            _pick_top_cust = (_pick_df.groupby('CUSTOMER NAME')
                              .agg(Orders=('ID','count'), Total_Spend=('SUBTOTAL','sum'))
                              .reset_index().sort_values('Total_Spend', ascending=False).head(10))
            _pick_top_cust['Total_Spend'] = _pick_top_cust['Total_Spend'].apply(lambda x: f"{int(x):,} TZS")
            _pick_top_cust.index = range(1, len(_pick_top_cust)+1)
            st.dataframe(_pick_top_cust, use_container_width=True)
        else:
            # Fallback: show completed orders analysis
            st.info("DELIVERY TYPE column not found or no pickup entries ‚Äî showing all completed orders analysis.")
            if not _comp_all.empty:
                _co1, _co2, _co3 = st.columns(3)
                _co1.metric("Completed Orders", f"{_total_comp:,}")
                _co2.metric("Completed Revenue", f"{_comp_all['SUBTOTAL'].sum()/1e6:.2f}M TZS")
                _co3.metric("Avg Order Value", f"{_comp_all['SUBTOTAL'].mean()/1e3:.0f}K TZS")
                _comp_wk = (_comp_all.groupby('ISO_Week').agg(Orders=('ID','count')).reset_index())
                _cofig, _coax = plt.subplots(figsize=(11,4))
                _coax.bar(_comp_wk['ISO_Week'].astype(str), _comp_wk['Orders'], color='#27ae60', alpha=0.8)
                _coax.set_title("Completed Orders by Week"); _coax.grid(True, alpha=0.3, axis='y')
                plt.tight_layout(); st.pyplot(_cofig); plt.close()

    with _da_tab5:
        st.markdown("#### üåô Late Night Orders (23:00 ‚Äì 02:00)")
        if not _ln_df.empty:
            _ln1, _ln2, _ln3, _ln4 = st.columns(4)
            _ln1.metric("Late Night Orders", f"{len(_ln_df):,}")
            _ln2.metric("Revenue", f"{_ln_df['SUBTOTAL'].sum()/1e6:.2f}M TZS")
            _ln3.metric("% of Total Orders",
                        f"{len(_ln_df)/max(_total_all,1)*100:.1f}%")
            _ln4.metric("This Week",
                        f"{len(_ln_df[(_ln_df['ISO_Week']==_pp_max_wk) & (_ln_df['ISO_Year']==_pp_max_yr)]):,}")

            # Weekly trend
            _ln_wk = (_ln_df.groupby(['ISO_Year','ISO_Week'])
                      .agg(Orders=('ID','count'), Revenue=('SUBTOTAL','sum'))
                      .reset_index().sort_values(['ISO_Year','ISO_Week']))
            _ln_wk['Week_Label'] = "W" + _ln_wk['ISO_Week'].astype(str)
            _lnfig, _lnax = plt.subplots(figsize=(11,4))
            _lnax.plot(_ln_wk['Week_Label'], _ln_wk['Orders'],
                       marker='o', color='#8e44ad', lw=2, label='Late Night Orders')
            _lnax.fill_between(range(len(_ln_wk)), _ln_wk['Orders'],
                               alpha=0.15, color='#8e44ad')
            _lnax.set_title("Late Night Orders Trend"); _lnax.grid(True, alpha=0.3)
            _lnax.legend(); plt.xticks(rotation=30, ha='right'); plt.tight_layout()
            st.pyplot(_lnfig); plt.close()

            # Hour breakdown
            _ln_hr = _ln_df['HOUR'].value_counts().sort_index()
            _lnhf, _lnha = plt.subplots(figsize=(7,3))
            _lnha.bar(_ln_hr.index.astype(str), _ln_hr.values, color='#2c3e50', alpha=0.8)
            _lnha.set_xlabel("Hour"); _lnha.set_ylabel("Orders")
            _lnha.set_title("Distribution by Hour (23‚Äì02)"); plt.tight_layout()
            st.pyplot(_lnhf); plt.close()

            # Top products late night
            st.markdown("##### üõí Top Late Night Products")
            _ln_prods = defaultdict(int)
            for _, _r in _ln_df.iterrows():
                for _pn, _qty in extract_products(_r.get('PRODUCTS','')):
                    _ln_prods[standardize_product(_pn)] += _qty
            if _ln_prods:
                _lnp_df = pd.DataFrame(_ln_prods.items(), columns=['Product','Qty']).sort_values('Qty', ascending=False)
                st.dataframe(_lnp_df.head(10), use_container_width=True)
        else:
            st.info("No late night orders found.")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # OUT-OF-STOCK / MISSING PRODUCT ALERT
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    st.markdown('<div class="section-header">‚ö†Ô∏è Out-of-Stock & Availability Alerts</div>', unsafe_allow_html=True)
    if _pp_prod_totals:
        try:
            _wcp_len = len(_week_cols_pp)
        except NameError:
            _week_cols_pp = []
            _wcp_len = 0
    if _pp_prod_totals and _wcp_len >= 2:
        # Rebuild OOS using (ISO_Year, ISO_Week) from _pp_comp for accuracy
        _pp_cur_max_composite = _pp_max_yr * 100 + _pp_max_wk
        _pp_wk_prod_yr = defaultdict(lambda: defaultdict(int))
        for _, _oos_row in _pp_comp.iterrows():
            _yw = int(_oos_row['ISO_Year'])*100 + int(_oos_row['ISO_Week'])
            for _pn2, _qty2 in extract_products(_oos_row.get('PRODUCTS','')):
                _pp_wk_prod_yr[standardize_product(_pn2)][_yw] += _qty2

        _oos_rows = []
        for _prod, _wk_data in _pp_wk_prod_yr.items():
            _last_sold_yw = max((_yw for _yw, _q in _wk_data.items() if _q > 0), default=None)
            if _last_sold_yw and _last_sold_yw < _pp_cur_max_composite:
                _ls_yr, _ls_wk = _last_sold_yw // 100, _last_sold_yw % 100
                # How many calendar weeks missing
                _weeks_missing = ((_pp_max_yr - _ls_yr)*52 + (_pp_max_wk - _ls_wk))
                _hist_avg = sum(_wk_data.values()) / max(len(_wk_data),1)
                _oos_rows.append({'Product': _prod,
                                  'Last Sold': f"{_ls_yr}-W{_ls_wk:02d}",
                                  'Weeks Missing': _weeks_missing,
                                  'Hist. Weekly Avg Qty': round(_hist_avg,1)})
        if _oos_rows:
            _oos_df = pd.DataFrame(_oos_rows).sort_values('Weeks Missing', ascending=False)

            # Get avg order value from completed orders to estimate revenue loss
            _avg_order_val = _pp_comp['SUBTOTAL'].mean() if not _pp_comp.empty else 5000
            # Estimate revenue lost = hist_avg_qty * avg_items_per_order_revenue
            # Simpler: use avg price per product unit ~ avg_order_val / avg_items_per_order
            _avg_items_per_order = max(
                pd.Series([len(extract_products(r)) for r in _pp_comp['PRODUCTS'].dropna().head(200)]).mean(), 1
            )
            _price_per_unit = _avg_order_val / _avg_items_per_order

            _oos_df['Est. Weekly Revenue Lost (TZS)'] = (
                _oos_df['Hist. Weekly Avg Qty'] * _price_per_unit
            ).round(0).astype(int)

            # Sort by estimated revenue loss (highest first = most impactful)
            _oos_df = _oos_df.sort_values('Est. Weekly Revenue Lost (TZS)', ascending=False)

            _total_rev_lost = _oos_df['Est. Weekly Revenue Lost (TZS)'].sum()
            _top_oos = _oos_df.head(5)

            st.warning(
                f"‚ö†Ô∏è **{len(_oos_df)} products** not sold this week ‚Äî "
                f"estimated **{_total_rev_lost/1e3:.0f}K TZS** in weekly revenue at risk. "
                f"Sorted by highest revenue impact first."
            )

            # Highlight the top impactful missing products
            st.markdown("##### üî¥ Top Products Missing This Week (Highest Revenue Impact)")
            for _, _oos_r in _top_oos.iterrows():
                st.markdown(
                    f"- **{_oos_r['Product']}** ‚Äî last sold `{_oos_r['Last Sold']}` "
                    f"({_oos_r['Weeks Missing']} week(s) missing) | "
                    f"hist. avg **{_oos_r['Hist. Weekly Avg Qty']}** units/week | "
                    f"~**{_oos_r['Est. Weekly Revenue Lost (TZS)']:,} TZS** lost this week"
                )

            with st.expander("üìã View all missing products", expanded=False):
                _oos_display = _oos_df.copy()
                _oos_display['Est. Weekly Revenue Lost (TZS)'] = _oos_display['Est. Weekly Revenue Lost (TZS)'].apply(lambda x: f"{x:,}")
                st.dataframe(_oos_display, use_container_width=True)
        else:
            st.success("‚úÖ No products appear to be missing in the current week.")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # AI INSIGHT ‚Äî AUTO-RUNS (cached in session state)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    if not _pp_weekly.empty and _pp_prod_totals:
        _top5_str = pd.DataFrame(_pp_prod_totals.items(), columns=['Product','Qty'])\
                      .sort_values('Qty', ascending=False).head(10).to_string(index=False)

        # Soju summary for context
        _soju_ctx = ""
        try:
            if not _soju_df.empty:
                _s_cur  = _soju_df[_soju_df['YW']==_pp_cur_yw]
                _s_prev = _soju_df[_soju_df['YW']==_pp_prev_yw]
                _soju_ctx = (f"\nSOJU THIS WEEK (W{_pp_max_wk}/{_pp_max_yr}): {int(_s_cur['Qty'].sum())} units | "
                             f"PREV WEEK: {int(_s_prev['Qty'].sum())} units\n")
        except Exception:
            pass

        # Cancelled context
        _can_ctx = ""
        try:
            if not _can_df.empty:
                _top_can_prod = sorted(_can_prods.items(), key=lambda x: -x[1])[:3] if _can_prods else []
                _can_ctx = (f"\nCANCELLED ORDERS: {len(_can_df)} total ({len(_can_df)/max(len(_all_pp),1)*100:.1f}% rate)\n"
                            f"Top cancelled products: {', '.join([p for p,_ in _top_can_prod])}\n")
        except Exception:
            pass

        # Late night context
        _ln_ctx = ""
        try:
            if not _ln_df.empty:
                _ln_yw = _ln_df['ISO_Year'] * 100 + _ln_df['ISO_Week']
                _ln_this_wk = len(_ln_df[_ln_yw==_pp_cur_yw])
                _ln_ctx = (f"\nLATE NIGHT ORDERS: {len(_ln_df)} ({len(_ln_df)/max(_total_all,1)*100:.1f}% of total)\n"
                           f"This week (W{_pp_max_wk}/{_pp_max_yr}) late night: {_ln_this_wk}\n")
        except Exception:
            pass

        # OOS context
        _oos_ctx = ""
        try:
            if not _oos_df.empty:
                _top_oos_names = _oos_df.head(5)['Product'].tolist()
                _total_loss = _oos_df['Est. Weekly Revenue Lost (TZS)'].sum() if 'Est. Weekly Revenue Lost (TZS)' in _oos_df.columns else 0
                _oos_ctx = (f"\nPRODUCTS NOT SOLD THIS WEEK (potential OOS): {', '.join(_top_oos_names)}\n"
                            f"Estimated total revenue at risk from missing products: {_total_loss:,} TZS/week\n")
        except Exception:
            _oos_ctx = ""

        _pp_ctx = (f"PIKI PARTY STORE ANALYSIS ‚Äî Current Week: W{_pp_max_wk}\n"
                   f"Total completed orders: {len(_pp_comp):,}\n"
                   f"Total sales: {_pp_comp['SUBTOTAL'].sum()/1e6:.2f}M TZS\n"
                   f"Weeks available: {len(_pp_weekly)}\n\n"
                   f"TOP 10 PRODUCTS:\n{_top5_str}\n\n"
                   f"WEEKLY TREND (last 4 weeks):\n"
                   + _pp_weekly.tail(4)[['Week_Label','Total_Orders','Total_Sales']].to_string(index=False)
                   + _soju_ctx + _can_ctx + _ln_ctx + _oos_ctx)

        _pp_prompt = (
            "You are a senior BI analyst for Piki, a Tanzanian food delivery company.\n"
            "You are analysing the Piki Party Store ‚Äî a specialty party supply/catering store in Tanzania.\n\n"
            + _pp_ctx + "\n\n"
            "Provide a deep, comprehensive analysis:\n"
            "1. **Store Performance** ‚Äî Is Piki Party growing? Key trend observation with numbers.\n"
            "2. **Star Products & Out-of-Stock Alerts** ‚Äî Top sellers + flag any products missing this week that were selling before (possible stock-out or system issue).\n"
            "3. **Soju Performance** ‚Äî How are soju products selling? Any specific variant spiking or declining?\n"
            "4. **Cancellation Insights** ‚Äî Which products appear most in cancelled orders? What could be causing it?\n"
            "5. **Late Night Opportunity** ‚Äî Is the late night segment (23‚Äì02h) growing? How significant is it to the business?\n"
            "6. **Wholesale Signals** ‚Äî Any high-value orders suggesting bulk/wholesale demand? Opportunity?\n"
            "7. **Strategic Actions** ‚Äî 3 specific, prioritized recommendations to grow Piki Party revenue next week.\n\n"
            "Be specific, use real numbers from the data provided, write as a strategic advisor."
        )

        # Auto-run AI insight ‚Äî cached per data context, refresh button available
        _pp_ins_key = "pp_auto_insight"
        _pp_ctx_hash = str(hash(_pp_ctx[:300]))
        if _pp_ins_key not in st.session_state:
            st.session_state[_pp_ins_key]            = None
            st.session_state[_pp_ins_key + "_hash"]  = None
        if (st.session_state[_pp_ins_key] is None or
                st.session_state.get(_pp_ins_key + "_hash") != _pp_ctx_hash):
            with st.spinner("ü§ñ Generating Piki Party deep analysis‚Ä¶"):
                try:
                    st.session_state[_pp_ins_key]           = claude_insight(_pp_prompt, max_tokens=1200)
                    st.session_state[_pp_ins_key + "_hash"] = _pp_ctx_hash
                except Exception as _pp_err:
                    st.session_state[_pp_ins_key] = f"Error generating insight: {_pp_err}"
        if st.session_state[_pp_ins_key]:
            ai_block("piki_party", _pp_ctx, st.session_state[_pp_ins_key])
        _pp_ref_c1, _ = st.columns([2, 4])
        if _pp_ref_c1.button("‚Ü∫ Refresh AI Insight", key="pp_ins_refresh"):
            st.session_state[_pp_ins_key] = None
            st.rerun()
    else:
        st.info("Upload more data to generate AI insights for Piki Party.")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # DOWNLOADS
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    st.markdown('<div class="section-header">‚¨áÔ∏è Export Reports</div>', unsafe_allow_html=True)

    if _pp_prod_totals:
        _dl1, _dl2 = st.columns(2)

        _exp_buf1 = io.BytesIO()
        with pd.ExcelWriter(_exp_buf1, engine='xlsxwriter') as _ew:
            _pp_display.to_excel(_ew, sheet_name='Top Items', index=False)
            if not _cat_rank.empty:
                _cat_disp.to_excel(_ew, sheet_name='Category Ranking', index=False)
            _top_ord_view.to_excel(_ew, sheet_name='Top Orders by Value', index=False)

        _dl1.download_button("‚¨áÔ∏è Filtered Results (Excel)",
                             data=_exp_buf1.getvalue(),
                             file_name="Piki_Party_Filtered.xlsx",
                             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        _exp_buf2 = io.BytesIO()
        with pd.ExcelWriter(_exp_buf2, engine='xlsxwriter') as _ew2:
            if not _cat_rank.empty:
                _cat_disp.to_excel(_ew2, sheet_name='CATEGORY_RANKING', index=False)
            for _cname in (_cat_rank['Category'].unique() if not _cat_rank.empty else []):
                _csheet = _pp_matrix[_pp_matrix['Category']==_cname].sort_values('Total Qty', ascending=False)
                _csheet.to_excel(_ew2, sheet_name=str(_cname)[:31], index=False)

        _dl2.download_button("‚¨áÔ∏è Full Category Report (All Sheets)",
                             data=_exp_buf2.getvalue(),
                             file_name="Piki_Party_Full_Report.xlsx",
                             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# TAB 6 ‚Äî QUICK ACCESS & TOOLS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
with tab6:
    st.markdown('<div class="section-header">üîó Quick Access & Useful Links</div>', unsafe_allow_html=True)

    st.markdown("""
    <style>
    .qa-section-title {
        font-size: 15px; font-weight: 700; color: #FF6B00;
        margin: 20px 0 10px 0; border-bottom: 2px solid #FF6B00;
        padding-bottom: 4px;
    }
    .qa-card {
        background: #fff; border-radius: 10px;
        border: 1px solid #e8e8e8; border-left: 4px solid #FF6B00;
        padding: 14px 18px; margin: 8px 0;
        display: flex; align-items: center; gap: 14px;
    }
    .qa-card-icon { font-size: 28px; flex-shrink: 0; }
    .qa-card-title { font-weight: 700; font-size: 14px; color: #1a1a2e; margin-bottom: 2px; }
    .qa-card-desc  { font-size: 12px; color: #666; }
    .qa-card-link  { margin-left: auto; flex-shrink: 0; }
    .qa-link-btn {
        background: #FF6B00; color: #fff; font-weight: 700;
        padding: 7px 16px; border-radius: 20px; text-decoration: none;
        font-size: 12px; white-space: nowrap;
    }
    .qa-link-btn:hover { background: #CC5500; color: #fff; }
    .qa-link-btn-blue {
        background: #4A6CF7; color: #fff; font-weight: 700;
        padding: 7px 16px; border-radius: 20px; text-decoration: none;
        font-size: 12px; white-space: nowrap;
    }
    .qa-link-btn-green {
        background: #28a745; color: #fff; font-weight: 700;
        padding: 7px 16px; border-radius: 20px; text-decoration: none;
        font-size: 12px; white-space: nowrap;
    }
    .qa-link-btn-purple {
        background: #6f42c1; color: #fff; font-weight: 700;
        padding: 7px 16px; border-radius: 20px; text-decoration: none;
        font-size: 12px; white-space: nowrap;
    }
    .qa-link-btn-teal {
        background: #00897b; color: #fff; font-weight: 700;
        padding: 7px 16px; border-radius: 20px; text-decoration: none;
        font-size: 12px; white-space: nowrap;
    }
    .qa-divider { height: 1px; background: #f0f0f0; margin: 8px 0; }
    </style>
    """, unsafe_allow_html=True)

    # ‚îÄ‚îÄ SECTION 1: Piki Customer & App ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown('<div class="qa-section-title">üõµ Piki for Customers</div>', unsafe_allow_html=True)

    st.markdown("""
    <div class="qa-card">
        <div class="qa-card-icon">üåê</div>
        <div>
            <div class="qa-card-title">Order Online ‚Äî Piki Website</div>
            <div class="qa-card-desc">Place food orders directly from piki.co.tz</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn" href="https://l.instagram.com/?u=http%3A%2F%2Fwww.piki.co.tz%2F%3Futm_source%3Dig%26utm_medium%3Dsocial%26utm_content%3Dlink_in_bio%26fbclid%3DPAZXh0bgNhZW0CMTEAc3J0YwZhcHBfaWQMMjU2MjgxMDQwNTU4AAGn7eZ35ldpBSy-D3M2qJDnujzDhVbD0d1zTShYR0cQrMjM7Yv1cilEocqbFUo_aem_A-6152u0SGk8Eblm8WbZWg&e=AT6S18r4ghfoqWdFoC3nATHbV3vgIBBJ8_Hwv5g0tLCzkQfyMpMU4XhrkYIpq2cV7q0C5PatptYK9IrN71gHFRVQYaC7xFtGEU-MW2w3hQ" target="_blank">Order Now ‚Üí</a>
        </div>
    </div>

    <div class="qa-card">
        <div class="qa-card-icon">üì±</div>
        <div>
            <div class="qa-card-title">Download the Piki App</div>
            <div class="qa-card-desc">Available on Android & iOS ‚Äî fast delivery at your fingertips</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn" href="https://l.instagram.com/?u=https%3A%2F%2Fonelink.to%2F9hp5ge%3Futm_source%3Dig%26utm_medium%3Dsocial%26utm_content%3Dlink_in_bio%26fbclid%3DPAZXh0bgNhZW0CMTEAc3J0YwZhcHBfaWQMMjU2MjgxMDQwNTU4AAGnKzDsjnfmImd588_uM-YOPELOAfZhKk_eat5Qa-uFph9miR4XNLXbTJaA1aw_aem_deEtznh7evXpEZZFYcMukg&e=AT6Fm0P6C4xz7nQ6KPVZatzLubC-Zc7hJ_lXpl3gkg469iK59jachvtP7RgueDuGy6xIYJpV8y7D5FFGfRsmadG4MZT2wRgUMaIzyP5KTQ" target="_blank">Download App ‚Üí</a>
        </div>
    </div>

    <div class="qa-card">
        <div class="qa-card-icon">üì∏</div>
        <div>
            <div class="qa-card-title">Piki on Instagram</div>
            <div class="qa-card-desc">Follow @piki.tz for promos, updates & community content</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn-blue" href="https://www.instagram.com/piki.tz/" target="_blank">Follow Us ‚Üí</a>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # ‚îÄ‚îÄ SECTION 2: Internal Tools ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown('<div class="qa-section-title">‚öôÔ∏è Internal Tools & Operations</div>', unsafe_allow_html=True)

    st.markdown(f"""
    <div class="qa-card">
        <div class="qa-card-icon">üìã</div>
        <div>
            <div class="qa-card-title">Weekly Standup Presentation</div>
            <div class="qa-card-desc">Department updates, weekly highlights & meeting notes</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn-purple" href="https://docs.google.com/presentation/d/1uHEeI-R2xyaKd9HyAcgPxqDc-3guMtRI7O9WmOPh6UY/edit" target="_blank">Open Slides ‚Üí</a>
        </div>
    </div>

    <div class="qa-card">
        <div class="qa-card-icon">üìù</div>
        <div>
            <div class="qa-card-title">Content Team Tracker</div>
            <div class="qa-card-desc">Content submissions, status tracking & work pipeline</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn-green" href="https://docs.google.com/spreadsheets/d/1nk_a_aObBK7njLGKzz_Eghr2WXUwJRARw5m9Iiugqlo/edit" target="_blank">Open Tracker ‚Üí</a>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # ‚îÄ‚îÄ SECTION 3: ERP Links ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown('<div class="qa-section-title">üèóÔ∏è ERP ‚Äî Project Management</div>', unsafe_allow_html=True)

    st.markdown("""
    <div class="qa-card">
        <div class="qa-card-icon">üìÅ</div>
        <div>
            <div class="qa-card-title">General Projects</div>
            <div class="qa-card-desc">All active company projects and tasks</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn-teal" href="http://erp.piki.co.tz/app/projects" target="_blank">Open ERP ‚Üí</a>
        </div>
    </div>

    <div class="qa-card">
        <div class="qa-card-icon">üé®</div>
        <div>
            <div class="qa-card-title">Design Projects</div>
            <div class="qa-card-desc">Creative & design work tracking</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn-teal" href="http://erp.piki.co.tz/app/design-projects" target="_blank">Open ERP ‚Üí</a>
        </div>
    </div>

    <div class="qa-card">
        <div class="qa-card-icon">üì£</div>
        <div>
            <div class="qa-card-title">Content & Marketing Projects</div>
            <div class="qa-card-desc">Kanban board for content & marketing campaign work</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn-teal" href="http://erp.piki.co.tz/app/content-and-marketing-projects/view/kanban/piki" target="_blank">Open ERP ‚Üí</a>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # ‚îÄ‚îÄ SECTION 4: Training ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown('<div class="qa-section-title">üìö Training & Resources</div>', unsafe_allow_html=True)

    st.markdown("""
    <div class="qa-card">
        <div class="qa-card-icon">üö¥</div>
        <div>
            <div class="qa-card-title">Piki Driver App Training Guide</div>
            <div class="qa-card-desc">Login, order flow, delivery completion & reporting protocols</div>
        </div>
        <div class="qa-card-link">
            <a class="qa-link-btn" href="https://www.piki.co.tz" target="_blank">View Guide ‚Üí</a>
        </div>
    </div>
    """, unsafe_allow_html=True)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.divider()
st.markdown(
    """
    <div style="background:#1a1a2e;color:#ccc;padding:20px 28px;border-radius:10px;
                font-size:12px;text-align:center;line-height:2.0;margin-top:12px;">
        <div style="font-size:26px;font-weight:800;color:#FF6B00;letter-spacing:3px;margin-bottom:2px;">
            üõµ PIKI
        </div>
        <div style="color:#FF8C3A;margin-bottom:8px;font-size:11px;letter-spacing:1.5px;font-weight:600;">
            BUSINESS INTELLIGENCE DASHBOARD
        </div>
        <div style="border-top:1px solid #FF6B00;opacity:0.4;margin:8px 0;"></div>
        <div style="opacity:1;">
            For any questions or recommendations:<br>
            üìû <a href="tel:+255767871795" style="color:#FF8C3A;text-decoration:none;font-weight:600;">Tel: +255 767 871 795</a>
            &nbsp;|&nbsp;
            ‚úâÔ∏è <a href="mailto:lusekelo.kangele@piki.co.tz" style="color:#FF8C3A;text-decoration:none;">lusekelo.kangele@piki.co.tz</a>
            &nbsp;|&nbsp;
            üåê <a href="https://www.piki.co.tz" target="_blank" style="color:#FF8C3A;text-decoration:none;font-weight:600;">www.piki.co.tz</a>
        </div>
        <div style="margin-top:8px;color:#aaa;font-size:11px;letter-spacing:0.5px;">
            üèôÔ∏è Dar es Salaam &nbsp;&bull;&nbsp; Arusha &nbsp;&bull;&nbsp; Dodoma &nbsp;&bull;&nbsp; Mwanza &nbsp;&bull;&nbsp; Zanzibar
        </div>
    </div>
    """,
    unsafe_allow_html=True
)
